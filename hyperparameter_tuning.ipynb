{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jungkihong07/Deepwave/blob/main/hyperparameter_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pEOEFD7yDCZw",
        "outputId": "39fb4ef5-7882-47e2-972a-43c3aeaa30b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: optuna in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.3.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from optuna) (1.16.1)\n",
            "Requirement already satisfied: colorlog in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
            "Requirement already satisfied: greenlet>=1 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna) (3.2.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 25.1.1\n",
            "[notice] To update, run: C:\\Users\\rosac\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xF-1Xe-yDCZx",
        "outputId": "24c5062a-5780-45f7-d3d1-ea5e800924cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: librosa==0.11.0 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 1)) (0.11.0)\n",
            "Requirement already satisfied: matplotlib==3.9.4 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 2)) (3.9.4)\n",
            "Requirement already satisfied: numpy==2.0.2 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 3)) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn==1.6.1 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 4)) (1.6.1)\n",
            "Requirement already satisfied: tensorflow==2.19.0 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 5)) (2.19.0)\n",
            "Requirement already satisfied: ipykernel in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 6)) (6.29.5)\n",
            "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa==0.11.0->-r requirements.txt (line 1)) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa==0.11.0->-r requirements.txt (line 1)) (0.61.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa==0.11.0->-r requirements.txt (line 1)) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.0 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa==0.11.0->-r requirements.txt (line 1)) (1.5.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa==0.11.0->-r requirements.txt (line 1)) (5.2.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa==0.11.0->-r requirements.txt (line 1)) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa==0.11.0->-r requirements.txt (line 1)) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa==0.11.0->-r requirements.txt (line 1)) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa==0.11.0->-r requirements.txt (line 1)) (4.13.2)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa==0.11.0->-r requirements.txt (line 1)) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa==0.11.0->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib==3.9.4->-r requirements.txt (line 2)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib==3.9.4->-r requirements.txt (line 2)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib==3.9.4->-r requirements.txt (line 2)) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib==3.9.4->-r requirements.txt (line 2)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib==3.9.4->-r requirements.txt (line 2)) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib==3.9.4->-r requirements.txt (line 2)) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib==3.9.4->-r requirements.txt (line 2)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib==3.9.4->-r requirements.txt (line 2)) (2.9.0.post0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn==1.6.1->-r requirements.txt (line 4)) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow==2.19.0->-r requirements.txt (line 5)) (2.3.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow==2.19.0->-r requirements.txt (line 5)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow==2.19.0->-r requirements.txt (line 5)) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow==2.19.0->-r requirements.txt (line 5)) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow==2.19.0->-r requirements.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow==2.19.0->-r requirements.txt (line 5)) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow==2.19.0->-r requirements.txt (line 5)) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow==2.19.0->-r requirements.txt (line 5)) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow==2.19.0->-r requirements.txt (line 5)) (2.32.3)\n",
            "Requirement already satisfied: setuptools in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow==2.19.0->-r requirements.txt (line 5)) (65.5.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow==2.19.0->-r requirements.txt (line 5)) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow==2.19.0->-r requirements.txt (line 5)) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow==2.19.0->-r requirements.txt (line 5)) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow==2.19.0->-r requirements.txt (line 5)) (1.71.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow==2.19.0->-r requirements.txt (line 5)) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow==2.19.0->-r requirements.txt (line 5)) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow==2.19.0->-r requirements.txt (line 5)) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow==2.19.0->-r requirements.txt (line 5)) (0.5.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow==2.19.0->-r requirements.txt (line 5)) (0.31.0)\n",
            "Requirement already satisfied: comm>=0.1.1 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipykernel->-r requirements.txt (line 6)) (0.2.2)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipykernel->-r requirements.txt (line 6)) (1.8.14)\n",
            "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipykernel->-r requirements.txt (line 6)) (9.2.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipykernel->-r requirements.txt (line 6)) (8.6.3)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipykernel->-r requirements.txt (line 6)) (5.7.2)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipykernel->-r requirements.txt (line 6)) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipykernel->-r requirements.txt (line 6)) (1.6.0)\n",
            "Requirement already satisfied: psutil in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipykernel->-r requirements.txt (line 6)) (7.0.0)\n",
            "Requirement already satisfied: pyzmq>=24 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipykernel->-r requirements.txt (line 6)) (26.4.0)\n",
            "Requirement already satisfied: tornado>=6.1 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipykernel->-r requirements.txt (line 6)) (6.4.2)\n",
            "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipykernel->-r requirements.txt (line 6)) (5.14.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow==2.19.0->-r requirements.txt (line 5)) (0.45.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 6)) (0.4.6)\n",
            "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 6)) (1.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 6)) (0.19.2)\n",
            "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 6)) (3.0.51)\n",
            "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 6)) (2.19.1)\n",
            "Requirement already satisfied: stack_data in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 6)) (0.6.3)\n",
            "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->-r requirements.txt (line 6)) (4.3.7)\n",
            "Requirement already satisfied: pywin32>=300 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->-r requirements.txt (line 6)) (310)\n",
            "Requirement already satisfied: rich in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.5.0->tensorflow==2.19.0->-r requirements.txt (line 5)) (14.0.0)\n",
            "Requirement already satisfied: namex in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.5.0->tensorflow==2.19.0->-r requirements.txt (line 5)) (0.1.0)\n",
            "Requirement already satisfied: optree in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.5.0->tensorflow==2.19.0->-r requirements.txt (line 5)) (0.16.0)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from numba>=0.51.0->librosa==0.11.0->-r requirements.txt (line 1)) (0.44.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow==2.19.0->-r requirements.txt (line 5)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow==2.19.0->-r requirements.txt (line 5)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow==2.19.0->-r requirements.txt (line 5)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow==2.19.0->-r requirements.txt (line 5)) (2025.4.26)\n",
            "Requirement already satisfied: cffi>=1.0 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from soundfile>=0.12.1->librosa==0.11.0->-r requirements.txt (line 1)) (1.17.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow==2.19.0->-r requirements.txt (line 5)) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow==2.19.0->-r requirements.txt (line 5)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow==2.19.0->-r requirements.txt (line 5)) (3.1.3)\n",
            "Requirement already satisfied: pycparser in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa==0.11.0->-r requirements.txt (line 1)) (2.22)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->-r requirements.txt (line 6)) (0.8.4)\n",
            "Requirement already satisfied: wcwidth in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel->-r requirements.txt (line 6)) (0.2.13)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow==2.19.0->-r requirements.txt (line 5)) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow==2.19.0->-r requirements.txt (line 5)) (3.0.0)\n",
            "Requirement already satisfied: executing>=1.2.0 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 6)) (2.2.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 6)) (3.0.0)\n",
            "Requirement already satisfied: pure-eval in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 6)) (0.2.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\rosac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow==2.19.0->-r requirements.txt (line 5)) (0.1.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 25.1.1\n",
            "[notice] To update, run: C:\\Users\\rosac\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKpJWg_rv9ig"
      },
      "source": [
        "## 학습용 데이터 로딩"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ox0lftHIv-SY"
      },
      "outputs": [],
      "source": [
        "train_audio_path = 'train'\n",
        "train_label_path = 'train_label.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTIKFCTpDCZy",
        "outputId": "89564984-4886-4b84-879d-913fdd14eddf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "librosa version: 0.11.0\n",
            "matplotlib version: 3.9.4\n",
            "numpy version: 2.0.2\n",
            "scikit-learn version: 1.6.1\n",
            "tensorflow version: 2.19.0\n"
          ]
        }
      ],
      "source": [
        "import librosa\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import tensorflow as tf\n",
        "import ipykernel\n",
        "print(\"librosa version:\", librosa.__version__)\n",
        "print(\"matplotlib version:\", matplotlib.__version__)\n",
        "print(\"numpy version:\", np.__version__)\n",
        "print(\"scikit-learn version:\", sklearn.__version__)\n",
        "print(\"tensorflow version:\", tf.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSLTh3V2BLND"
      },
      "source": [
        "### 캐시가 없을 때\n",
        "- 캐시가 있다면 목차의 \"캐시로부터 MFCC 데이터 로드 함수\"를 실행하고 난후 다음 단계로 넘어가주시기 바랍니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EGQIT-TBIaK",
        "outputId": "b19562bd-9f51-4570-aad6-319ee4c8ce77"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading MFCC: 100%|████████████████████████████████████████████████████████████████| 4000/4000 [01:57<00:00, 34.00it/s]\n"
          ]
        }
      ],
      "source": [
        "max_len = 4000\n",
        "X, y = load_mfcc_data(train_audio_path, train_label_path, max_len)\n",
        "X, scaler = standardize(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1LGQ-tkxJRq"
      },
      "outputs": [],
      "source": [
        "test_audio_path = 'test'\n",
        "test_label_path = 'test_label.txt'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJhy6QIvDPI-"
      },
      "source": [
        "### 캐시가 없을 때\n",
        "- 캐시가 있다면 목차의 \"캐시로부터 MFCC 데이터 로드 함수\"를 실행하고 난후 다음 단계로 넘어가주시기 바랍니다.\n",
        "- 캐시를 생성하고 싶다면 목차의 \"데이터 셋 캐시 저장\"을 실행하시기 바립니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EF-GT8ECDLz2",
        "outputId": "ced1d669-636f-4bd8-c657-eefe260fdca4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading MFCC: 100%|████████████████████████████████████████████████████████████████| 2000/2000 [00:51<00:00, 38.73it/s]\n"
          ]
        }
      ],
      "source": [
        "X_test, y_test = load_mfcc_data(test_audio_path, test_label_path, max_len)\n",
        "\n",
        "ns_test = X_test.shape[0]\n",
        "X_test, _ = standardize(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1ppfLQd9u6a"
      },
      "source": [
        "### 데이터 셋 캐시 저장\n",
        "- 사용 예시\n",
        "save_mfcc_cache(X, y, scaler, cache_prefix=\"train\")\n",
        "- 사용 조건\n",
        "  - 목차의 \"캐시가 없을 때\"를 실행하고 난 후 실행하셔야 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivm8u9ibDrn1"
      },
      "source": [
        "#### Train set 캐시 저장 함수\n",
        "- test set을 위한 코드가 아닙니다. train set에만 사용하시기 바랍니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwdKGbzV9yhj",
        "outputId": "9fffaec2-a0b6-4196-af87-5eeb0ae41dd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 학습용 캐시 저장 완료:\n",
            "   - X      → cache/train\\X.npy\n",
            "   - y      → cache/train\\y.npy\n",
            "   - scaler → cache/train\\scaler.npy\n"
          ]
        }
      ],
      "source": [
        "# ──────────── 예시 셀 A ──────────── #\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def save_mfcc_cache_train(X, y, scaler, directory=\"cache/train\"):\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "    X_path      = os.path.join(directory, \"X.npy\")\n",
        "    y_path      = os.path.join(directory, \"y.npy\")\n",
        "    scaler_path = os.path.join(directory, \"scaler.npy\")\n",
        "\n",
        "    np.save(X_path, X)\n",
        "    np.save(y_path, y)\n",
        "    np.save(scaler_path, {'mean': scaler.mean_, 'scale': scaler.scale_})\n",
        "    print(\"✅ 학습용 캐시 저장 완료:\")\n",
        "    print(f\"   - X      → {X_path}\")\n",
        "    print(f\"   - y      → {y_path}\")\n",
        "    print(f\"   - scaler → {scaler_path}\")\n",
        "# 이 셀을 실행하면 “함수만 정의”되고 출력(프린트)은 없음.\n",
        "# ──────────── 셀 A 끝 ──────────── #\n",
        "\n",
        "# ──────────── 예시 셀 B ──────────── #\n",
        "# 위에서 이미 정의한 save_mfcc_cache_train 함수를 \"실제로 호출\"하는 부분\n",
        "save_mfcc_cache_train(X, y, scaler, directory=\"cache/train\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVf2SC0rD6-B"
      },
      "source": [
        "#### Test set 캐시 저장\n",
        "-  test set을 위한 코드입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-B9-jNUf-wq2",
        "outputId": "059ad997-f15b-4291-90ae-ef2cf9f9d108"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 테스트셋 캐시 저장 완료\n"
          ]
        }
      ],
      "source": [
        "os.makedirs(\"cache/test\", exist_ok=True)\n",
        "test_X_path = \"cache/test/X.npy\"\n",
        "test_y_path = \"cache/test/y.npy\"\n",
        "\n",
        "np.save(test_X_path, X_test)\n",
        "np.save(test_y_path, y_test)\n",
        "print(\"✅ 테스트셋 캐시 저장 완료\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApDVnUfa-Sxv"
      },
      "source": [
        "### 캐시로부터 MFCC 데이터 로드 함수\n",
        "- 사용 예시\n",
        "X, y, scaler = load_mfcc_cache(cache_prefix=\"train\")\n",
        "- 사용 조건\n",
        "  - 이후 캐시를 저장하고 난 후는 계속해서 MFCC 데이터 로드 함수를 활용해 이후, 로드할 필요 없이 사용하시면 됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hd7-2qCDEJ2w"
      },
      "source": [
        "#### Train set 캐시 로드 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLWFGJYV-OuG"
      },
      "outputs": [],
      "source": [
        "def load_mfcc_cache_train(directory=\"cache/train\"):\n",
        "    \"\"\"\n",
        "    설명:\n",
        "      - \"cache/train/\" 폴더 아래에 저장된 X.npy, y.npy, scaler.npy 세 파일을 불러와,\n",
        "        표준화된 학습용 데이터 X, 레이블 y, 그리고 복원된 StandardScaler 객체를 반환합니다.\n",
        "      - 파일이 없으면 FileNotFoundError을 발생시킵니다.\n",
        "\n",
        "    매개변수:\n",
        "      directory : str, 캐시가 저장된 학습용 디렉터리 경로 (예: \"cache/train\")\n",
        "\n",
        "    반환값:\n",
        "      X      : np.ndarray, 학습용 입력 데이터\n",
        "      y      : np.ndarray, 학습용 레이블\n",
        "      scaler : sklearn.preprocessing.StandardScaler, 복원된 표준화 객체\n",
        "    \"\"\"\n",
        "    # 1. 파일 경로 구성\n",
        "    X_path      = os.path.join(directory, \"X.npy\")\n",
        "    y_path      = os.path.join(directory, \"y.npy\")\n",
        "    scaler_path = os.path.join(directory, \"scaler.npy\")\n",
        "\n",
        "    # 2. 파일 존재 여부 검사\n",
        "    if not (os.path.exists(X_path) and os.path.exists(y_path) and os.path.exists(scaler_path)):\n",
        "        raise FileNotFoundError(f\"❌ 학습용 캐시 파일이 존재하지 않습니다: {directory}\")\n",
        "\n",
        "    # 3. .npy 파일에서 데이터 로드\n",
        "    X = np.load(X_path)\n",
        "    y = np.load(y_path)\n",
        "    scaler_params = np.load(scaler_path, allow_pickle=True).item()\n",
        "\n",
        "    # 4. StandardScaler 객체로 복원\n",
        "    scaler = StandardScaler()\n",
        "    scaler.mean_  = scaler_params['mean']\n",
        "    scaler.scale_ = scaler_params['scale']\n",
        "\n",
        "    print(f\"✅ 학습용 캐시 불러오기 완료: {directory}\")\n",
        "    return X, y, scaler\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZR7IRs9HENvW"
      },
      "source": [
        "#### test set 캐시 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9tDNtU9A0OR"
      },
      "outputs": [],
      "source": [
        "def load_mfcc_cache_test(directory=\"cache/test\"):\n",
        "    \"\"\"\n",
        "    설명:\n",
        "      - \"cache/test/\" 폴더 아래에 저장된 X.npy, y.npy 두 파일을 불러와\n",
        "        테스트용 입력 X_test와 레이블 y_test를 반환합니다.\n",
        "      - 파일이 없으면 FileNotFoundError을 발생시킵니다.\n",
        "\n",
        "    매개변수:\n",
        "      directory : str, 캐시가 저장된 테스트용 디렉터리 경로 (예: \"cache/test\")\n",
        "\n",
        "    반환값:\n",
        "      X_test : np.ndarray, 테스트용 입력 데이터\n",
        "      y_test : np.ndarray, 테스트용 레이블\n",
        "    \"\"\"\n",
        "    # 1. 파일 경로 구성\n",
        "    X_path = os.path.join(directory, \"X.npy\")\n",
        "    y_path = os.path.join(directory, \"y.npy\")\n",
        "\n",
        "    # 2. 파일 존재 여부 검사\n",
        "    if not (os.path.exists(X_path) and os.path.exists(y_path)):\n",
        "        raise FileNotFoundError(f\"❌ 테스트용 캐시 파일이 존재하지 않습니다: {directory}\")\n",
        "\n",
        "    # 3. .npy 파일에서 데이터 로드\n",
        "    X_test = np.load(X_path)\n",
        "    y_test = np.load(y_path)\n",
        "\n",
        "    print(f\"✅ 테스트용 캐시 불러오기 완료: {directory}\")\n",
        "    return X_test, y_test\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjL9zysWvkmK"
      },
      "source": [
        "## 1. 필요 라이브러러 임포트 및 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6C-2s9DAvMIj"
      },
      "outputs": [],
      "source": [
        "# -------------------------------------------\n",
        "# 1. 라이브러리 설치 및 임포트\n",
        "# -------------------------------------------\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "\n",
        "# 재현성 설정\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3NiFNQjvaBf"
      },
      "source": [
        "## 데이터 로딩 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHEIEEHnvU9N"
      },
      "outputs": [],
      "source": [
        "# -------------------------------------------\n",
        "# 2. 데이터 로딩 함수 정의\n",
        "# -------------------------------------------\n",
        "def load_mfcc_data(audio_path, label_path, max_len=200):\n",
        "    entries = []\n",
        "    with open(label_path, 'r') as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) >= 5:\n",
        "                entries.append((parts[1], parts[-1]))\n",
        "    df = pd.DataFrame(entries, columns=['filename','label'])\n",
        "\n",
        "    X_list, y_list = [], []\n",
        "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Loading MFCC\"):\n",
        "        fp = os.path.join(audio_path, row['filename'])\n",
        "        if not os.path.isfile(fp):\n",
        "            continue\n",
        "        try:\n",
        "            audio, sr = librosa.load(fp, sr=16000)\n",
        "            mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=20).T # 기존에는 13이었음.\n",
        "            if mfcc.shape[0] < max_len:\n",
        "                mfcc = np.pad(mfcc, ((0, max_len-mfcc.shape[0]), (0,0)), mode='constant')\n",
        "            else:\n",
        "                mfcc = mfcc[:max_len]\n",
        "            X_list.append(mfcc)\n",
        "            y_list.append(0 if row['label']=='Real' else 1)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    return np.array(X_list), np.array(y_list)\n",
        "\n",
        "\n",
        "def standardize(X):\n",
        "    ns, nt, nf = X.shape\n",
        "    scaler = StandardScaler().fit(X.reshape(-1, nf))\n",
        "    X_scaled = scaler.transform(X.reshape(-1, nf)).reshape(ns, nt, nf)\n",
        "    return X_scaled, scaler\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9T8gTqbmvq4n"
      },
      "source": [
        "## DNN 모델 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmkqpng0y2m0"
      },
      "outputs": [],
      "source": [
        "def build_dnn_model(\n",
        "    input_shape,\n",
        "    units1=128,         # 첫 번째 Dense 레이어의 유닛 수 (튜닝 대상)\n",
        "    units2=64,          # 두 번째 Dense 레이어의 유닛 수 (튜닝 대상)\n",
        "    dropout1=0.3,       # 첫 번째 Dropout 비율 (튜닝 대상)\n",
        "    dropout2=0.3,       # 두 번째 Dropout 비율 (튜닝 대상)\n",
        "    learning_rate=1e-3  # Adam 학습률 (튜닝 대상)\n",
        "):\n",
        "    \"\"\"\n",
        "    기존 모델 정의 부분을 하이퍼파라미터 인자를 받도록 수정한 함수입니다.\n",
        "      - units1, units2: 각 Dense 레이어의 유닛 개수\n",
        "      - dropout1, dropout2: 각 Dropout 레이어 비율\n",
        "      - learning_rate: Adam 옵티마이저 학습률\n",
        "    \"\"\"\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=input_shape, name=\"input_mfcc\"),\n",
        "        layers.Flatten(name=\"flatten\"),\n",
        "\n",
        "        # 첫 번째 Dense 블록\n",
        "        layers.Dense(units1, activation=None, name=\"dense_1\"),\n",
        "        layers.BatchNormalization(name=\"bn_1\"),\n",
        "        layers.Activation('relu', name=\"act_1\"),\n",
        "        layers.Dropout(dropout1, name=\"dropout_1\"),\n",
        "\n",
        "        # 두 번째 Dense 블록\n",
        "        layers.Dense(units2, activation=None, name=\"dense_2\"),\n",
        "        layers.BatchNormalization(name=\"bn_2\"),\n",
        "        layers.Activation('relu', name=\"act_2\"),\n",
        "        layers.Dropout(dropout2, name=\"dropout_2\"),\n",
        "\n",
        "        # 출력층\n",
        "        layers.Dense(1, activation='sigmoid', name=\"output\")\n",
        "    ])\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttO-tN2lDCZ1",
        "outputId": "cafaeec3-c106-4be7-de93-fc89ced2a588"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-04 11:10:32,682] A new study created in memory with name: no-name-3a4267a9-fe93-4312-99ca-1de6b6a208d7\n",
            "  0%|                                                                                           | 0/30 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 102ms/step - accuracy: 0.8270 - loss: 0.3980 - val_accuracy: 0.9425 - val_loss: 0.1598 - learning_rate: 5.2916e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.9814 - loss: 0.1029 - val_accuracy: 0.9775 - val_loss: 0.0733 - learning_rate: 5.2916e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.9933 - loss: 0.0578 - val_accuracy: 0.9875 - val_loss: 0.0499 - learning_rate: 5.2916e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.9989 - loss: 0.0374 - val_accuracy: 0.9887 - val_loss: 0.0422 - learning_rate: 5.2916e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.9998 - loss: 0.0289 - val_accuracy: 0.9912 - val_loss: 0.0393 - learning_rate: 5.2916e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 0.0218 - val_accuracy: 0.9937 - val_loss: 0.0354 - learning_rate: 5.2916e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 0.0179 - val_accuracy: 0.9925 - val_loss: 0.0347 - learning_rate: 5.2916e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 0.0149 - val_accuracy: 0.9925 - val_loss: 0.0328 - learning_rate: 5.2916e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 0.0125 - val_accuracy: 0.9937 - val_loss: 0.0313 - learning_rate: 5.2916e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - accuracy: 1.0000 - loss: 0.0093 - val_accuracy: 0.9937 - val_loss: 0.0306 - learning_rate: 5.2916e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 0.0089 - val_accuracy: 0.9937 - val_loss: 0.0315 - learning_rate: 5.2916e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 0.0075 - val_accuracy: 0.9937 - val_loss: 0.0300 - learning_rate: 5.2916e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.9937 - val_loss: 0.0299 - learning_rate: 5.2916e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 0.9937 - val_loss: 0.0291 - learning_rate: 5.2916e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 0.9937 - val_loss: 0.0282 - learning_rate: 5.2916e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 103ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.9937 - val_loss: 0.0282 - learning_rate: 5.2916e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.9937 - val_loss: 0.0287 - learning_rate: 5.2916e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.9937 - val_loss: 0.0279 - learning_rate: 5.2916e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.9937 - val_loss: 0.0272 - learning_rate: 5.2916e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.9937 - val_loss: 0.0275 - learning_rate: 5.2916e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9937 - val_loss: 0.0272 - learning_rate: 5.2916e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9937 - val_loss: 0.0270 - learning_rate: 5.2916e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9937 - val_loss: 0.0272 - learning_rate: 5.2916e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9937 - val_loss: 0.0273 - learning_rate: 5.2916e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9937 - val_loss: 0.0275 - learning_rate: 5.2916e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9937 - val_loss: 0.0280 - learning_rate: 5.2916e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9937 - val_loss: 0.0281 - learning_rate: 5.2916e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9937 - val_loss: 0.0284 - learning_rate: 2.6458e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9937 - val_loss: 0.0287 - learning_rate: 2.6458e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9937 - val_loss: 0.0288 - learning_rate: 2.6458e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9937 - val_loss: 0.0291 - learning_rate: 2.6458e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9937 - val_loss: 0.0294 - learning_rate: 2.6458e-04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 0. Best value: 0.99375:   3%|█▌                                             | 1/30 [01:17<37:19, 77.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Trial  0] units1=128, units2=64, dropout1=0.2, dropout2=0.5, lr=5.3e-04, batch_size=128 → val_acc=0.9937\n",
            "\n",
            "[I 2025-06-04 11:11:49,913] Trial 0 finished with value: 0.9937499761581421 and parameters: {'units1': 128, 'units2': 64, 'dropout1': 0.2, 'dropout2': 0.5, 'learning_rate': 0.0005291638976855859, 'batch_size': 128}. Best is trial 0 with value: 0.9937499761581421.\n",
            "Epoch 1/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.8665 - loss: 0.3338 - val_accuracy: 0.9812 - val_loss: 0.0651 - learning_rate: 9.5620e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9891 - loss: 0.0722 - val_accuracy: 0.9925 - val_loss: 0.0395 - learning_rate: 9.5620e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9889 - loss: 0.0418 - val_accuracy: 0.9900 - val_loss: 0.0310 - learning_rate: 9.5620e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9973 - loss: 0.0220 - val_accuracy: 0.9912 - val_loss: 0.0275 - learning_rate: 9.5620e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9953 - loss: 0.0203 - val_accuracy: 0.9925 - val_loss: 0.0339 - learning_rate: 9.5620e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9979 - loss: 0.0117 - val_accuracy: 0.9900 - val_loss: 0.0426 - learning_rate: 9.5620e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9974 - loss: 0.0144 - val_accuracy: 0.9925 - val_loss: 0.0282 - learning_rate: 9.5620e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9959 - loss: 0.0145 - val_accuracy: 0.9912 - val_loss: 0.0323 - learning_rate: 9.5620e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9985 - loss: 0.0071 - val_accuracy: 0.9925 - val_loss: 0.0367 - learning_rate: 9.5620e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9985 - loss: 0.0066 - val_accuracy: 0.9925 - val_loss: 0.0383 - learning_rate: 4.7810e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9992 - loss: 0.0048 - val_accuracy: 0.9925 - val_loss: 0.0338 - learning_rate: 4.7810e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.9998 - loss: 0.0041 - val_accuracy: 0.9925 - val_loss: 0.0364 - learning_rate: 4.7810e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9990 - loss: 0.0043 - val_accuracy: 0.9925 - val_loss: 0.0371 - learning_rate: 4.7810e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9990 - loss: 0.0056 - val_accuracy: 0.9925 - val_loss: 0.0356 - learning_rate: 4.7810e-04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 0. Best value: 0.99375:   7%|███▏                                           | 2/30 [02:03<27:36, 59.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Trial  1] units1=64, units2=64, dropout1=0.5, dropout2=0.2, lr=9.6e-04, batch_size=32 → val_acc=0.9925\n",
            "\n",
            "[I 2025-06-04 11:12:36,432] Trial 1 finished with value: 0.9925000071525574 and parameters: {'units1': 64, 'units2': 64, 'dropout1': 0.5, 'dropout2': 0.2, 'learning_rate': 0.0009562008106773795, 'batch_size': 32}. Best is trial 0 with value: 0.9937499761581421.\n",
            "Epoch 1/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 129ms/step - accuracy: 0.8504 - loss: 0.3300 - val_accuracy: 0.9762 - val_loss: 0.0705 - learning_rate: 2.4373e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 119ms/step - accuracy: 0.9870 - loss: 0.0576 - val_accuracy: 0.9925 - val_loss: 0.0411 - learning_rate: 2.4373e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 119ms/step - accuracy: 0.9956 - loss: 0.0329 - val_accuracy: 0.9912 - val_loss: 0.0385 - learning_rate: 2.4373e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 114ms/step - accuracy: 0.9985 - loss: 0.0192 - val_accuracy: 0.9925 - val_loss: 0.0331 - learning_rate: 2.4373e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 115ms/step - accuracy: 0.9983 - loss: 0.0133 - val_accuracy: 0.9925 - val_loss: 0.0285 - learning_rate: 2.4373e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 108ms/step - accuracy: 0.9997 - loss: 0.0106 - val_accuracy: 0.9912 - val_loss: 0.0315 - learning_rate: 2.4373e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 113ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 0.9925 - val_loss: 0.0317 - learning_rate: 2.4373e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 119ms/step - accuracy: 0.9996 - loss: 0.0062 - val_accuracy: 0.9925 - val_loss: 0.0289 - learning_rate: 2.4373e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 113ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.9925 - val_loss: 0.0297 - learning_rate: 2.4373e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.9925 - val_loss: 0.0295 - learning_rate: 2.4373e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 113ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.9925 - val_loss: 0.0292 - learning_rate: 1.2186e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 111ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9925 - val_loss: 0.0299 - learning_rate: 1.2186e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 108ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9925 - val_loss: 0.0303 - learning_rate: 1.2186e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 110ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9925 - val_loss: 0.0298 - learning_rate: 1.2186e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9925 - val_loss: 0.0307 - learning_rate: 1.2186e-04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 0. Best value: 0.99375:  10%|████▌                                         | 3/30 [05:04<51:35, 114.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Trial  2] units1=384, units2=128, dropout1=0.4, dropout2=0.5, lr=2.4e-04, batch_size=32 → val_acc=0.9925\n",
            "\n",
            "[I 2025-06-04 11:15:37,097] Trial 2 finished with value: 0.9925000071525574 and parameters: {'units1': 384, 'units2': 128, 'dropout1': 0.4, 'dropout2': 0.5, 'learning_rate': 0.0002437266437497274, 'batch_size': 32}. Best is trial 0 with value: 0.9937499761581421.\n",
            "Epoch 1/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 56ms/step - accuracy: 0.9012 - loss: 0.2453 - val_accuracy: 0.9812 - val_loss: 0.0835 - learning_rate: 0.0052\n",
            "Epoch 2/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 63ms/step - accuracy: 0.9851 - loss: 0.0463 - val_accuracy: 0.9850 - val_loss: 0.0506 - learning_rate: 0.0052\n",
            "Epoch 3/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 60ms/step - accuracy: 0.9925 - loss: 0.0239 - val_accuracy: 0.9862 - val_loss: 0.0485 - learning_rate: 0.0052\n",
            "Epoch 4/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - accuracy: 0.9925 - loss: 0.0212 - val_accuracy: 0.9925 - val_loss: 0.0501 - learning_rate: 0.0052\n",
            "Epoch 5/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.9947 - loss: 0.0161 - val_accuracy: 0.9925 - val_loss: 0.0411 - learning_rate: 0.0052\n",
            "Epoch 6/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.9960 - loss: 0.0113 - val_accuracy: 0.9862 - val_loss: 0.0732 - learning_rate: 0.0052\n",
            "Epoch 7/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 0.9900 - loss: 0.0321 - val_accuracy: 0.9862 - val_loss: 0.0500 - learning_rate: 0.0052\n",
            "Epoch 8/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 0.9958 - loss: 0.0131 - val_accuracy: 0.9887 - val_loss: 0.0541 - learning_rate: 0.0052\n",
            "Epoch 9/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 57ms/step - accuracy: 0.9998 - loss: 0.0028 - val_accuracy: 0.9912 - val_loss: 0.0492 - learning_rate: 0.0052\n",
            "Epoch 10/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9912 - val_loss: 0.0519 - learning_rate: 0.0052\n",
            "Epoch 11/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9912 - val_loss: 0.0526 - learning_rate: 0.0026\n",
            "Epoch 12/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 3.5336e-04 - val_accuracy: 0.9912 - val_loss: 0.0545 - learning_rate: 0.0026\n",
            "Epoch 13/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 5.7345e-04 - val_accuracy: 0.9912 - val_loss: 0.0573 - learning_rate: 0.0026\n",
            "Epoch 14/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 3.5010e-04 - val_accuracy: 0.9912 - val_loss: 0.0604 - learning_rate: 0.0026\n",
            "Epoch 15/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 1.6570e-04 - val_accuracy: 0.9912 - val_loss: 0.0611 - learning_rate: 0.0026\n",
            "[Trial  3] units1=192, units2=256, dropout1=0.2, dropout2=0.2, lr=5.2e-03, batch_size=16 → val_acc=0.9912\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 0. Best value: 0.99375:  13%|██████▏                                       | 4/30 [07:58<59:47, 137.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[I 2025-06-04 11:18:30,836] Trial 3 finished with value: 0.9912499785423279 and parameters: {'units1': 192, 'units2': 256, 'dropout1': 0.2, 'dropout2': 0.2, 'learning_rate': 0.005162305305782334, 'batch_size': 16}. Best is trial 0 with value: 0.9937499761581421.\n",
            "Epoch 1/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 139ms/step - accuracy: 0.9065 - loss: 0.2379 - val_accuracy: 0.9812 - val_loss: 0.0805 - learning_rate: 0.0077\n",
            "Epoch 2/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 142ms/step - accuracy: 0.9851 - loss: 0.0367 - val_accuracy: 0.9887 - val_loss: 0.0429 - learning_rate: 0.0077\n",
            "Epoch 3/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 138ms/step - accuracy: 0.9961 - loss: 0.0127 - val_accuracy: 0.9925 - val_loss: 0.0306 - learning_rate: 0.0077\n",
            "Epoch 4/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 141ms/step - accuracy: 0.9941 - loss: 0.0140 - val_accuracy: 0.9875 - val_loss: 0.0441 - learning_rate: 0.0077\n",
            "Epoch 5/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 138ms/step - accuracy: 0.9944 - loss: 0.0186 - val_accuracy: 0.9887 - val_loss: 0.0529 - learning_rate: 0.0077\n",
            "Epoch 6/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 134ms/step - accuracy: 0.9944 - loss: 0.0167 - val_accuracy: 0.9850 - val_loss: 0.0801 - learning_rate: 0.0077\n",
            "Epoch 7/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 145ms/step - accuracy: 0.9987 - loss: 0.0071 - val_accuracy: 0.9912 - val_loss: 0.0451 - learning_rate: 0.0077\n",
            "Epoch 8/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 9.8027e-04 - val_accuracy: 0.9912 - val_loss: 0.0427 - learning_rate: 0.0077\n",
            "Epoch 9/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 5.5688e-04 - val_accuracy: 0.9925 - val_loss: 0.0417 - learning_rate: 0.0039\n",
            "Epoch 10/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 3.3635e-04 - val_accuracy: 0.9912 - val_loss: 0.0405 - learning_rate: 0.0039\n",
            "Epoch 11/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 2.5137e-04 - val_accuracy: 0.9912 - val_loss: 0.0405 - learning_rate: 0.0039\n",
            "Epoch 12/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 3.4624e-04 - val_accuracy: 0.9912 - val_loss: 0.0411 - learning_rate: 0.0039\n",
            "Epoch 13/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 2.3220e-04 - val_accuracy: 0.9912 - val_loss: 0.0420 - learning_rate: 0.0039\n",
            "[Trial  4] units1=512, units2=64, dropout1=0.3, dropout2=0.5, lr=7.7e-03, batch_size=32 → val_acc=0.9912\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 0. Best value: 0.99375:  17%|███████▎                                    | 5/30 [11:04<1:04:44, 155.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[I 2025-06-04 11:21:37,033] Trial 4 finished with value: 0.9912499785423279 and parameters: {'units1': 512, 'units2': 64, 'dropout1': 0.30000000000000004, 'dropout2': 0.5, 'learning_rate': 0.007711788571894636, 'batch_size': 32}. Best is trial 0 with value: 0.9937499761581421.\n",
            "Epoch 1/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 138ms/step - accuracy: 0.8607 - loss: 0.3290 - val_accuracy: 0.9775 - val_loss: 0.0731 - learning_rate: 1.4293e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 139ms/step - accuracy: 0.9909 - loss: 0.0674 - val_accuracy: 0.9937 - val_loss: 0.0430 - learning_rate: 1.4293e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 144ms/step - accuracy: 0.9989 - loss: 0.0400 - val_accuracy: 0.9925 - val_loss: 0.0401 - learning_rate: 1.4293e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 136ms/step - accuracy: 0.9986 - loss: 0.0292 - val_accuracy: 0.9937 - val_loss: 0.0347 - learning_rate: 1.4293e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 140ms/step - accuracy: 0.9994 - loss: 0.0217 - val_accuracy: 0.9925 - val_loss: 0.0342 - learning_rate: 1.4293e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.0175 - val_accuracy: 0.9937 - val_loss: 0.0304 - learning_rate: 1.4293e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 0.0138 - val_accuracy: 0.9937 - val_loss: 0.0294 - learning_rate: 1.4293e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 165ms/step - accuracy: 1.0000 - loss: 0.0122 - val_accuracy: 0.9925 - val_loss: 0.0298 - learning_rate: 1.4293e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 0.0106 - val_accuracy: 0.9937 - val_loss: 0.0280 - learning_rate: 1.4293e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 155ms/step - accuracy: 1.0000 - loss: 0.0086 - val_accuracy: 0.9925 - val_loss: 0.0285 - learning_rate: 1.4293e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0077 - val_accuracy: 0.9937 - val_loss: 0.0283 - learning_rate: 1.4293e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.9937 - val_loss: 0.0289 - learning_rate: 1.4293e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.9925 - val_loss: 0.0290 - learning_rate: 1.4293e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.9937 - val_loss: 0.0283 - learning_rate: 1.4293e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.9925 - val_loss: 0.0284 - learning_rate: 7.1465e-05\n",
            "Epoch 16/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.9937 - val_loss: 0.0279 - learning_rate: 7.1465e-05\n",
            "Epoch 17/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.9937 - val_loss: 0.0282 - learning_rate: 7.1465e-05\n",
            "Epoch 18/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9937 - val_loss: 0.0284 - learning_rate: 7.1465e-05\n",
            "Epoch 19/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.9937 - val_loss: 0.0285 - learning_rate: 7.1465e-05\n",
            "Epoch 20/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9937 - val_loss: 0.0287 - learning_rate: 3.5732e-05\n",
            "Epoch 21/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.9937 - val_loss: 0.0286 - learning_rate: 3.5732e-05\n",
            "Epoch 22/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9937 - val_loss: 0.0283 - learning_rate: 3.5732e-05\n",
            "Epoch 23/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9937 - val_loss: 0.0283 - learning_rate: 3.5732e-05\n",
            "Epoch 24/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9937 - val_loss: 0.0283 - learning_rate: 3.5732e-05\n",
            "Epoch 25/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9937 - val_loss: 0.0284 - learning_rate: 1.7866e-05\n",
            "Epoch 26/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.9937 - val_loss: 0.0283 - learning_rate: 1.7866e-05\n",
            "[Trial  5] units1=512, units2=64, dropout1=0.4, dropout2=0.3, lr=1.4e-04, batch_size=32 → val_acc=0.9937\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 0. Best value: 0.99375:  20%|████████▊                                   | 6/30 [17:24<1:32:46, 231.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[I 2025-06-04 11:27:57,578] Trial 5 finished with value: 0.9937499761581421 and parameters: {'units1': 512, 'units2': 64, 'dropout1': 0.4, 'dropout2': 0.30000000000000004, 'learning_rate': 0.00014292928613626935, 'batch_size': 32}. Best is trial 0 with value: 0.9937499761581421.\n",
            "Epoch 1/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.7643 - loss: 0.4867 - val_accuracy: 0.9413 - val_loss: 0.1770 - learning_rate: 1.5269e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.9816 - loss: 0.1560 - val_accuracy: 0.9775 - val_loss: 0.1117 - learning_rate: 1.5269e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.9913 - loss: 0.1182 - val_accuracy: 0.9875 - val_loss: 0.0922 - learning_rate: 1.5269e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.9958 - loss: 0.0952 - val_accuracy: 0.9887 - val_loss: 0.0848 - learning_rate: 1.5269e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.9978 - loss: 0.0831 - val_accuracy: 0.9925 - val_loss: 0.0771 - learning_rate: 1.5269e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.9989 - loss: 0.0705 - val_accuracy: 0.9912 - val_loss: 0.0735 - learning_rate: 1.5269e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.9991 - loss: 0.0642 - val_accuracy: 0.9912 - val_loss: 0.0703 - learning_rate: 1.5269e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.9997 - loss: 0.0554 - val_accuracy: 0.9912 - val_loss: 0.0666 - learning_rate: 1.5269e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.9996 - loss: 0.0494 - val_accuracy: 0.9925 - val_loss: 0.0614 - learning_rate: 1.5269e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.9999 - loss: 0.0429 - val_accuracy: 0.9925 - val_loss: 0.0603 - learning_rate: 1.5269e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0405 - val_accuracy: 0.9937 - val_loss: 0.0567 - learning_rate: 1.5269e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.0361 - val_accuracy: 0.9937 - val_loss: 0.0530 - learning_rate: 1.5269e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.0338 - val_accuracy: 0.9925 - val_loss: 0.0500 - learning_rate: 1.5269e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0322 - val_accuracy: 0.9925 - val_loss: 0.0479 - learning_rate: 1.5269e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0287 - val_accuracy: 0.9925 - val_loss: 0.0458 - learning_rate: 1.5269e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.0261 - val_accuracy: 0.9925 - val_loss: 0.0436 - learning_rate: 1.5269e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0234 - val_accuracy: 0.9937 - val_loss: 0.0430 - learning_rate: 1.5269e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0221 - val_accuracy: 0.9937 - val_loss: 0.0399 - learning_rate: 1.5269e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.0213 - val_accuracy: 0.9937 - val_loss: 0.0391 - learning_rate: 1.5269e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0189 - val_accuracy: 0.9925 - val_loss: 0.0377 - learning_rate: 1.5269e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.0180 - val_accuracy: 0.9937 - val_loss: 0.0367 - learning_rate: 1.5269e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.0165 - val_accuracy: 0.9937 - val_loss: 0.0360 - learning_rate: 1.5269e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0160 - val_accuracy: 0.9937 - val_loss: 0.0356 - learning_rate: 1.5269e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0157 - val_accuracy: 0.9937 - val_loss: 0.0352 - learning_rate: 1.5269e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0139 - val_accuracy: 0.9925 - val_loss: 0.0352 - learning_rate: 1.5269e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0126 - val_accuracy: 0.9937 - val_loss: 0.0348 - learning_rate: 1.5269e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0124 - val_accuracy: 0.9937 - val_loss: 0.0337 - learning_rate: 1.5269e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.0115 - val_accuracy: 0.9937 - val_loss: 0.0340 - learning_rate: 1.5269e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0117 - val_accuracy: 0.9937 - val_loss: 0.0333 - learning_rate: 1.5269e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0111 - val_accuracy: 0.9937 - val_loss: 0.0328 - learning_rate: 1.5269e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0103 - val_accuracy: 0.9937 - val_loss: 0.0323 - learning_rate: 1.5269e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0097 - val_accuracy: 0.9937 - val_loss: 0.0326 - learning_rate: 1.5269e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0088 - val_accuracy: 0.9937 - val_loss: 0.0312 - learning_rate: 1.5269e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.0091 - val_accuracy: 0.9925 - val_loss: 0.0316 - learning_rate: 1.5269e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.0084 - val_accuracy: 0.9925 - val_loss: 0.0321 - learning_rate: 1.5269e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.0082 - val_accuracy: 0.9937 - val_loss: 0.0319 - learning_rate: 1.5269e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.0075 - val_accuracy: 0.9937 - val_loss: 0.0313 - learning_rate: 1.5269e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 0.9937 - val_loss: 0.0316 - learning_rate: 1.5269e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.9937 - val_loss: 0.0307 - learning_rate: 7.6343e-05\n",
            "Epoch 40/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 0.9937 - val_loss: 0.0306 - learning_rate: 7.6343e-05\n",
            "Epoch 41/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.9937 - val_loss: 0.0305 - learning_rate: 7.6343e-05\n",
            "Epoch 42/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 0.9937 - val_loss: 0.0300 - learning_rate: 7.6343e-05\n",
            "Epoch 43/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 0.9937 - val_loss: 0.0297 - learning_rate: 7.6343e-05\n",
            "Epoch 44/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 0.9937 - val_loss: 0.0300 - learning_rate: 7.6343e-05\n",
            "Epoch 45/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.9937 - val_loss: 0.0300 - learning_rate: 7.6343e-05\n",
            "Epoch 46/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.9937 - val_loss: 0.0301 - learning_rate: 7.6343e-05\n",
            "Epoch 47/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 0.9937 - val_loss: 0.0294 - learning_rate: 7.6343e-05\n",
            "Epoch 48/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.9937 - val_loss: 0.0304 - learning_rate: 7.6343e-05\n",
            "Epoch 49/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.9925 - val_loss: 0.0302 - learning_rate: 7.6343e-05\n",
            "Epoch 50/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.9925 - val_loss: 0.0295 - learning_rate: 7.6343e-05\n",
            "[Trial  6] units1=96, units2=32, dropout1=0.1, dropout2=0.3, lr=1.5e-04, batch_size=64 → val_acc=0.9925\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 0. Best value: 0.99375:  23%|██████████▎                                 | 7/30 [19:14<1:13:33, 191.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-06-04 11:29:47,106] Trial 6 finished with value: 0.9925000071525574 and parameters: {'units1': 96, 'units2': 32, 'dropout1': 0.1, 'dropout2': 0.30000000000000004, 'learning_rate': 0.0001526852461589429, 'batch_size': 64}. Best is trial 0 with value: 0.9937499761581421.\n",
            "Epoch 1/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.7803 - loss: 0.4609 - val_accuracy: 0.9525 - val_loss: 0.1145 - learning_rate: 1.1669e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 117ms/step - accuracy: 0.9921 - loss: 0.1020 - val_accuracy: 0.9862 - val_loss: 0.0598 - learning_rate: 1.1669e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - accuracy: 0.9958 - loss: 0.0641 - val_accuracy: 0.9900 - val_loss: 0.0492 - learning_rate: 1.1669e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - accuracy: 0.9987 - loss: 0.0470 - val_accuracy: 0.9925 - val_loss: 0.0427 - learning_rate: 1.1669e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - accuracy: 0.9995 - loss: 0.0375 - val_accuracy: 0.9937 - val_loss: 0.0419 - learning_rate: 1.1669e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - accuracy: 1.0000 - loss: 0.0304 - val_accuracy: 0.9937 - val_loss: 0.0408 - learning_rate: 1.1669e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 0.0260 - val_accuracy: 0.9937 - val_loss: 0.0402 - learning_rate: 1.1669e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.0225 - val_accuracy: 0.9937 - val_loss: 0.0391 - learning_rate: 1.1669e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.0202 - val_accuracy: 0.9937 - val_loss: 0.0391 - learning_rate: 1.1669e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 0.0179 - val_accuracy: 0.9937 - val_loss: 0.0389 - learning_rate: 1.1669e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 0.0163 - val_accuracy: 0.9937 - val_loss: 0.0388 - learning_rate: 1.1669e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - accuracy: 1.0000 - loss: 0.0143 - val_accuracy: 0.9937 - val_loss: 0.0377 - learning_rate: 1.1669e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.0133 - val_accuracy: 0.9937 - val_loss: 0.0372 - learning_rate: 1.1669e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 0.0118 - val_accuracy: 0.9937 - val_loss: 0.0374 - learning_rate: 1.1669e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - accuracy: 1.0000 - loss: 0.0112 - val_accuracy: 0.9937 - val_loss: 0.0362 - learning_rate: 1.1669e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - accuracy: 1.0000 - loss: 0.0101 - val_accuracy: 0.9937 - val_loss: 0.0361 - learning_rate: 1.1669e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - accuracy: 1.0000 - loss: 0.0098 - val_accuracy: 0.9937 - val_loss: 0.0357 - learning_rate: 1.1669e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 0.0091 - val_accuracy: 0.9937 - val_loss: 0.0346 - learning_rate: 1.1669e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 0.0087 - val_accuracy: 0.9937 - val_loss: 0.0343 - learning_rate: 1.1669e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 0.0079 - val_accuracy: 0.9937 - val_loss: 0.0338 - learning_rate: 1.1669e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.9937 - val_loss: 0.0332 - learning_rate: 1.1669e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.9937 - val_loss: 0.0330 - learning_rate: 1.1669e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.9937 - val_loss: 0.0333 - learning_rate: 1.1669e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 0.0064 - val_accuracy: 0.9937 - val_loss: 0.0326 - learning_rate: 1.1669e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.9937 - val_loss: 0.0320 - learning_rate: 1.1669e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.9937 - val_loss: 0.0315 - learning_rate: 1.1669e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.9937 - val_loss: 0.0315 - learning_rate: 1.1669e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.9937 - val_loss: 0.0317 - learning_rate: 1.1669e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.9937 - val_loss: 0.0312 - learning_rate: 1.1669e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.9937 - val_loss: 0.0312 - learning_rate: 1.1669e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.9937 - val_loss: 0.0307 - learning_rate: 1.1669e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.9937 - val_loss: 0.0304 - learning_rate: 1.1669e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.9937 - val_loss: 0.0302 - learning_rate: 1.1669e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9937 - val_loss: 0.0302 - learning_rate: 1.1669e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9937 - val_loss: 0.0304 - learning_rate: 1.1669e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9937 - val_loss: 0.0303 - learning_rate: 1.1669e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9937 - val_loss: 0.0297 - learning_rate: 1.1669e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.9937 - val_loss: 0.0293 - learning_rate: 1.1669e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9937 - val_loss: 0.0293 - learning_rate: 1.1669e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9937 - val_loss: 0.0294 - learning_rate: 1.1669e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9937 - val_loss: 0.0296 - learning_rate: 1.1669e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.9937 - val_loss: 0.0297 - learning_rate: 1.1669e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.9937 - val_loss: 0.0299 - learning_rate: 1.1669e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9937 - val_loss: 0.0298 - learning_rate: 5.8347e-05\n",
            "Epoch 45/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.9937 - val_loss: 0.0297 - learning_rate: 5.8347e-05\n",
            "Epoch 46/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9937 - val_loss: 0.0298 - learning_rate: 5.8347e-05\n",
            "Epoch 47/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9937 - val_loss: 0.0296 - learning_rate: 5.8347e-05\n",
            "Epoch 48/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9937 - val_loss: 0.0296 - learning_rate: 5.8347e-05\n",
            "Epoch 49/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9937 - val_loss: 0.0295 - learning_rate: 2.9174e-05\n",
            "[Trial  7] units1=256, units2=64, dropout1=0.3, dropout2=0.1, lr=1.2e-04, batch_size=128 → val_acc=0.9937\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 0. Best value: 0.99375:  27%|███████████▋                                | 8/30 [22:08<1:08:16, 186.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-06-04 11:32:41,146] Trial 7 finished with value: 0.9937499761581421 and parameters: {'units1': 256, 'units2': 64, 'dropout1': 0.30000000000000004, 'dropout2': 0.1, 'learning_rate': 0.00011669446016593203, 'batch_size': 128}. Best is trial 0 with value: 0.9937499761581421.\n",
            "Epoch 1/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.8315 - loss: 0.3635 - val_accuracy: 0.9675 - val_loss: 0.0924 - learning_rate: 2.9301e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 136ms/step - accuracy: 0.9908 - loss: 0.0522 - val_accuracy: 0.9887 - val_loss: 0.0491 - learning_rate: 2.9301e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 136ms/step - accuracy: 0.9982 - loss: 0.0257 - val_accuracy: 0.9912 - val_loss: 0.0383 - learning_rate: 2.9301e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 138ms/step - accuracy: 0.9974 - loss: 0.0220 - val_accuracy: 0.9912 - val_loss: 0.0346 - learning_rate: 2.9301e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 132ms/step - accuracy: 0.9981 - loss: 0.0150 - val_accuracy: 0.9937 - val_loss: 0.0312 - learning_rate: 2.9301e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0083 - val_accuracy: 0.9937 - val_loss: 0.0301 - learning_rate: 2.9301e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 132ms/step - accuracy: 0.9997 - loss: 0.0074 - val_accuracy: 0.9937 - val_loss: 0.0299 - learning_rate: 2.9301e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 125ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.9925 - val_loss: 0.0300 - learning_rate: 2.9301e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.9937 - val_loss: 0.0283 - learning_rate: 2.9301e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9937 - val_loss: 0.0293 - learning_rate: 2.9301e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.9937 - val_loss: 0.0283 - learning_rate: 2.9301e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9937 - val_loss: 0.0279 - learning_rate: 2.9301e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9937 - val_loss: 0.0285 - learning_rate: 2.9301e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9937 - val_loss: 0.0275 - learning_rate: 2.9301e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9937 - val_loss: 0.0268 - learning_rate: 2.9301e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 127ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9937 - val_loss: 0.0271 - learning_rate: 2.9301e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9937 - val_loss: 0.0277 - learning_rate: 2.9301e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 129ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9937 - val_loss: 0.0277 - learning_rate: 2.9301e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9937 - val_loss: 0.0281 - learning_rate: 2.9301e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9937 - val_loss: 0.0290 - learning_rate: 2.9301e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9937 - val_loss: 0.0280 - learning_rate: 1.4651e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 125ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9937 - val_loss: 0.0279 - learning_rate: 1.4651e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9937 - val_loss: 0.0280 - learning_rate: 1.4651e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 9.9427e-04 - val_accuracy: 0.9937 - val_loss: 0.0281 - learning_rate: 1.4651e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 9.8726e-04 - val_accuracy: 0.9937 - val_loss: 0.0284 - learning_rate: 1.4651e-04\n",
            "[Trial  8] units1=384, units2=128, dropout1=0.5, dropout2=0.4, lr=2.9e-04, batch_size=64 → val_acc=0.9937\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 0. Best value: 0.99375:  30%|█████████████▏                              | 9/30 [25:04<1:04:01, 182.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[I 2025-06-04 11:35:36,856] Trial 8 finished with value: 0.9937499761581421 and parameters: {'units1': 384, 'units2': 128, 'dropout1': 0.5, 'dropout2': 0.4, 'learning_rate': 0.00029301153767192416, 'batch_size': 64}. Best is trial 0 with value: 0.9937499761581421.\n",
            "Epoch 1/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 135ms/step - accuracy: 0.9062 - loss: 0.2729 - val_accuracy: 0.9850 - val_loss: 0.0509 - learning_rate: 0.0014\n",
            "Epoch 2/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 128ms/step - accuracy: 0.9854 - loss: 0.0638 - val_accuracy: 0.9912 - val_loss: 0.0375 - learning_rate: 0.0014\n",
            "Epoch 3/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 128ms/step - accuracy: 0.9963 - loss: 0.0242 - val_accuracy: 0.9912 - val_loss: 0.0347 - learning_rate: 0.0014\n",
            "Epoch 4/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 127ms/step - accuracy: 0.9963 - loss: 0.0189 - val_accuracy: 0.9912 - val_loss: 0.0315 - learning_rate: 0.0014\n",
            "Epoch 5/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 128ms/step - accuracy: 0.9964 - loss: 0.0128 - val_accuracy: 0.9862 - val_loss: 0.0759 - learning_rate: 0.0014\n",
            "Epoch 6/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 129ms/step - accuracy: 0.9922 - loss: 0.0285 - val_accuracy: 0.9862 - val_loss: 0.0481 - learning_rate: 0.0014\n",
            "Epoch 7/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 129ms/step - accuracy: 1.0000 - loss: 0.0074 - val_accuracy: 0.9912 - val_loss: 0.0377 - learning_rate: 0.0014\n",
            "Epoch 8/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 129ms/step - accuracy: 0.9990 - loss: 0.0061 - val_accuracy: 0.9862 - val_loss: 0.0618 - learning_rate: 0.0014\n",
            "Epoch 9/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 129ms/step - accuracy: 0.9978 - loss: 0.0085 - val_accuracy: 0.9887 - val_loss: 0.0357 - learning_rate: 0.0014\n",
            "Epoch 10/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 126ms/step - accuracy: 0.9953 - loss: 0.0109 - val_accuracy: 0.9912 - val_loss: 0.0344 - learning_rate: 6.8272e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 132ms/step - accuracy: 0.9991 - loss: 0.0030 - val_accuracy: 0.9937 - val_loss: 0.0297 - learning_rate: 6.8272e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9937 - val_loss: 0.0317 - learning_rate: 6.8272e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9937 - val_loss: 0.0328 - learning_rate: 6.8272e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 132ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9937 - val_loss: 0.0336 - learning_rate: 6.8272e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 128ms/step - accuracy: 1.0000 - loss: 6.7297e-04 - val_accuracy: 0.9937 - val_loss: 0.0356 - learning_rate: 6.8272e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9925 - val_loss: 0.0362 - learning_rate: 6.8272e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 128ms/step - accuracy: 1.0000 - loss: 5.4859e-04 - val_accuracy: 0.9937 - val_loss: 0.0367 - learning_rate: 3.4136e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 6.3861e-04 - val_accuracy: 0.9937 - val_loss: 0.0370 - learning_rate: 3.4136e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 5.9142e-04 - val_accuracy: 0.9937 - val_loss: 0.0368 - learning_rate: 3.4136e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 134ms/step - accuracy: 1.0000 - loss: 4.7595e-04 - val_accuracy: 0.9937 - val_loss: 0.0373 - learning_rate: 3.4136e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 3.9517e-04 - val_accuracy: 0.9937 - val_loss: 0.0377 - learning_rate: 3.4136e-04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 0. Best value: 0.99375:  33%|██████████████▎                            | 10/30 [34:15<1:38:51, 296.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Trial  9] units1=512, units2=32, dropout1=0.1, dropout2=0.4, lr=1.4e-03, batch_size=16 → val_acc=0.9937\n",
            "\n",
            "[I 2025-06-04 11:44:47,928] Trial 9 finished with value: 0.9937499761581421 and parameters: {'units1': 512, 'units2': 32, 'dropout1': 0.1, 'dropout2': 0.4, 'learning_rate': 0.001365447404836599, 'batch_size': 16}. Best is trial 0 with value: 0.9937499761581421.\n",
            "Epoch 1/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - accuracy: 0.8461 - loss: 0.3510 - val_accuracy: 0.9600 - val_loss: 0.1166 - learning_rate: 7.3714e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.9940 - loss: 0.0309 - val_accuracy: 0.9862 - val_loss: 0.0600 - learning_rate: 7.3714e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.9986 - loss: 0.0117 - val_accuracy: 0.9900 - val_loss: 0.0459 - learning_rate: 7.3714e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.9887 - val_loss: 0.0436 - learning_rate: 7.3714e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.9912 - val_loss: 0.0414 - learning_rate: 7.3714e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9912 - val_loss: 0.0400 - learning_rate: 7.3714e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9912 - val_loss: 0.0393 - learning_rate: 7.3714e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9925 - val_loss: 0.0368 - learning_rate: 7.3714e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9925 - val_loss: 0.0375 - learning_rate: 7.3714e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9912 - val_loss: 0.0379 - learning_rate: 7.3714e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9912 - val_loss: 0.0383 - learning_rate: 7.3714e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9912 - val_loss: 0.0374 - learning_rate: 7.3714e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 9.5615e-04 - val_accuracy: 0.9912 - val_loss: 0.0390 - learning_rate: 7.3714e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 8.7532e-04 - val_accuracy: 0.9912 - val_loss: 0.0394 - learning_rate: 3.6857e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 8.1440e-04 - val_accuracy: 0.9912 - val_loss: 0.0395 - learning_rate: 3.6857e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 7.4718e-04 - val_accuracy: 0.9912 - val_loss: 0.0390 - learning_rate: 3.6857e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - accuracy: 1.0000 - loss: 6.7467e-04 - val_accuracy: 0.9912 - val_loss: 0.0385 - learning_rate: 3.6857e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 6.0597e-04 - val_accuracy: 0.9912 - val_loss: 0.0388 - learning_rate: 3.6857e-04\n",
            "[Trial 10] units1=128, units2=256, dropout1=0.2, dropout2=0.4, lr=7.4e-04, batch_size=128 → val_acc=0.9912\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 0. Best value: 0.99375:  37%|███████████████▊                           | 11/30 [34:52<1:08:46, 217.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-06-04 11:45:25,065] Trial 10 finished with value: 0.9912499785423279 and parameters: {'units1': 128, 'units2': 256, 'dropout1': 0.2, 'dropout2': 0.4, 'learning_rate': 0.0007371429198732381, 'batch_size': 128}. Best is trial 0 with value: 0.9937499761581421.\n",
            "Epoch 1/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.7936 - loss: 0.4338 - val_accuracy: 0.9475 - val_loss: 0.1431 - learning_rate: 4.2448e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.9893 - loss: 0.1173 - val_accuracy: 0.9737 - val_loss: 0.0817 - learning_rate: 4.2448e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.9947 - loss: 0.0666 - val_accuracy: 0.9875 - val_loss: 0.0523 - learning_rate: 4.2448e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9970 - loss: 0.0484 - val_accuracy: 0.9912 - val_loss: 0.0409 - learning_rate: 4.2448e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.9988 - loss: 0.0346 - val_accuracy: 0.9912 - val_loss: 0.0380 - learning_rate: 4.2448e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.9997 - loss: 0.0262 - val_accuracy: 0.9925 - val_loss: 0.0362 - learning_rate: 4.2448e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.9997 - loss: 0.0208 - val_accuracy: 0.9925 - val_loss: 0.0350 - learning_rate: 4.2448e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0166 - val_accuracy: 0.9937 - val_loss: 0.0323 - learning_rate: 4.2448e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 0.0145 - val_accuracy: 0.9937 - val_loss: 0.0313 - learning_rate: 4.2448e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.0121 - val_accuracy: 0.9937 - val_loss: 0.0305 - learning_rate: 4.2448e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.0106 - val_accuracy: 0.9937 - val_loss: 0.0294 - learning_rate: 4.2448e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 0.0092 - val_accuracy: 0.9937 - val_loss: 0.0296 - learning_rate: 4.2448e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 0.0082 - val_accuracy: 0.9925 - val_loss: 0.0300 - learning_rate: 4.2448e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.9937 - val_loss: 0.0283 - learning_rate: 4.2448e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.9937 - val_loss: 0.0274 - learning_rate: 4.2448e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.9937 - val_loss: 0.0276 - learning_rate: 4.2448e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.9937 - val_loss: 0.0275 - learning_rate: 4.2448e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.9937 - val_loss: 0.0274 - learning_rate: 4.2448e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.9937 - val_loss: 0.0273 - learning_rate: 4.2448e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9937 - val_loss: 0.0266 - learning_rate: 4.2448e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9937 - val_loss: 0.0260 - learning_rate: 4.2448e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9937 - val_loss: 0.0264 - learning_rate: 4.2448e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9937 - val_loss: 0.0266 - learning_rate: 4.2448e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.9937 - val_loss: 0.0271 - learning_rate: 4.2448e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9937 - val_loss: 0.0274 - learning_rate: 4.2448e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9937 - val_loss: 0.0270 - learning_rate: 4.2448e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9937 - val_loss: 0.0268 - learning_rate: 2.1224e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9937 - val_loss: 0.0271 - learning_rate: 2.1224e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9937 - val_loss: 0.0276 - learning_rate: 2.1224e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9925 - val_loss: 0.0278 - learning_rate: 2.1224e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9937 - val_loss: 0.0275 - learning_rate: 2.1224e-04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 0. Best value: 0.99375:  40%|██████████████████                           | 12/30 [35:52<50:51, 169.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Trial 11] units1=128, units2=64, dropout1=0.4, dropout2=0.3, lr=4.2e-04, batch_size=128 → val_acc=0.9937\n",
            "\n",
            "[I 2025-06-04 11:46:25,656] Trial 11 finished with value: 0.9937499761581421 and parameters: {'units1': 128, 'units2': 64, 'dropout1': 0.4, 'dropout2': 0.30000000000000004, 'learning_rate': 0.0004244840114428352, 'batch_size': 128}. Best is trial 0 with value: 0.9937499761581421.\n",
            "Epoch 1/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.8790 - loss: 0.2864 - val_accuracy: 0.9750 - val_loss: 0.0819 - learning_rate: 0.0019\n",
            "Epoch 2/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.9905 - loss: 0.0467 - val_accuracy: 0.9887 - val_loss: 0.0421 - learning_rate: 0.0019\n",
            "Epoch 3/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.9967 - loss: 0.0210 - val_accuracy: 0.9900 - val_loss: 0.0319 - learning_rate: 0.0019\n",
            "Epoch 4/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.9991 - loss: 0.0085 - val_accuracy: 0.9900 - val_loss: 0.0317 - learning_rate: 0.0019\n",
            "Epoch 5/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.9995 - loss: 0.0052 - val_accuracy: 0.9925 - val_loss: 0.0314 - learning_rate: 0.0019\n",
            "Epoch 6/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.9996 - loss: 0.0040 - val_accuracy: 0.9912 - val_loss: 0.0287 - learning_rate: 0.0019\n",
            "Epoch 7/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.9999 - loss: 0.0026 - val_accuracy: 0.9912 - val_loss: 0.0315 - learning_rate: 0.0019\n",
            "Epoch 8/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.9966 - loss: 0.0072 - val_accuracy: 0.9850 - val_loss: 0.1056 - learning_rate: 0.0019\n",
            "Epoch 9/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - accuracy: 0.9973 - loss: 0.0084 - val_accuracy: 0.9887 - val_loss: 0.0601 - learning_rate: 0.0019\n",
            "Epoch 10/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.9992 - loss: 0.0053 - val_accuracy: 0.9887 - val_loss: 0.0425 - learning_rate: 0.0019\n",
            "Epoch 11/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9887 - val_loss: 0.0502 - learning_rate: 0.0019\n",
            "Epoch 12/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9900 - val_loss: 0.0522 - learning_rate: 9.4907e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 9.7254e-04 - val_accuracy: 0.9900 - val_loss: 0.0525 - learning_rate: 9.4907e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.1704e-04 - val_accuracy: 0.9900 - val_loss: 0.0512 - learning_rate: 9.4907e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 6.2243e-04 - val_accuracy: 0.9900 - val_loss: 0.0513 - learning_rate: 9.4907e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.6545e-04 - val_accuracy: 0.9900 - val_loss: 0.0522 - learning_rate: 9.4907e-04\n",
            "[Trial 12] units1=128, units2=64, dropout1=0.2, dropout2=0.5, lr=1.9e-03, batch_size=32 → val_acc=0.9900\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 0. Best value: 0.99375:  43%|███████████████████▌                         | 13/30 [37:06<39:46, 140.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-06-04 11:47:38,947] Trial 12 finished with value: 0.9900000095367432 and parameters: {'units1': 128, 'units2': 64, 'dropout1': 0.2, 'dropout2': 0.5, 'learning_rate': 0.0018981324482034887, 'batch_size': 32}. Best is trial 0 with value: 0.9937499761581421.\n",
            "Epoch 1/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 258ms/step - accuracy: 0.8674 - loss: 0.2964 - val_accuracy: 0.9388 - val_loss: 0.2525 - learning_rate: 4.9075e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - accuracy: 0.9970 - loss: 0.0504 - val_accuracy: 0.9825 - val_loss: 0.0834 - learning_rate: 4.9075e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - accuracy: 0.9992 - loss: 0.0282 - val_accuracy: 0.9875 - val_loss: 0.0558 - learning_rate: 4.9075e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 238ms/step - accuracy: 0.9997 - loss: 0.0193 - val_accuracy: 0.9912 - val_loss: 0.0427 - learning_rate: 4.9075e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - accuracy: 1.0000 - loss: 0.0140 - val_accuracy: 0.9925 - val_loss: 0.0387 - learning_rate: 4.9075e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 247ms/step - accuracy: 1.0000 - loss: 0.0108 - val_accuracy: 0.9925 - val_loss: 0.0346 - learning_rate: 4.9075e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 234ms/step - accuracy: 1.0000 - loss: 0.0087 - val_accuracy: 0.9937 - val_loss: 0.0330 - learning_rate: 4.9075e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 226ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.9937 - val_loss: 0.0322 - learning_rate: 4.9075e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 222ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.9937 - val_loss: 0.0309 - learning_rate: 4.9075e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 249ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.9937 - val_loss: 0.0303 - learning_rate: 4.9075e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.9937 - val_loss: 0.0288 - learning_rate: 4.9075e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 220ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.9937 - val_loss: 0.0282 - learning_rate: 4.9075e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9937 - val_loss: 0.0281 - learning_rate: 4.9075e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 274ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9937 - val_loss: 0.0278 - learning_rate: 4.9075e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 254ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9937 - val_loss: 0.0274 - learning_rate: 4.9075e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 246ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9937 - val_loss: 0.0273 - learning_rate: 4.9075e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 220ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9937 - val_loss: 0.0273 - learning_rate: 4.9075e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 237ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9937 - val_loss: 0.0273 - learning_rate: 4.9075e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 212ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9937 - val_loss: 0.0267 - learning_rate: 4.9075e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 233ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9937 - val_loss: 0.0266 - learning_rate: 4.9075e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9925 - val_loss: 0.0268 - learning_rate: 4.9075e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 257ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9925 - val_loss: 0.0266 - learning_rate: 4.9075e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 254ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9937 - val_loss: 0.0263 - learning_rate: 4.9075e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9937 - val_loss: 0.0264 - learning_rate: 4.9075e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9937 - val_loss: 0.0264 - learning_rate: 4.9075e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 247ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9937 - val_loss: 0.0262 - learning_rate: 4.9075e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 223ms/step - accuracy: 1.0000 - loss: 9.7151e-04 - val_accuracy: 0.9937 - val_loss: 0.0262 - learning_rate: 4.9075e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 222ms/step - accuracy: 1.0000 - loss: 8.8113e-04 - val_accuracy: 0.9937 - val_loss: 0.0264 - learning_rate: 4.9075e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 236ms/step - accuracy: 1.0000 - loss: 8.2635e-04 - val_accuracy: 0.9937 - val_loss: 0.0267 - learning_rate: 4.9075e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 249ms/step - accuracy: 1.0000 - loss: 7.9611e-04 - val_accuracy: 0.9937 - val_loss: 0.0267 - learning_rate: 4.9075e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 221ms/step - accuracy: 1.0000 - loss: 7.4138e-04 - val_accuracy: 0.9937 - val_loss: 0.0266 - learning_rate: 4.9075e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 216ms/step - accuracy: 1.0000 - loss: 6.7169e-04 - val_accuracy: 0.9937 - val_loss: 0.0266 - learning_rate: 2.4537e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 222ms/step - accuracy: 1.0000 - loss: 6.6435e-04 - val_accuracy: 0.9937 - val_loss: 0.0267 - learning_rate: 2.4537e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 6.5689e-04 - val_accuracy: 0.9937 - val_loss: 0.0268 - learning_rate: 2.4537e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 234ms/step - accuracy: 1.0000 - loss: 6.4190e-04 - val_accuracy: 0.9937 - val_loss: 0.0269 - learning_rate: 2.4537e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 243ms/step - accuracy: 1.0000 - loss: 6.3800e-04 - val_accuracy: 0.9937 - val_loss: 0.0271 - learning_rate: 2.4537e-04\n",
            "[Trial 13] units1=512, units2=64, dropout1=0.4, dropout2=0.1, lr=4.9e-04, batch_size=128 → val_acc=0.9937\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 0. Best value: 0.99375:  47%|█████████████████████                        | 14/30 [40:44<43:40, 163.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-06-04 11:51:16,820] Trial 13 finished with value: 0.9937499761581421 and parameters: {'units1': 512, 'units2': 64, 'dropout1': 0.4, 'dropout2': 0.1, 'learning_rate': 0.0004907470925465368, 'batch_size': 128}. Best is trial 0 with value: 0.9937499761581421.\n",
            "Epoch 1/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 39ms/step - accuracy: 0.9022 - loss: 0.2498 - val_accuracy: 0.9825 - val_loss: 0.0654 - learning_rate: 0.0026\n",
            "Epoch 2/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9897 - loss: 0.0414 - val_accuracy: 0.9912 - val_loss: 0.0359 - learning_rate: 0.0026\n",
            "Epoch 3/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9977 - loss: 0.0121 - val_accuracy: 0.9912 - val_loss: 0.0372 - learning_rate: 0.0026\n",
            "Epoch 4/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9974 - loss: 0.0102 - val_accuracy: 0.9912 - val_loss: 0.0379 - learning_rate: 0.0026\n",
            "Epoch 5/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9992 - loss: 0.0044 - val_accuracy: 0.9912 - val_loss: 0.0386 - learning_rate: 0.0026\n",
            "Epoch 6/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.9996 - loss: 0.0032 - val_accuracy: 0.9887 - val_loss: 0.0433 - learning_rate: 0.0026\n",
            "Epoch 7/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9989 - loss: 0.0048 - val_accuracy: 0.9887 - val_loss: 0.0606 - learning_rate: 0.0026\n",
            "Epoch 8/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9981 - loss: 0.0076 - val_accuracy: 0.9900 - val_loss: 0.0421 - learning_rate: 0.0013\n",
            "Epoch 9/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9983 - loss: 0.0048 - val_accuracy: 0.9912 - val_loss: 0.0455 - learning_rate: 0.0013\n",
            "Epoch 10/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9900 - val_loss: 0.0481 - learning_rate: 0.0013\n",
            "Epoch 11/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9983 - loss: 0.0035 - val_accuracy: 0.9912 - val_loss: 0.0433 - learning_rate: 0.0013\n",
            "Epoch 12/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9992 - loss: 0.0017 - val_accuracy: 0.9900 - val_loss: 0.0398 - learning_rate: 0.0013\n",
            "[Trial 14] units1=96, units2=64, dropout1=0.3, dropout2=0.2, lr=2.6e-03, batch_size=32 → val_acc=0.9900\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 0. Best value: 0.99375:  50%|██████████████████████▌                      | 15/30 [41:33<32:20, 129.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-06-04 11:52:06,475] Trial 14 finished with value: 0.9900000095367432 and parameters: {'units1': 96, 'units2': 64, 'dropout1': 0.30000000000000004, 'dropout2': 0.2, 'learning_rate': 0.0026126191108000385, 'batch_size': 32}. Best is trial 0 with value: 0.9937499761581421.\n",
            "Epoch 1/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - accuracy: 0.7853 - loss: 0.4528 - val_accuracy: 0.9312 - val_loss: 0.1496 - learning_rate: 1.9023e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - accuracy: 0.9881 - loss: 0.1141 - val_accuracy: 0.9762 - val_loss: 0.0700 - learning_rate: 1.9023e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - accuracy: 0.9977 - loss: 0.0688 - val_accuracy: 0.9900 - val_loss: 0.0515 - learning_rate: 1.9023e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - accuracy: 0.9983 - loss: 0.0538 - val_accuracy: 0.9925 - val_loss: 0.0449 - learning_rate: 1.9023e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 144ms/step - accuracy: 0.9986 - loss: 0.0435 - val_accuracy: 0.9925 - val_loss: 0.0416 - learning_rate: 1.9023e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - accuracy: 0.9992 - loss: 0.0368 - val_accuracy: 0.9925 - val_loss: 0.0394 - learning_rate: 1.9023e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 0.0317 - val_accuracy: 0.9925 - val_loss: 0.0387 - learning_rate: 1.9023e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 0.0275 - val_accuracy: 0.9937 - val_loss: 0.0387 - learning_rate: 1.9023e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - accuracy: 1.0000 - loss: 0.0253 - val_accuracy: 0.9925 - val_loss: 0.0384 - learning_rate: 1.9023e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 0.0215 - val_accuracy: 0.9925 - val_loss: 0.0375 - learning_rate: 1.9023e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - accuracy: 1.0000 - loss: 0.0197 - val_accuracy: 0.9925 - val_loss: 0.0371 - learning_rate: 1.9023e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - accuracy: 1.0000 - loss: 0.0176 - val_accuracy: 0.9925 - val_loss: 0.0362 - learning_rate: 1.9023e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 0.0156 - val_accuracy: 0.9925 - val_loss: 0.0354 - learning_rate: 1.9023e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 0.0146 - val_accuracy: 0.9925 - val_loss: 0.0346 - learning_rate: 1.9023e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - accuracy: 1.0000 - loss: 0.0137 - val_accuracy: 0.9925 - val_loss: 0.0341 - learning_rate: 1.9023e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 0.0119 - val_accuracy: 0.9925 - val_loss: 0.0335 - learning_rate: 1.9023e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - accuracy: 1.0000 - loss: 0.0114 - val_accuracy: 0.9925 - val_loss: 0.0326 - learning_rate: 1.9023e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 0.0106 - val_accuracy: 0.9937 - val_loss: 0.0326 - learning_rate: 1.9023e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 0.0103 - val_accuracy: 0.9925 - val_loss: 0.0323 - learning_rate: 1.9023e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 0.0089 - val_accuracy: 0.9925 - val_loss: 0.0324 - learning_rate: 1.9023e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 167ms/step - accuracy: 1.0000 - loss: 0.0082 - val_accuracy: 0.9925 - val_loss: 0.0320 - learning_rate: 1.9023e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 170ms/step - accuracy: 1.0000 - loss: 0.0079 - val_accuracy: 0.9925 - val_loss: 0.0311 - learning_rate: 1.9023e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 0.0075 - val_accuracy: 0.9925 - val_loss: 0.0313 - learning_rate: 1.9023e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.9925 - val_loss: 0.0308 - learning_rate: 1.9023e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.9937 - val_loss: 0.0302 - learning_rate: 1.9023e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.9937 - val_loss: 0.0303 - learning_rate: 1.9023e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.9937 - val_loss: 0.0302 - learning_rate: 1.9023e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.9937 - val_loss: 0.0297 - learning_rate: 1.9023e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.9937 - val_loss: 0.0291 - learning_rate: 1.9023e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.9937 - val_loss: 0.0298 - learning_rate: 1.9023e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.9925 - val_loss: 0.0298 - learning_rate: 1.9023e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.9925 - val_loss: 0.0296 - learning_rate: 1.9023e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.9937 - val_loss: 0.0294 - learning_rate: 1.9023e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.9937 - val_loss: 0.0292 - learning_rate: 1.9023e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.9937 - val_loss: 0.0291 - learning_rate: 9.5115e-05\n",
            "Epoch 36/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.9937 - val_loss: 0.0292 - learning_rate: 9.5115e-05\n",
            "Epoch 37/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9937 - val_loss: 0.0292 - learning_rate: 9.5115e-05\n",
            "Epoch 38/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9937 - val_loss: 0.0292 - learning_rate: 9.5115e-05\n",
            "Epoch 39/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 129ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9937 - val_loss: 0.0292 - learning_rate: 9.5115e-05\n",
            "[Trial 15] units1=256, units2=64, dropout1=0.2, dropout2=0.4, lr=1.9e-04, batch_size=128 → val_acc=0.9937\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 0. Best value: 0.99375:  53%|████████████████████████                     | 16/30 [43:58<31:16, 134.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[I 2025-06-04 11:54:31,418] Trial 15 finished with value: 0.9937499761581421 and parameters: {'units1': 256, 'units2': 64, 'dropout1': 0.2, 'dropout2': 0.4, 'learning_rate': 0.0001902293320764631, 'batch_size': 128}. Best is trial 0 with value: 0.9937499761581421.\n",
            "Epoch 1/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 55ms/step - accuracy: 0.8235 - loss: 0.3814 - val_accuracy: 0.9862 - val_loss: 0.0690 - learning_rate: 1.1111e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.9800 - loss: 0.1019 - val_accuracy: 0.9900 - val_loss: 0.0466 - learning_rate: 1.1111e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 0.9923 - loss: 0.0588 - val_accuracy: 0.9925 - val_loss: 0.0393 - learning_rate: 1.1111e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 0.9973 - loss: 0.0383 - val_accuracy: 0.9912 - val_loss: 0.0370 - learning_rate: 1.1111e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 57ms/step - accuracy: 0.9988 - loss: 0.0282 - val_accuracy: 0.9912 - val_loss: 0.0313 - learning_rate: 1.1111e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 57ms/step - accuracy: 0.9991 - loss: 0.0210 - val_accuracy: 0.9925 - val_loss: 0.0309 - learning_rate: 1.1111e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 60ms/step - accuracy: 0.9994 - loss: 0.0173 - val_accuracy: 0.9912 - val_loss: 0.0312 - learning_rate: 1.1111e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0129 - val_accuracy: 0.9925 - val_loss: 0.0301 - learning_rate: 1.1111e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0109 - val_accuracy: 0.9925 - val_loss: 0.0289 - learning_rate: 1.1111e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.9998 - loss: 0.0085 - val_accuracy: 0.9925 - val_loss: 0.0313 - learning_rate: 1.1111e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0082 - val_accuracy: 0.9925 - val_loss: 0.0340 - learning_rate: 1.1111e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.9925 - val_loss: 0.0296 - learning_rate: 1.1111e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.9925 - val_loss: 0.0303 - learning_rate: 1.1111e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.9925 - val_loss: 0.0318 - learning_rate: 1.1111e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.9925 - val_loss: 0.0321 - learning_rate: 5.5554e-05\n",
            "Epoch 16/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.9925 - val_loss: 0.0328 - learning_rate: 5.5554e-05\n",
            "Epoch 17/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.9925 - val_loss: 0.0333 - learning_rate: 5.5554e-05\n",
            "Epoch 18/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.9925 - val_loss: 0.0330 - learning_rate: 5.5554e-05\n",
            "Epoch 19/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.9925 - val_loss: 0.0327 - learning_rate: 5.5554e-05\n",
            "[Trial 16] units1=192, units2=128, dropout1=0.4, dropout2=0.3, lr=1.1e-04, batch_size=16 → val_acc=0.9925\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 0. Best value: 0.99375:  57%|█████████████████████████▌                   | 17/30 [47:40<34:47, 160.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-06-04 11:58:13,539] Trial 16 finished with value: 0.9925000071525574 and parameters: {'units1': 192, 'units2': 128, 'dropout1': 0.4, 'dropout2': 0.30000000000000004, 'learning_rate': 0.00011110899088358946, 'batch_size': 16}. Best is trial 0 with value: 0.9937499761581421.\n",
            "Epoch 1/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.8492 - loss: 0.3520 - val_accuracy: 0.9725 - val_loss: 0.0885 - learning_rate: 5.8177e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9909 - loss: 0.0368 - val_accuracy: 0.9837 - val_loss: 0.0556 - learning_rate: 5.8177e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9987 - loss: 0.0133 - val_accuracy: 0.9912 - val_loss: 0.0377 - learning_rate: 5.8177e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.9937 - val_loss: 0.0330 - learning_rate: 5.8177e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.9925 - val_loss: 0.0326 - learning_rate: 5.8177e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9997 - loss: 0.0027 - val_accuracy: 0.9925 - val_loss: 0.0296 - learning_rate: 5.8177e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9912 - val_loss: 0.0316 - learning_rate: 5.8177e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9925 - val_loss: 0.0309 - learning_rate: 5.8177e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9937 - val_loss: 0.0305 - learning_rate: 5.8177e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9937 - val_loss: 0.0279 - learning_rate: 5.8177e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9937 - val_loss: 0.0277 - learning_rate: 5.8177e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 8.4211e-04 - val_accuracy: 0.9937 - val_loss: 0.0282 - learning_rate: 5.8177e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9937 - val_loss: 0.0299 - learning_rate: 5.8177e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 6.3419e-04 - val_accuracy: 0.9937 - val_loss: 0.0289 - learning_rate: 5.8177e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 4.8991e-04 - val_accuracy: 0.9937 - val_loss: 0.0297 - learning_rate: 5.8177e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 5.5829e-04 - val_accuracy: 0.9937 - val_loss: 0.0299 - learning_rate: 5.8177e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 4.9072e-04 - val_accuracy: 0.9937 - val_loss: 0.0298 - learning_rate: 2.9088e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 4.0035e-04 - val_accuracy: 0.9937 - val_loss: 0.0300 - learning_rate: 2.9088e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 6.0901e-04 - val_accuracy: 0.9937 - val_loss: 0.0302 - learning_rate: 2.9088e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 4.4826e-04 - val_accuracy: 0.9937 - val_loss: 0.0302 - learning_rate: 2.9088e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 5.3101e-04 - val_accuracy: 0.9937 - val_loss: 0.0285 - learning_rate: 2.9088e-04\n",
            "[Trial 17] units1=64, units2=256, dropout1=0.1, dropout2=0.5, lr=5.8e-04, batch_size=64 → val_acc=0.9937\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 0. Best value: 0.99375:  60%|███████████████████████████                  | 18/30 [48:19<24:48, 124.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-06-04 11:58:52,585] Trial 17 finished with value: 0.9937499761581421 and parameters: {'units1': 64, 'units2': 256, 'dropout1': 0.1, 'dropout2': 0.5, 'learning_rate': 0.000581765657511884, 'batch_size': 64}. Best is trial 0 with value: 0.9937499761581421.\n",
            "Epoch 1/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.7334 - loss: 0.5431 - val_accuracy: 0.9638 - val_loss: 0.0917 - learning_rate: 3.3444e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.9748 - loss: 0.1877 - val_accuracy: 0.9800 - val_loss: 0.0563 - learning_rate: 3.3444e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.9901 - loss: 0.1287 - val_accuracy: 0.9900 - val_loss: 0.0428 - learning_rate: 3.3444e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.9942 - loss: 0.0977 - val_accuracy: 0.9912 - val_loss: 0.0416 - learning_rate: 3.3444e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.9964 - loss: 0.0847 - val_accuracy: 0.9925 - val_loss: 0.0436 - learning_rate: 3.3444e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.9972 - loss: 0.0697 - val_accuracy: 0.9925 - val_loss: 0.0437 - learning_rate: 3.3444e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.9984 - loss: 0.0571 - val_accuracy: 0.9937 - val_loss: 0.0462 - learning_rate: 3.3444e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.9997 - loss: 0.0486 - val_accuracy: 0.9925 - val_loss: 0.0463 - learning_rate: 3.3444e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.9995 - loss: 0.0422 - val_accuracy: 0.9925 - val_loss: 0.0466 - learning_rate: 3.3444e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 0.0393 - val_accuracy: 0.9937 - val_loss: 0.0472 - learning_rate: 1.6722e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.0355 - val_accuracy: 0.9925 - val_loss: 0.0469 - learning_rate: 1.6722e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.9994 - loss: 0.0337 - val_accuracy: 0.9925 - val_loss: 0.0475 - learning_rate: 1.6722e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 0.0320 - val_accuracy: 0.9925 - val_loss: 0.0468 - learning_rate: 1.6722e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 0.0306 - val_accuracy: 0.9925 - val_loss: 0.0458 - learning_rate: 1.6722e-04\n",
            "[Trial 18] units1=128, units2=32, dropout1=0.5, dropout2=0.2, lr=3.3e-04, batch_size=128 → val_acc=0.9925\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 0. Best value: 0.99375:  63%|█████████████████████████████▏                | 19/30 [48:51<17:39, 96.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-06-04 11:59:24,225] Trial 18 finished with value: 0.9925000071525574 and parameters: {'units1': 128, 'units2': 32, 'dropout1': 0.5, 'dropout2': 0.2, 'learning_rate': 0.00033443547442935074, 'batch_size': 128}. Best is trial 0 with value: 0.9937499761581421.\n",
            "Epoch 1/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 140ms/step - accuracy: 0.8872 - loss: 0.2667 - val_accuracy: 0.9800 - val_loss: 0.0737 - learning_rate: 0.0030\n",
            "Epoch 2/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 147ms/step - accuracy: 0.9919 - loss: 0.0333 - val_accuracy: 0.9925 - val_loss: 0.0338 - learning_rate: 0.0030\n",
            "Epoch 3/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 144ms/step - accuracy: 0.9982 - loss: 0.0124 - val_accuracy: 0.9900 - val_loss: 0.0324 - learning_rate: 0.0030\n",
            "Epoch 4/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 143ms/step - accuracy: 0.9996 - loss: 0.0067 - val_accuracy: 0.9912 - val_loss: 0.0336 - learning_rate: 0.0030\n",
            "Epoch 5/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 138ms/step - accuracy: 0.9979 - loss: 0.0050 - val_accuracy: 0.9875 - val_loss: 0.0465 - learning_rate: 0.0030\n",
            "Epoch 6/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 135ms/step - accuracy: 0.9964 - loss: 0.0102 - val_accuracy: 0.9887 - val_loss: 0.0539 - learning_rate: 0.0030\n",
            "Epoch 7/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 153ms/step - accuracy: 0.9951 - loss: 0.0135 - val_accuracy: 0.9887 - val_loss: 0.0483 - learning_rate: 0.0030\n",
            "Epoch 8/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 150ms/step - accuracy: 0.9976 - loss: 0.0118 - val_accuracy: 0.9875 - val_loss: 0.0430 - learning_rate: 0.0030\n",
            "Epoch 9/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 142ms/step - accuracy: 0.9995 - loss: 0.0022 - val_accuracy: 0.9950 - val_loss: 0.0334 - learning_rate: 0.0015\n",
            "Epoch 10/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9925 - val_loss: 0.0341 - learning_rate: 0.0015\n",
            "Epoch 11/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 7.8878e-04 - val_accuracy: 0.9925 - val_loss: 0.0358 - learning_rate: 0.0015\n",
            "Epoch 12/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 6.9487e-04 - val_accuracy: 0.9925 - val_loss: 0.0364 - learning_rate: 0.0015\n",
            "Epoch 13/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 5.9229e-04 - val_accuracy: 0.9925 - val_loss: 0.0380 - learning_rate: 0.0015\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 0. Best value: 0.99375:  67%|██████████████████████████████               | 20/30 [52:03<20:49, 124.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Trial 19] units1=512, units2=64, dropout1=0.3, dropout2=0.4, lr=3.0e-03, batch_size=32 → val_acc=0.9925\n",
            "\n",
            "[I 2025-06-04 12:02:35,960] Trial 19 finished with value: 0.9925000071525574 and parameters: {'units1': 512, 'units2': 64, 'dropout1': 0.30000000000000004, 'dropout2': 0.4, 'learning_rate': 0.0029986108375176686, 'batch_size': 32}. Best is trial 0 with value: 0.9937499761581421.\n",
            "Epoch 1/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 139ms/step - accuracy: 0.8967 - loss: 0.2645 - val_accuracy: 0.9837 - val_loss: 0.0583 - learning_rate: 2.0886e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 147ms/step - accuracy: 0.9916 - loss: 0.0541 - val_accuracy: 0.9912 - val_loss: 0.0387 - learning_rate: 2.0886e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 144ms/step - accuracy: 0.9982 - loss: 0.0301 - val_accuracy: 0.9925 - val_loss: 0.0339 - learning_rate: 2.0886e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 145ms/step - accuracy: 0.9991 - loss: 0.0202 - val_accuracy: 0.9925 - val_loss: 0.0308 - learning_rate: 2.0886e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 139ms/step - accuracy: 0.9997 - loss: 0.0153 - val_accuracy: 0.9925 - val_loss: 0.0299 - learning_rate: 2.0886e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 146ms/step - accuracy: 0.9997 - loss: 0.0119 - val_accuracy: 0.9925 - val_loss: 0.0289 - learning_rate: 2.0886e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 0.0093 - val_accuracy: 0.9925 - val_loss: 0.0279 - learning_rate: 2.0886e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.0081 - val_accuracy: 0.9925 - val_loss: 0.0280 - learning_rate: 2.0886e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.9925 - val_loss: 0.0280 - learning_rate: 2.0886e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 142ms/step - accuracy: 0.9994 - loss: 0.0059 - val_accuracy: 0.9925 - val_loss: 0.0279 - learning_rate: 2.0886e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.9937 - val_loss: 0.0273 - learning_rate: 2.0886e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.9937 - val_loss: 0.0282 - learning_rate: 2.0886e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9925 - val_loss: 0.0271 - learning_rate: 2.0886e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9925 - val_loss: 0.0284 - learning_rate: 2.0886e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9925 - val_loss: 0.0273 - learning_rate: 2.0886e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9925 - val_loss: 0.0279 - learning_rate: 2.0886e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9925 - val_loss: 0.0273 - learning_rate: 2.0886e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9925 - val_loss: 0.0280 - learning_rate: 2.0886e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9925 - val_loss: 0.0284 - learning_rate: 1.0443e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9937 - val_loss: 0.0281 - learning_rate: 1.0443e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9925 - val_loss: 0.0281 - learning_rate: 1.0443e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9937 - val_loss: 0.0284 - learning_rate: 1.0443e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9925 - val_loss: 0.0291 - learning_rate: 1.0443e-04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 0. Best value: 0.99375:  70%|███████████████████████████████▍             | 21/30 [57:37<28:10, 187.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Trial 20] units1=512, units2=64, dropout1=0.4, dropout2=0.3, lr=2.1e-04, batch_size=32 → val_acc=0.9925\n",
            "\n",
            "[I 2025-06-04 12:08:10,310] Trial 20 finished with value: 0.9925000071525574 and parameters: {'units1': 512, 'units2': 64, 'dropout1': 0.4, 'dropout2': 0.30000000000000004, 'learning_rate': 0.0002088578446041724, 'batch_size': 32}. Best is trial 0 with value: 0.9937499761581421.\n",
            "Epoch 1/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 0.7531 - loss: 0.5060 - val_accuracy: 0.9287 - val_loss: 0.1879 - learning_rate: 1.0049e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - accuracy: 0.9916 - loss: 0.1325 - val_accuracy: 0.9700 - val_loss: 0.0955 - learning_rate: 1.0049e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - accuracy: 0.9977 - loss: 0.0918 - val_accuracy: 0.9850 - val_loss: 0.0745 - learning_rate: 1.0049e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - accuracy: 0.9984 - loss: 0.0707 - val_accuracy: 0.9900 - val_loss: 0.0640 - learning_rate: 1.0049e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - accuracy: 0.9992 - loss: 0.0591 - val_accuracy: 0.9912 - val_loss: 0.0599 - learning_rate: 1.0049e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 0.0494 - val_accuracy: 0.9925 - val_loss: 0.0554 - learning_rate: 1.0049e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - accuracy: 1.0000 - loss: 0.0435 - val_accuracy: 0.9925 - val_loss: 0.0537 - learning_rate: 1.0049e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 0.0382 - val_accuracy: 0.9925 - val_loss: 0.0527 - learning_rate: 1.0049e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.0344 - val_accuracy: 0.9925 - val_loss: 0.0501 - learning_rate: 1.0049e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - accuracy: 1.0000 - loss: 0.0308 - val_accuracy: 0.9925 - val_loss: 0.0495 - learning_rate: 1.0049e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 0.0278 - val_accuracy: 0.9925 - val_loss: 0.0485 - learning_rate: 1.0049e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - accuracy: 1.0000 - loss: 0.0253 - val_accuracy: 0.9925 - val_loss: 0.0462 - learning_rate: 1.0049e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.0232 - val_accuracy: 0.9925 - val_loss: 0.0450 - learning_rate: 1.0049e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 0.0210 - val_accuracy: 0.9925 - val_loss: 0.0439 - learning_rate: 1.0049e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - accuracy: 1.0000 - loss: 0.0198 - val_accuracy: 0.9925 - val_loss: 0.0428 - learning_rate: 1.0049e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 0.0184 - val_accuracy: 0.9925 - val_loss: 0.0421 - learning_rate: 1.0049e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - accuracy: 1.0000 - loss: 0.0174 - val_accuracy: 0.9925 - val_loss: 0.0418 - learning_rate: 1.0049e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 0.0161 - val_accuracy: 0.9925 - val_loss: 0.0407 - learning_rate: 1.0049e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.0153 - val_accuracy: 0.9925 - val_loss: 0.0400 - learning_rate: 1.0049e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - accuracy: 1.0000 - loss: 0.0142 - val_accuracy: 0.9925 - val_loss: 0.0387 - learning_rate: 1.0049e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 0.0131 - val_accuracy: 0.9925 - val_loss: 0.0383 - learning_rate: 1.0049e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 0.0126 - val_accuracy: 0.9925 - val_loss: 0.0378 - learning_rate: 1.0049e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 0.0118 - val_accuracy: 0.9925 - val_loss: 0.0370 - learning_rate: 1.0049e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 0.0112 - val_accuracy: 0.9925 - val_loss: 0.0363 - learning_rate: 1.0049e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 0.0106 - val_accuracy: 0.9925 - val_loss: 0.0358 - learning_rate: 1.0049e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - accuracy: 1.0000 - loss: 0.0101 - val_accuracy: 0.9925 - val_loss: 0.0352 - learning_rate: 1.0049e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - accuracy: 1.0000 - loss: 0.0097 - val_accuracy: 0.9925 - val_loss: 0.0347 - learning_rate: 1.0049e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 0.0088 - val_accuracy: 0.9925 - val_loss: 0.0344 - learning_rate: 1.0049e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 0.0086 - val_accuracy: 0.9925 - val_loss: 0.0342 - learning_rate: 1.0049e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 0.0082 - val_accuracy: 0.9925 - val_loss: 0.0337 - learning_rate: 1.0049e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - accuracy: 1.0000 - loss: 0.0077 - val_accuracy: 0.9925 - val_loss: 0.0331 - learning_rate: 1.0049e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0074 - val_accuracy: 0.9925 - val_loss: 0.0332 - learning_rate: 1.0049e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.9925 - val_loss: 0.0325 - learning_rate: 1.0049e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 0.9925 - val_loss: 0.0323 - learning_rate: 1.0049e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.9925 - val_loss: 0.0318 - learning_rate: 1.0049e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 0.9925 - val_loss: 0.0313 - learning_rate: 1.0049e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.9925 - val_loss: 0.0310 - learning_rate: 1.0049e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.9925 - val_loss: 0.0311 - learning_rate: 1.0049e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.9925 - val_loss: 0.0310 - learning_rate: 1.0049e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.9925 - val_loss: 0.0307 - learning_rate: 1.0049e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.9925 - val_loss: 0.0305 - learning_rate: 1.0049e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.9925 - val_loss: 0.0305 - learning_rate: 1.0049e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.9925 - val_loss: 0.0301 - learning_rate: 1.0049e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.9937 - val_loss: 0.0294 - learning_rate: 1.0049e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.9925 - val_loss: 0.0295 - learning_rate: 1.0049e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.9937 - val_loss: 0.0292 - learning_rate: 1.0049e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.9925 - val_loss: 0.0294 - learning_rate: 1.0049e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.9925 - val_loss: 0.0289 - learning_rate: 1.0049e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.9937 - val_loss: 0.0292 - learning_rate: 1.0049e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9925 - val_loss: 0.0295 - learning_rate: 1.0049e-04\n",
            "[Trial 21] units1=256, units2=64, dropout1=0.3, dropout2=0.1, lr=1.0e-04, batch_size=128 → val_acc=0.9925\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 0. Best value: 0.99375:  73%|███████████████████████████████▌           | 22/30 [1:00:32<24:31, 184.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-06-04 12:11:05,446] Trial 21 finished with value: 0.9925000071525574 and parameters: {'units1': 256, 'units2': 64, 'dropout1': 0.30000000000000004, 'dropout2': 0.1, 'learning_rate': 0.00010048741754516857, 'batch_size': 128}. Best is trial 0 with value: 0.9937499761581421.\n",
            "Epoch 1/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 142ms/step - accuracy: 0.7929 - loss: 0.4298 - val_accuracy: 0.8888 - val_loss: 0.2490 - learning_rate: 1.4142e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - accuracy: 0.9950 - loss: 0.0779 - val_accuracy: 0.9700 - val_loss: 0.1009 - learning_rate: 1.4142e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - accuracy: 0.9989 - loss: 0.0485 - val_accuracy: 0.9812 - val_loss: 0.0686 - learning_rate: 1.4142e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - accuracy: 0.9995 - loss: 0.0374 - val_accuracy: 0.9900 - val_loss: 0.0570 - learning_rate: 1.4142e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - accuracy: 1.0000 - loss: 0.0306 - val_accuracy: 0.9900 - val_loss: 0.0514 - learning_rate: 1.4142e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - accuracy: 1.0000 - loss: 0.0253 - val_accuracy: 0.9925 - val_loss: 0.0477 - learning_rate: 1.4142e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 0.0223 - val_accuracy: 0.9925 - val_loss: 0.0460 - learning_rate: 1.4142e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - accuracy: 1.0000 - loss: 0.0188 - val_accuracy: 0.9912 - val_loss: 0.0441 - learning_rate: 1.4142e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 0.0169 - val_accuracy: 0.9937 - val_loss: 0.0424 - learning_rate: 1.4142e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.0154 - val_accuracy: 0.9937 - val_loss: 0.0420 - learning_rate: 1.4142e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 0.0139 - val_accuracy: 0.9925 - val_loss: 0.0406 - learning_rate: 1.4142e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 0.0126 - val_accuracy: 0.9925 - val_loss: 0.0394 - learning_rate: 1.4142e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.0118 - val_accuracy: 0.9912 - val_loss: 0.0386 - learning_rate: 1.4142e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 0.0109 - val_accuracy: 0.9912 - val_loss: 0.0378 - learning_rate: 1.4142e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - accuracy: 1.0000 - loss: 0.0097 - val_accuracy: 0.9912 - val_loss: 0.0368 - learning_rate: 1.4142e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 0.0091 - val_accuracy: 0.9937 - val_loss: 0.0357 - learning_rate: 1.4142e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0084 - val_accuracy: 0.9925 - val_loss: 0.0354 - learning_rate: 1.4142e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - accuracy: 1.0000 - loss: 0.0079 - val_accuracy: 0.9925 - val_loss: 0.0347 - learning_rate: 1.4142e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 162ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.9925 - val_loss: 0.0342 - learning_rate: 1.4142e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.9925 - val_loss: 0.0333 - learning_rate: 1.4142e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 163ms/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.9925 - val_loss: 0.0326 - learning_rate: 1.4142e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.9925 - val_loss: 0.0322 - learning_rate: 1.4142e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.9925 - val_loss: 0.0314 - learning_rate: 1.4142e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.9925 - val_loss: 0.0315 - learning_rate: 1.4142e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.9925 - val_loss: 0.0313 - learning_rate: 1.4142e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.9925 - val_loss: 0.0307 - learning_rate: 1.4142e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.9925 - val_loss: 0.0306 - learning_rate: 1.4142e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.9937 - val_loss: 0.0303 - learning_rate: 1.4142e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.9925 - val_loss: 0.0300 - learning_rate: 1.4142e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.9925 - val_loss: 0.0298 - learning_rate: 1.4142e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.9925 - val_loss: 0.0301 - learning_rate: 1.4142e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9925 - val_loss: 0.0299 - learning_rate: 1.4142e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9925 - val_loss: 0.0295 - learning_rate: 1.4142e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.9937 - val_loss: 0.0296 - learning_rate: 1.4142e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9925 - val_loss: 0.0293 - learning_rate: 1.4142e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9925 - val_loss: 0.0292 - learning_rate: 1.4142e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.9925 - val_loss: 0.0289 - learning_rate: 1.4142e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9925 - val_loss: 0.0286 - learning_rate: 1.4142e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.9925 - val_loss: 0.0287 - learning_rate: 1.4142e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9925 - val_loss: 0.0289 - learning_rate: 1.4142e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9937 - val_loss: 0.0287 - learning_rate: 1.4142e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9937 - val_loss: 0.0282 - learning_rate: 1.4142e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9937 - val_loss: 0.0283 - learning_rate: 1.4142e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9925 - val_loss: 0.0284 - learning_rate: 1.4142e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9925 - val_loss: 0.0282 - learning_rate: 1.4142e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9925 - val_loss: 0.0283 - learning_rate: 1.4142e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9925 - val_loss: 0.0285 - learning_rate: 1.4142e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9925 - val_loss: 0.0284 - learning_rate: 7.0709e-05\n",
            "Epoch 49/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9925 - val_loss: 0.0285 - learning_rate: 7.0709e-05\n",
            "Epoch 50/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9925 - val_loss: 0.0282 - learning_rate: 7.0709e-05\n",
            "[Trial 22] units1=256, units2=64, dropout1=0.2, dropout2=0.1, lr=1.4e-04, batch_size=128 → val_acc=0.9925\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 0. Best value: 0.99375:  77%|████████████████████████████████▉          | 23/30 [1:03:32<21:18, 182.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[I 2025-06-04 12:14:04,786] Trial 22 finished with value: 0.9925000071525574 and parameters: {'units1': 256, 'units2': 64, 'dropout1': 0.2, 'dropout2': 0.1, 'learning_rate': 0.00014141803826165164, 'batch_size': 128}. Best is trial 0 with value: 0.9937499761581421.\n",
            "Epoch 1/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.8262 - loss: 0.3683 - val_accuracy: 0.9350 - val_loss: 0.1893 - learning_rate: 3.5655e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - accuracy: 0.9946 - loss: 0.0613 - val_accuracy: 0.9762 - val_loss: 0.0682 - learning_rate: 3.5655e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 140ms/step - accuracy: 0.9991 - loss: 0.0349 - val_accuracy: 0.9875 - val_loss: 0.0462 - learning_rate: 3.5655e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 116ms/step - accuracy: 0.9997 - loss: 0.0245 - val_accuracy: 0.9900 - val_loss: 0.0376 - learning_rate: 3.5655e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - accuracy: 1.0000 - loss: 0.0180 - val_accuracy: 0.9925 - val_loss: 0.0341 - learning_rate: 3.5655e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - accuracy: 1.0000 - loss: 0.0139 - val_accuracy: 0.9925 - val_loss: 0.0307 - learning_rate: 3.5655e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 0.0113 - val_accuracy: 0.9925 - val_loss: 0.0302 - learning_rate: 3.5655e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.0096 - val_accuracy: 0.9925 - val_loss: 0.0291 - learning_rate: 3.5655e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 0.0082 - val_accuracy: 0.9937 - val_loss: 0.0284 - learning_rate: 3.5655e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.9937 - val_loss: 0.0281 - learning_rate: 3.5655e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.9925 - val_loss: 0.0276 - learning_rate: 3.5655e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.9937 - val_loss: 0.0269 - learning_rate: 3.5655e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.9937 - val_loss: 0.0265 - learning_rate: 3.5655e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.9937 - val_loss: 0.0264 - learning_rate: 3.5655e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9937 - val_loss: 0.0260 - learning_rate: 3.5655e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9937 - val_loss: 0.0261 - learning_rate: 3.5655e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.9937 - val_loss: 0.0258 - learning_rate: 3.5655e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9925 - val_loss: 0.0255 - learning_rate: 3.5655e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9925 - val_loss: 0.0253 - learning_rate: 3.5655e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9925 - val_loss: 0.0247 - learning_rate: 3.5655e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9925 - val_loss: 0.0253 - learning_rate: 3.5655e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9925 - val_loss: 0.0253 - learning_rate: 3.5655e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9925 - val_loss: 0.0255 - learning_rate: 3.5655e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9925 - val_loss: 0.0255 - learning_rate: 3.5655e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9925 - val_loss: 0.0255 - learning_rate: 3.5655e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9925 - val_loss: 0.0252 - learning_rate: 1.7828e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9925 - val_loss: 0.0254 - learning_rate: 1.7828e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9925 - val_loss: 0.0257 - learning_rate: 1.7828e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9925 - val_loss: 0.0259 - learning_rate: 1.7828e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9925 - val_loss: 0.0261 - learning_rate: 1.7828e-04\n",
            "[Trial 23] units1=256, units2=64, dropout1=0.3, dropout2=0.2, lr=3.6e-04, batch_size=128 → val_acc=0.9925\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 0. Best value: 0.99375:  80%|██████████████████████████████████▍        | 24/30 [1:05:18<15:58, 159.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[I 2025-06-04 12:15:51,257] Trial 23 finished with value: 0.9925000071525574 and parameters: {'units1': 256, 'units2': 64, 'dropout1': 0.30000000000000004, 'dropout2': 0.2, 'learning_rate': 0.0003565519138435076, 'batch_size': 128}. Best is trial 0 with value: 0.9937499761581421.\n",
            "Epoch 1/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.6753 - loss: 0.6580 - val_accuracy: 0.9663 - val_loss: 0.0917 - learning_rate: 1.6519e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - accuracy: 0.9902 - loss: 0.1159 - val_accuracy: 0.9837 - val_loss: 0.0657 - learning_rate: 1.6519e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - accuracy: 0.9973 - loss: 0.0764 - val_accuracy: 0.9875 - val_loss: 0.0555 - learning_rate: 1.6519e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 148ms/step - accuracy: 0.9997 - loss: 0.0603 - val_accuracy: 0.9875 - val_loss: 0.0526 - learning_rate: 1.6519e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - accuracy: 1.0000 - loss: 0.0515 - val_accuracy: 0.9875 - val_loss: 0.0504 - learning_rate: 1.6519e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 163ms/step - accuracy: 1.0000 - loss: 0.0441 - val_accuracy: 0.9887 - val_loss: 0.0499 - learning_rate: 1.6519e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - accuracy: 1.0000 - loss: 0.0388 - val_accuracy: 0.9887 - val_loss: 0.0504 - learning_rate: 1.6519e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - accuracy: 1.0000 - loss: 0.0368 - val_accuracy: 0.9900 - val_loss: 0.0494 - learning_rate: 1.6519e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - accuracy: 1.0000 - loss: 0.0320 - val_accuracy: 0.9900 - val_loss: 0.0481 - learning_rate: 1.6519e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - accuracy: 1.0000 - loss: 0.0296 - val_accuracy: 0.9900 - val_loss: 0.0478 - learning_rate: 1.6519e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 0.0270 - val_accuracy: 0.9900 - val_loss: 0.0465 - learning_rate: 1.6519e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 0.0249 - val_accuracy: 0.9900 - val_loss: 0.0458 - learning_rate: 1.6519e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - accuracy: 1.0000 - loss: 0.0231 - val_accuracy: 0.9900 - val_loss: 0.0447 - learning_rate: 1.6519e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.0217 - val_accuracy: 0.9912 - val_loss: 0.0437 - learning_rate: 1.6519e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 0.0199 - val_accuracy: 0.9900 - val_loss: 0.0430 - learning_rate: 1.6519e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.0185 - val_accuracy: 0.9912 - val_loss: 0.0415 - learning_rate: 1.6519e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - accuracy: 1.0000 - loss: 0.0173 - val_accuracy: 0.9912 - val_loss: 0.0405 - learning_rate: 1.6519e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - accuracy: 1.0000 - loss: 0.0164 - val_accuracy: 0.9912 - val_loss: 0.0398 - learning_rate: 1.6519e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 0.0156 - val_accuracy: 0.9912 - val_loss: 0.0395 - learning_rate: 1.6519e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.0145 - val_accuracy: 0.9912 - val_loss: 0.0387 - learning_rate: 1.6519e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 0.0138 - val_accuracy: 0.9925 - val_loss: 0.0381 - learning_rate: 1.6519e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 0.0131 - val_accuracy: 0.9925 - val_loss: 0.0373 - learning_rate: 1.6519e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - accuracy: 1.0000 - loss: 0.0123 - val_accuracy: 0.9925 - val_loss: 0.0365 - learning_rate: 1.6519e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0118 - val_accuracy: 0.9912 - val_loss: 0.0362 - learning_rate: 1.6519e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.0110 - val_accuracy: 0.9925 - val_loss: 0.0359 - learning_rate: 1.6519e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - accuracy: 1.0000 - loss: 0.0106 - val_accuracy: 0.9925 - val_loss: 0.0354 - learning_rate: 1.6519e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 0.0102 - val_accuracy: 0.9925 - val_loss: 0.0348 - learning_rate: 1.6519e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 0.0099 - val_accuracy: 0.9925 - val_loss: 0.0347 - learning_rate: 1.6519e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - accuracy: 1.0000 - loss: 0.0091 - val_accuracy: 0.9925 - val_loss: 0.0342 - learning_rate: 1.6519e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 0.0087 - val_accuracy: 0.9925 - val_loss: 0.0339 - learning_rate: 1.6519e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - accuracy: 1.0000 - loss: 0.0083 - val_accuracy: 0.9925 - val_loss: 0.0335 - learning_rate: 1.6519e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - accuracy: 1.0000 - loss: 0.0079 - val_accuracy: 0.9925 - val_loss: 0.0332 - learning_rate: 1.6519e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 0.9925 - val_loss: 0.0328 - learning_rate: 1.6519e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 0.0075 - val_accuracy: 0.9925 - val_loss: 0.0328 - learning_rate: 1.6519e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.9925 - val_loss: 0.0325 - learning_rate: 1.6519e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 0.9925 - val_loss: 0.0323 - learning_rate: 1.6519e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.9925 - val_loss: 0.0323 - learning_rate: 1.6519e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.9925 - val_loss: 0.0319 - learning_rate: 1.6519e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.9925 - val_loss: 0.0317 - learning_rate: 1.6519e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.9925 - val_loss: 0.0317 - learning_rate: 1.6519e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.9925 - val_loss: 0.0314 - learning_rate: 1.6519e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.9925 - val_loss: 0.0314 - learning_rate: 1.6519e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.9937 - val_loss: 0.0312 - learning_rate: 1.6519e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.9925 - val_loss: 0.0311 - learning_rate: 1.6519e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.9925 - val_loss: 0.0311 - learning_rate: 1.6519e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.9925 - val_loss: 0.0311 - learning_rate: 1.6519e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.9925 - val_loss: 0.0312 - learning_rate: 1.6519e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.9925 - val_loss: 0.0309 - learning_rate: 1.6519e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.9925 - val_loss: 0.0307 - learning_rate: 1.6519e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.9925 - val_loss: 0.0310 - learning_rate: 1.6519e-04\n",
            "[Trial 24] units1=256, units2=64, dropout1=0.2, dropout2=0.1, lr=1.7e-04, batch_size=128 → val_acc=0.9925\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 0. Best value: 0.99375:  83%|███████████████████████████████████▊       | 25/30 [1:08:16<13:45, 165.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-06-04 12:18:48,756] Trial 24 finished with value: 0.9925000071525574 and parameters: {'units1': 256, 'units2': 64, 'dropout1': 0.2, 'dropout2': 0.1, 'learning_rate': 0.0001651945440548371, 'batch_size': 128}. Best is trial 0 with value: 0.9937499761581421.\n",
            "Epoch 1/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.8264 - loss: 0.3872 - val_accuracy: 0.9388 - val_loss: 0.1892 - learning_rate: 7.0756e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.9923 - loss: 0.0893 - val_accuracy: 0.9762 - val_loss: 0.0869 - learning_rate: 7.0756e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.9966 - loss: 0.0460 - val_accuracy: 0.9887 - val_loss: 0.0543 - learning_rate: 7.0756e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.9991 - loss: 0.0291 - val_accuracy: 0.9925 - val_loss: 0.0414 - learning_rate: 7.0756e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - accuracy: 0.9997 - loss: 0.0210 - val_accuracy: 0.9937 - val_loss: 0.0381 - learning_rate: 7.0756e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.0145 - val_accuracy: 0.9925 - val_loss: 0.0382 - learning_rate: 7.0756e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.0111 - val_accuracy: 0.9912 - val_loss: 0.0356 - learning_rate: 7.0756e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.0092 - val_accuracy: 0.9925 - val_loss: 0.0338 - learning_rate: 7.0756e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.0080 - val_accuracy: 0.9937 - val_loss: 0.0331 - learning_rate: 7.0756e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.9925 - val_loss: 0.0333 - learning_rate: 7.0756e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 0.9912 - val_loss: 0.0330 - learning_rate: 7.0756e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.9912 - val_loss: 0.0330 - learning_rate: 7.0756e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.9912 - val_loss: 0.0339 - learning_rate: 7.0756e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9912 - val_loss: 0.0326 - learning_rate: 7.0756e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9912 - val_loss: 0.0332 - learning_rate: 7.0756e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9912 - val_loss: 0.0336 - learning_rate: 7.0756e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9912 - val_loss: 0.0336 - learning_rate: 7.0756e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9912 - val_loss: 0.0333 - learning_rate: 7.0756e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9925 - val_loss: 0.0336 - learning_rate: 7.0756e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9925 - val_loss: 0.0339 - learning_rate: 3.5378e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9912 - val_loss: 0.0342 - learning_rate: 3.5378e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9912 - val_loss: 0.0345 - learning_rate: 3.5378e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9912 - val_loss: 0.0349 - learning_rate: 3.5378e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9912 - val_loss: 0.0354 - learning_rate: 3.5378e-04\n",
            "[Trial 25] units1=128, units2=64, dropout1=0.4, dropout2=0.3, lr=7.1e-04, batch_size=128 → val_acc=0.9912\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 0. Best value: 0.99375:  87%|█████████████████████████████████████▎     | 26/30 [1:09:06<08:42, 130.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-06-04 12:19:39,058] Trial 25 finished with value: 0.9912499785423279 and parameters: {'units1': 128, 'units2': 64, 'dropout1': 0.4, 'dropout2': 0.30000000000000004, 'learning_rate': 0.0007075625682893787, 'batch_size': 128}. Best is trial 0 with value: 0.9937499761581421.\n",
            "Epoch 1/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - accuracy: 0.8321 - loss: 0.3759 - val_accuracy: 0.9812 - val_loss: 0.0689 - learning_rate: 2.3838e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.9770 - loss: 0.0948 - val_accuracy: 0.9925 - val_loss: 0.0381 - learning_rate: 2.3838e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9867 - loss: 0.0553 - val_accuracy: 0.9925 - val_loss: 0.0323 - learning_rate: 2.3838e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.9938 - loss: 0.0371 - val_accuracy: 0.9912 - val_loss: 0.0323 - learning_rate: 2.3838e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.9971 - loss: 0.0229 - val_accuracy: 0.9937 - val_loss: 0.0292 - learning_rate: 2.3838e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.9984 - loss: 0.0168 - val_accuracy: 0.9925 - val_loss: 0.0311 - learning_rate: 2.3838e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.9993 - loss: 0.0139 - val_accuracy: 0.9925 - val_loss: 0.0288 - learning_rate: 2.3838e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9992 - loss: 0.0114 - val_accuracy: 0.9925 - val_loss: 0.0259 - learning_rate: 2.3838e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.9994 - loss: 0.0090 - val_accuracy: 0.9937 - val_loss: 0.0258 - learning_rate: 2.3838e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.9990 - loss: 0.0076 - val_accuracy: 0.9937 - val_loss: 0.0286 - learning_rate: 2.3838e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.9937 - val_loss: 0.0294 - learning_rate: 2.3838e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9997 - loss: 0.0049 - val_accuracy: 0.9937 - val_loss: 0.0359 - learning_rate: 2.3838e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.9988 - loss: 0.0067 - val_accuracy: 0.9925 - val_loss: 0.0363 - learning_rate: 2.3838e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.9992 - loss: 0.0069 - val_accuracy: 0.9925 - val_loss: 0.0357 - learning_rate: 1.1919e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.9937 - val_loss: 0.0344 - learning_rate: 1.1919e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.9998 - loss: 0.0038 - val_accuracy: 0.9937 - val_loss: 0.0335 - learning_rate: 1.1919e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.9991 - loss: 0.0033 - val_accuracy: 0.9937 - val_loss: 0.0335 - learning_rate: 1.1919e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9950 - val_loss: 0.0301 - learning_rate: 1.1919e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9950 - val_loss: 0.0322 - learning_rate: 5.9594e-05\n",
            "[Trial 26] units1=64, units2=128, dropout1=0.3, dropout2=0.4, lr=2.4e-04, batch_size=16 → val_acc=0.9950\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 26. Best value: 0.995:  90%|███████████████████████████████████████▌    | 27/30 [1:10:48<06:06, 122.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-06-04 12:21:21,324] Trial 26 finished with value: 0.9950000047683716 and parameters: {'units1': 64, 'units2': 128, 'dropout1': 0.30000000000000004, 'dropout2': 0.4, 'learning_rate': 0.00023837704617109712, 'batch_size': 16}. Best is trial 26 with value: 0.9950000047683716.\n",
            "Epoch 1/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - accuracy: 0.8364 - loss: 0.3664 - val_accuracy: 0.9862 - val_loss: 0.0575 - learning_rate: 2.5134e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9793 - loss: 0.0936 - val_accuracy: 0.9912 - val_loss: 0.0381 - learning_rate: 2.5134e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9877 - loss: 0.0520 - val_accuracy: 0.9912 - val_loss: 0.0348 - learning_rate: 2.5134e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.9911 - loss: 0.0342 - val_accuracy: 0.9925 - val_loss: 0.0289 - learning_rate: 2.5134e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9960 - loss: 0.0262 - val_accuracy: 0.9912 - val_loss: 0.0337 - learning_rate: 2.5134e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.9984 - loss: 0.0175 - val_accuracy: 0.9925 - val_loss: 0.0279 - learning_rate: 2.5134e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.9969 - loss: 0.0151 - val_accuracy: 0.9925 - val_loss: 0.0342 - learning_rate: 2.5134e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.9973 - loss: 0.0122 - val_accuracy: 0.9925 - val_loss: 0.0307 - learning_rate: 2.5134e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.9983 - loss: 0.0133 - val_accuracy: 0.9937 - val_loss: 0.0309 - learning_rate: 2.5134e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9978 - loss: 0.0103 - val_accuracy: 0.9925 - val_loss: 0.0352 - learning_rate: 2.5134e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9967 - loss: 0.0120 - val_accuracy: 0.9925 - val_loss: 0.0353 - learning_rate: 2.5134e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.9987 - loss: 0.0075 - val_accuracy: 0.9937 - val_loss: 0.0332 - learning_rate: 1.2567e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.9991 - loss: 0.0064 - val_accuracy: 0.9925 - val_loss: 0.0389 - learning_rate: 1.2567e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.9989 - loss: 0.0055 - val_accuracy: 0.9925 - val_loss: 0.0360 - learning_rate: 1.2567e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.9925 - val_loss: 0.0369 - learning_rate: 1.2567e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9937 - val_loss: 0.0356 - learning_rate: 1.2567e-04\n",
            "[Trial 27] units1=64, units2=128, dropout1=0.3, dropout2=0.4, lr=2.5e-04, batch_size=16 → val_acc=0.9937\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 26. Best value: 0.995:  93%|█████████████████████████████████████████   | 28/30 [1:12:14<03:42, 111.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-06-04 12:22:47,193] Trial 27 finished with value: 0.9937499761581421 and parameters: {'units1': 64, 'units2': 128, 'dropout1': 0.30000000000000004, 'dropout2': 0.4, 'learning_rate': 0.00025134063207072276, 'batch_size': 16}. Best is trial 26 with value: 0.9950000047683716.\n",
            "Epoch 1/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.8415 - loss: 0.3312 - val_accuracy: 0.9887 - val_loss: 0.0444 - learning_rate: 0.0011\n",
            "Epoch 2/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9773 - loss: 0.0691 - val_accuracy: 0.9900 - val_loss: 0.0305 - learning_rate: 0.0011\n",
            "Epoch 3/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9950 - loss: 0.0258 - val_accuracy: 0.9925 - val_loss: 0.0377 - learning_rate: 0.0011\n",
            "Epoch 4/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9952 - loss: 0.0218 - val_accuracy: 0.9912 - val_loss: 0.0326 - learning_rate: 0.0011\n",
            "Epoch 5/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9995 - loss: 0.0104 - val_accuracy: 0.9925 - val_loss: 0.0299 - learning_rate: 0.0011\n",
            "Epoch 6/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.9980 - loss: 0.0084 - val_accuracy: 0.9912 - val_loss: 0.0392 - learning_rate: 0.0011\n",
            "Epoch 7/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.9987 - loss: 0.0071 - val_accuracy: 0.9912 - val_loss: 0.0432 - learning_rate: 0.0011\n",
            "Epoch 8/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.9983 - loss: 0.0055 - val_accuracy: 0.9912 - val_loss: 0.0358 - learning_rate: 0.0011\n",
            "Epoch 9/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.9980 - loss: 0.0082 - val_accuracy: 0.9875 - val_loss: 0.0341 - learning_rate: 0.0011\n",
            "Epoch 10/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.9935 - loss: 0.0214 - val_accuracy: 0.9900 - val_loss: 0.0552 - learning_rate: 0.0011\n",
            "Epoch 11/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.9926 - loss: 0.0188 - val_accuracy: 0.9925 - val_loss: 0.0398 - learning_rate: 5.3541e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.9974 - loss: 0.0061 - val_accuracy: 0.9912 - val_loss: 0.0406 - learning_rate: 5.3541e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.9993 - loss: 0.0029 - val_accuracy: 0.9925 - val_loss: 0.0389 - learning_rate: 5.3541e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9912 - val_loss: 0.0409 - learning_rate: 5.3541e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.9992 - loss: 0.0037 - val_accuracy: 0.9937 - val_loss: 0.0516 - learning_rate: 5.3541e-04\n",
            "[Trial 28] units1=64, units2=128, dropout1=0.2, dropout2=0.5, lr=1.1e-03, batch_size=16 → val_acc=0.9937\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 26. Best value: 0.995:  97%|██████████████████████████████████████████▌ | 29/30 [1:13:35<01:42, 102.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-06-04 12:24:08,566] Trial 28 finished with value: 0.9937499761581421 and parameters: {'units1': 64, 'units2': 128, 'dropout1': 0.2, 'dropout2': 0.5, 'learning_rate': 0.001070811312567383, 'batch_size': 16}. Best is trial 26 with value: 0.9950000047683716.\n",
            "Epoch 1/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - accuracy: 0.8274 - loss: 0.3717 - val_accuracy: 0.9837 - val_loss: 0.0603 - learning_rate: 4.4459e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9707 - loss: 0.1050 - val_accuracy: 0.9925 - val_loss: 0.0410 - learning_rate: 4.4459e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9842 - loss: 0.0662 - val_accuracy: 0.9912 - val_loss: 0.0370 - learning_rate: 4.4459e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9909 - loss: 0.0447 - val_accuracy: 0.9900 - val_loss: 0.0447 - learning_rate: 4.4459e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9935 - loss: 0.0314 - val_accuracy: 0.9950 - val_loss: 0.0292 - learning_rate: 4.4459e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.9940 - loss: 0.0247 - val_accuracy: 0.9950 - val_loss: 0.0287 - learning_rate: 4.4459e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.9950 - loss: 0.0243 - val_accuracy: 0.9912 - val_loss: 0.0343 - learning_rate: 4.4459e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.9972 - loss: 0.0175 - val_accuracy: 0.9912 - val_loss: 0.0347 - learning_rate: 4.4459e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.9966 - loss: 0.0183 - val_accuracy: 0.9925 - val_loss: 0.0348 - learning_rate: 4.4459e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.9960 - loss: 0.0130 - val_accuracy: 0.9925 - val_loss: 0.0395 - learning_rate: 4.4459e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.9961 - loss: 0.0139 - val_accuracy: 0.9925 - val_loss: 0.0394 - learning_rate: 4.4459e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.9939 - loss: 0.0208 - val_accuracy: 0.9925 - val_loss: 0.0359 - learning_rate: 2.2229e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.9986 - loss: 0.0095 - val_accuracy: 0.9925 - val_loss: 0.0368 - learning_rate: 2.2229e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.9986 - loss: 0.0098 - val_accuracy: 0.9925 - val_loss: 0.0383 - learning_rate: 2.2229e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.9984 - loss: 0.0087 - val_accuracy: 0.9937 - val_loss: 0.0390 - learning_rate: 2.2229e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.9996 - loss: 0.0045 - val_accuracy: 0.9937 - val_loss: 0.0431 - learning_rate: 2.2229e-04\n",
            "[Trial 29] units1=64, units2=128, dropout1=0.5, dropout2=0.4, lr=4.4e-04, batch_size=16 → val_acc=0.9937\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 26. Best value: 0.995: 100%|████████████████████████████████████████████| 30/30 [1:15:02<00:00, 150.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-06-04 12:25:35,568] Trial 29 finished with value: 0.9937499761581421 and parameters: {'units1': 64, 'units2': 128, 'dropout1': 0.5, 'dropout2': 0.4, 'learning_rate': 0.0004445875002614039, 'batch_size': 16}. Best is trial 26 with value: 0.9950000047683716.\n",
            "========== 최적 하이퍼파라미터 ==========\n",
            "units1: 64\n",
            "units2: 128\n",
            "dropout1: 0.30000000000000004\n",
            "dropout2: 0.4\n",
            "learning_rate: 0.00023837704617109712\n",
            "batch_size: 16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - accuracy: 0.8065 - loss: 0.4205 - val_accuracy: 0.8050 - val_loss: 0.3794 - learning_rate: 2.3838e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9810 - loss: 0.0935 - val_accuracy: 0.8850 - val_loss: 0.2631 - learning_rate: 2.3838e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.9889 - loss: 0.0522 - val_accuracy: 0.9287 - val_loss: 0.1760 - learning_rate: 2.3838e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.9921 - loss: 0.0386 - val_accuracy: 0.9262 - val_loss: 0.1960 - learning_rate: 2.3838e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.9957 - loss: 0.0290 - val_accuracy: 0.9237 - val_loss: 0.2114 - learning_rate: 2.3838e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.9964 - loss: 0.0220 - val_accuracy: 0.9262 - val_loss: 0.2027 - learning_rate: 2.3838e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.9966 - loss: 0.0183 - val_accuracy: 0.9337 - val_loss: 0.1917 - learning_rate: 2.3838e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.9981 - loss: 0.0123 - val_accuracy: 0.9250 - val_loss: 0.2187 - learning_rate: 2.3838e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.9993 - loss: 0.0101 - val_accuracy: 0.9287 - val_loss: 0.2113 - learning_rate: 1.1919e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.9989 - loss: 0.0085 - val_accuracy: 0.9312 - val_loss: 0.2071 - learning_rate: 1.1919e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.9990 - loss: 0.0088 - val_accuracy: 0.9362 - val_loss: 0.1853 - learning_rate: 1.1919e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.9984 - loss: 0.0090 - val_accuracy: 0.9325 - val_loss: 0.1975 - learning_rate: 1.1919e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.9987 - loss: 0.0083 - val_accuracy: 0.9375 - val_loss: 0.1853 - learning_rate: 1.1919e-04\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0MAAAF2CAYAAACs6EPYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAACSG0lEQVR4nO3dB3hU1dYG4C89hBR6D733XgQBFUHAhqhYwd7AX+XaC0VFrFhB1KtYEVCRa0EUUFCk995LQg2hJJCQnv/59skkkzCBJCSZ9r3Pc5x2MrMnwTmzzl5rbZ/MzMxMiIiIiIiIeBlfZw9ARERERETEGRQMiYiIiIiIV1IwJCIiIiIiXknBkIiIiIiIeCUFQyIiIiIi4pUUDImIiIiIiFdSMCQiIiIiIl5JwZCIiIiIiHglBUMiIiIiIuKVFAyJiIiIiIhXUjAkUgw+//xz+Pj4YOXKlc4eioiIeIBJkyaZ40qXLl2cPRQRj6ZgSERERMTFfPPNN6hbty6WL1+OnTt3Ons4Ih5LwZCIiIiIC9mzZw8WL16MCRMmoHLlyiYwckUJCQnOHoLIBVMwJFJK1qxZg/79+yM8PByhoaG47LLLsHTp0lz7pKamYuzYsWjUqBGCg4NRsWJF9OjRA3Pnzs3e5/Dhw7jzzjtRq1YtBAUFoXr16rjmmmuwd+9eJ7wrEREpbgx+ypcvj4EDB+L66693GAydPHkSjz32mJk94rGAx4ShQ4ciNjY2e5+kpCSMGTMGjRs3NscUHi+uu+467Nq1yzy+YMECk4rHS3s8nvB+poDb3HHHHebYxZ8dMGAAwsLCcOutt5rH/vnnH9xwww2oXbu2GUtkZKQZ25kzZ84a99atW3HjjTeaIK9MmTJo0qQJnnvuOfPYX3/9ZV73xx9/POvnpk6dah5bsmTJBf1uRfLyP+seESl2mzZtwsUXX2wCoSeffBIBAQH46KOP0Lt3byxcuDA7J5wHrfHjx+Oee+5B586dER8fb+qQVq9ejcsvv9zsM3jwYPN8Dz/8sDkIxsTEmGApKirK3BYREffG4IdBS2BgIG6++WZ8+OGHWLFiBTp16mQeP336tDmmbNmyBXfddRfat29vgqCffvoJ+/fvR6VKlZCeno4rr7wS8+fPx0033YRHHnkEp06dMseLjRs3okGDBoUeV1paGvr162dO0r355psICQkx93/33XdITEzEgw8+aE7iMbXv/fffN2PhYzbr16834+Yx8L777jPHLAZXP//8M8aNG2eOiQyk+P4HDRp01u+EY+7WrdsF/35FcskUkQs2ZcqUTP7vtGLFCoePX3vttZmBgYGZu3btyr7v4MGDmWFhYZk9e/bMvq9NmzaZAwcOzPd1Tpw4YV7njTfeKOZ3ICIirmDlypXmc37u3LnmdkZGRmatWrUyH3nkkex9Ro0aZfaZOXPmWT/P/emzzz4z+0yYMCHfff766y+zDy/t7dmzx9zPY5vNsGHDzH1PP/30Wc+XmJh41n3jx4/P9PHxydy3b1/2fTze8bhnf5/9eOiZZ57JDAoKyjx58mT2fTExMZn+/v6Zo0ePdvAbE7kwSpMTKWE8O/fHH3/g2muvRf369bPvZ7rCLbfcgkWLFpkZICpXrpyZ9dmxY4fD52JKAc8UMqXhxIkTpfYeRESkdHAGpGrVqrjkkkvMbaaGDRkyBNOmTTPHE/rhhx/Qpk2bs2ZPbPvb9uEMEbMI8tunKDj74+jYZF9HxFmqiy66iCfcTYo4HT16FH///beZyWI6XX7jYapfcnIyvv/+++z7pk+fbmalbrvttiKPWyQ/CoZEShgPAEwfYF50Xs2aNUNGRgaio6PN7RdffNHkgTO/u1WrVnjiiSdMWoENc7Ffe+01/Pbbb+Zg2bNnT7z++uumjkhERNwbgx0GPQyE2ESBXeS4MZX6yJEjJuWNmFrWsmXLcz4X9+Fxx9+/+Coi+FysTcqLadqsKapQoYKpK2I9UK9evcxjcXFx5nL37t3m8nzjbtq0qUkHtK+T4vWuXbuiYcOGxfZeRGwUDIm4EAY3PIB99tln5oDx3//+1+SC89Lm0Ucfxfbt201tEQtiX3jhBRNU2c6+iYiIe/rzzz9x6NAhExCxkY5tY8MBKu6ucvnNENlmoPLiCTlfX9+z9mVN66+//oqnnnoKs2bNMnVJtuYLPOFXWJwdYj0ta454TGSzIc0KSUlRAwWREsYzZCwy3bZtm8OuOjywsGDUhmfW2C2OG4tkGSCxsQKbKtiwiPQ///mP2ZhS17ZtW7z11lv4+uuvS+19iYhI8WKwU6VKFUycOPGsx2bOnGm6rE2ePNkcA9gE4Vy4z7Jly0yXUjYscIQd64gZCfb27dtX4DFv2LDBnKD74osvTBBjY98FlWxp4ucbN7Hhw8iRI/Htt9+ajnQcP1MFRUqCZoZESpifnx/69u2L//3vf7naXzPlga1C2ZWHXebo2LFjuX6W6QZMC2D+NDHdjq1S8x7w2OLUto+IiLgffulnwMMOcGynnXcbMWKE6QbHjnHsKrpu3TqHLahZp0Pch7U7H3zwQb771KlTxxyjWMtjb9KkSQUeN3/e/jlt1999992zTgzy5B4zH5hW52g8Nqx14lIUPMHHAPGKK64w94mUBM0MiRQjfsjPmTPnrPs5s8OzZAx8HnroIZN3zdbaDGBY82PTvHlz01q0Q4cOZoaIbbVZRMqDIPHsG9cnYsoE9+Xz8GDIwIpn0kRExD0xyGGwc/XVVzt8nDUztgVYeSKNxwau7cOGBDxmHD9+3DwHZ47YXIGzNF9++aWZYWGra7a0ZnODefPmmeMQ16eLiIgwz8E22EyZ48m1X375xSzZUFCs8eHPPf744zhw4IA5ucfmDY6a/Lz33nvmOMj0b7bWrlevnjlJyBS7tWvX5tqX42cQSC+99FKhf58iBXaB3ehExK61dn5bdHR05urVqzP79euXGRoamhkSEpJ5ySWXZC5evDjX87z88suZnTt3zixXrlxmmTJlMps2bZo5bty4zJSUFPN4bGxs5vDhw839ZcuWzYyIiMjs0qVL5owZM5z0zkVEpDhcddVVmcHBwZkJCQn57nPHHXdkBgQEmGPBsWPHMkeMGJFZs2ZNs3QD22+z/TUfs295/dxzz2XWq1fP/Fy1atUyr7/++lzLPBw9ejRz8ODB5rhUvnz5zPvvvz9z48aNDltr87jjyObNmzP79Oljjm+VKlXKvPfeezPXrVt31nMQn3vQoEHmOMf326RJk8wXXnjhrOdMTk424+Fx7syZM4X+fYoUlA//U/DQSURERESkZLGVdo0aNXDVVVfh008/dfZwxIOpZkhEREREXAq70nFpCvumDCIlQTNDIiIiIuIS2AGP6+uxTohNE1avXu3sIYmH08yQiIiIiLiEDz/8EA8++KBpMc4GECIlTTNDIiIiIiLilTQzJCIiIiIiXknBkIiIiIiIeCWPWHQ1IyMDBw8eRFhYmFk0TERESg+zrblYJNvg+vrqHJuNjk0iIq5/XPKIYIgHm8jISGcPQ0TEq0VHR6NWrVrOHobL0LFJRMT1j0seEQzxrJvtDYeHhzt7OCIiXiU+Pt586bd9FotFxyYREdc/LnlEMGRLP+DBRgccERHnUCpYbjo2iYi4/nFJyd0iIiIiIuKVFAyJiIiIiIhXUjAkIiIiIiJeySNqhkTEtdsLp6SkOHsYcgECAgLg5+fn7GGIiIgUOwVDIlJiGATt2bPHBETi3sqVK4dq1aqpSYKIiHgUBUMiUmILnh06dMjMKLC9pRbjdN+/Y2JiImJiYszt6tWrO3tIIiIixUbBkIiUiLS0NPMlmqs/h4SEOHs4cgHKlCljLhkQValSpdRT5v7++2+88cYbWLVqlQmwf/zxR1x77bXn/JkFCxZg5MiR2LRpkwnGn3/+edxxxx259pk4caJ53sOHD6NNmzZ4//330blz5+zHk5KS8J///AfTpk1DcnIy+vXrh0mTJqFq1aol9l5FRKR06VStiJSI9PR0cxkYGOjsoUgxsAW0qamppf7aCQkJJlhh8FIQTM0cOHAgLrnkEqxduxaPPvoo7rnnHvz+++/Z+0yfPt0ES6NHj8bq1avN8zPYsc2A0WOPPYaff/4Z3333HRYuXIiDBw/iuuuuK5H3KCIizuGTyRwID1hlNiIiAnFxcVrYTsRF8Kw6v5TWq1cPwcHBzh6OlODfszQ/g1mzdL6Zoaeeegq//vorNm7cmH3fTTfdhJMnT2LOnDnmdpcuXdCpUyd88MEH5jbr2jiD9PDDD+Ppp58276Vy5cqYOnUqrr/+erPP1q1b0axZMyxZsgRdu3Y971h1bBIRcY7CfP5qZsie+8eFIiJej8FKnz59ct3HWR/eb2vswZQ7+31Y08bbtn34OGfB7Pdp2rQpateunb2PiIi4P9UM0fJPgJVTgJ6PAy2VAiEixaNu3bomRYvbhWINDNO+Tpw4YTq7Sf5YA5S3roe3eabwzJkz5nfINE5H+3D2x/YcTPHM+7vmPnzMEdYVcbPh64lI6UtMScOR+GQciU9CzKlkxMQnmeu87+ipZLApZpC/L4ID/LIvbdeDct3niyD/3Jf2P+PosjAdN5mclZqeifSMTKRlZJjLc91OS+dl7tvW9UxklOIJfV8fH/j7+cDf1wd+vj4I8PM1l45u+/v55tzv6ws/u5/jpSt0KFUwRCejgJhNwLbfFAyJeLnevXujbdu2eOeddy74uVasWIGyZcsWy7jE9Y0fPx5jx4519jBEPFZSajpiGOScygluYrICHut2knn8VHKa08YYyMAoK6gK9PM1QYoV0GTkBDImqMlAhhKS4JcdKGUFSFmBlLnt54M7LqqHu3vUK9ExKBiiJgOAxe8BO34H0lMBvwBnj0hEXBTP5HFWwd///B+frDmR0sf1kI4cOZLrPt5m3jg747EbHjdH+/Bnbc/BdDrWGdnPDtnvk9czzzxjmjLYzwyxDknEHaWmZyAx2WqEU9IykYnTydZsTvYsTlaAw+AmxgQ/yYg7U/AGLiGBfqgWHowq4UGoEhaMquFBqBoejMphQWY2goFVMre0DOt61mVSagaS06zLXPenZWTvn5x129o/PVdQk5KWYTYkFT0gczzDwsus29mzK9asC29ztqa0joEZmciekUpLz8h1PWfm6uzbjvAxbvktzX4qqeSb9igYosjOQEhFIPEYELUUqHexs0ckIk7A1svsGsbt3XffNfdNmTIFd955J2bPnm3aM2/YsAF//PGH+ZLLL75Lly413c5YWM+ZAfsak7xpcjwAf/LJJ6a4n53NatasibfeegtXX311kcb7ww8/YNSoUdi5c6dZ/4fF/2wFbcM20G+//Taio6NNIenFF1+M77//3jzGS85i8GfZKa5du3b43//+5xEzWd26dTN/L3tz58419xPT3zp06ID58+dnN2JgAwXeHjFihLnNxwMCAsx9gwcPNvdt27YNUVFR2c+TV1BQkNlEXAW/ZMafSTVBhG07mXVpu/9kYord42mIy7qdkFI6gVBhMRWtWkQwqoadHehUybrkFhrkX6qBo33gZLtkUGQLYAL8bKlhvrlSzHKlkfn5wtfHOlZ45InEjMyzZsdMKiDvy7ptBVE5qYD8W5Y0BUPk6wc0vgJY+w2wbbaCIZES+iA8k+qcg2uZAL8CHVwYAG3fvh0tW7bEiy++aO7jOjXEDmNvvvkm6tevj/Lly5sAY8CAARg3bpz5Avzll1/iqquuMl+YWWSfHwYgr7/+ulnfhuva3Hrrrdi3bx8qVKhQqPfEAv8bb7wRY8aMwZAhQ7B48WI89NBDqFixognqVq5cif/7v//DV199hYsuugjHjx/HP//8Y36Wa/XcfPPNZhyDBg3CqVOnzGOu2lz09OnTJmizYVc7tszm74y/a87IHDhwwPwN6IEHHjBd4p588kncdddd+PPPPzFjxgwThNowkB02bBg6duxo1hZiWiSDWga+xODx7rvvNvvxdTirxGCTgVBBOsmJZ+L/I8cSUnDw5BmzHTiZlH2dn2+OvuCeVTdhf7Y/64txzm2mBvnapQxl7WP3s/woS0hOzwpsUvIENrkDn1MXMDtR2phSlhPM2IKcYFQJs7svPBjhwf4uFyzw78ItzNkDcWE+tjqj0l2mrkAUDNk06W8FQ1t/Bfq9wr+as0ck4lH4RaH5qJx1XkrT5hf7ISTw/B93/ALMWQPOlNhSoWwF9QyOLr/88ux9+QWZa9PYvPTSS6bl808//ZQ9u+AIAxUGIvTKK6/gvffew/Lly3HFFVcU6j1NmDABl112GV544QVzu3Hjxti8ebMJsvganMHgLM+VV16JsLAw1KlTx8z+2IIhLorLNXN4P7Vq1QquioEdm0fY2FLRGMx8/vnn5v3w/dqw/TcDH64TxAC3Vq1a+O9//2s6ytkwgDx69KiZWWNDBNaJse22fVMFzqqxyxxnhuwXXRXPxbP5h+OsAGd/VpBjbdZ9B06eMWf93U3ZQD9ElAlAREggIsr4W9eztnIhgQi3v213vWyQv5mpKA0M9lwtyBHvoGDIpv4lgF8QcHIfcHQrUKWZs0ckIi6EMwh5Zys4K8Mv3bbggp3K7L+UO9K6devs6wxWOONgv9BnQW3ZsgXXXHNNrvu6d+9uZjhY08TAjYEOZ7IYaHHjLBADPQZxDKQYAPELft++fc1aOpzxctWmFueatWJA5Ohn1qxZc87nZdB6rsCV6ylxodeCLvYqro3/ho6bWZ0kE9TkzO7kzPLEns7pBngunK2oWb4MapQrg5rlyqBGRLAJHPKvnchdQG9fUJ/TISz/29ndw7JuMwUsIiQnaMkJbALOCmx4m7MWIuKYgiGboFCgfi9gxx9WqpyCIZFiT1XjDI2zXvtC5a2lefzxx00dClPnGjZsaArzGVCw6P5cWIdij2dCWa9S3DgbtHr1atOSmzVOnAFh8MYOd2wIwLEztY6PMV3vueeew7Jly8ysioi7OxR3Bgu2HcXaqJM4GJcT8LAoviCfFzXKBZtApxYDnggr6LEFPlUjgkybZRHxDAqG8naVYzC0dTZwcU4RsohcOH7pL0iqmrMxTY4zK+fz77//mnQ0zrbYZor27t2L0sKGDRxD3jExXY6d0ogd79jQgdvo0aNNEMT6GabH8e/BmSRuDJQ4i8Q0P/tuaCLuggXsK/eewILtMViw9Si2HTl1zlmd7BmdrKDHum5dcnZF6Voi3sP1v5mUJjZRoAMrgVNHgLDcC/KJiOdjBzjOkDCwCQ0NzXfWplGjRpg5c6ZpmsAvTqzdKYkZnvywa1ynTp1MrRLrX5YsWWKaBthqWn755Rfs3r0bPXv2NOlv7K7G8TVp0sS8P3ZJY3pclSpVzG3WzzDAEnEXrO1ZsC0Gf22Lwb87j5nWzDasc2kbWQ7dG1ZCnYplTdBTq1yIZnVE5CwKhuyFVwdqtAcOrga2zwE6DHP2iESklDH9jYX5zZs3NzVAbK2dXwMDdipjp7ZKlSrhqaeeMuvKlJb27dubDmmc1WFAxNbabPLA2SriLBCDNabGJSUlmeDt22+/RYsWLUy90d9//23qizhmzgqxxXf//v1LbfwiRZn9WbXvhEl/YxC09XDu2Z+KZQPRq0ll9G5SBT0bVTKNAUREzscn01V7qRYCD+bsAhUXF2eKkS/IwjeAv14GGvcHbplWXEMU8Tr8As4WyKxBYSG6eO7fs1g/gz2Ifi/FM/uzkKlv245i0Y5YnLKb/fHJmv25pEkV9G5SGS1rRMC3tFqfiYjHfP5qZiivpgOsYGj3X0BKIhAY4uwRiYiIeM3sz2rO/mzn7M9RbDkUf/bsT+PKZgaoZ6PKKF9Wsz8icmEUDOVVpTlQrjZwMsoKiJoOdPaIRMQLcKHQr7/+2uFjt912GyZPnlzqYxIpDUfik7CQqW/bY/APZ3+Scs/+tKmVM/vTqqZmf0SkeCkYyoufvOwqt2yy1WJbwZCIlALW+7BeyRGlWIkn4Ro8q6NOZjU/OHv2p0LZQFPzc0nTKri4UWVzW0SkpCgYcqRJ/6xgaA6QkQ74qvOMiJQsdnXjJuKJWJ684UAcpq2Ixi/rDiI+z+xP61rl0LtxZRMAcfbHT7M/IlJKFAw5Uqc7EBQBJMYCB1YBkZ2dPSIRERG3cyIhBbPWHsD0FdG5ur+VDwlATwY/TTj7UwkVQ4OcOk4R8V4KhhzxCwAaXQ5s/B7Y+quCIRERkQLKyMjE4l3HMG1FFP7YdAQp6db6W4H+vujfshpu7BiJrvUravZHRFyCgqFzpcoxGNr2G3D5WGePRkRExKUdPHkG363cj+9WRWP/iTPZ9zevHo4hnSJxbduaiAgJcOoYRUTy8kURTJw40azSzrUmunTpguXLl+e7Lxf969ixo1kAsGzZsmjbti2++uqrXPtwkUCu4G6/XXHFFXCqhn0AX38gdhtwbJdzxyIiIuKCktPS8ev6Qxj62XJ0f+1PvD1vuwmEwoL9cXvXOvjl4R6Y/cjFGHZRXQVCIuIZM0PTp0/HyJEjTZtXBkJcwbxfv37Ytm2bw+LfChUq4LnnnkPTpk0RGBiIX375BXfeeafZlz9nw+DHfqX3oCAn5w+XKQfU7QHsXmDNDl00wrnjERERcRHbj5wydUA/rjmA4wkp2fd3q1/RzAJd0bIaggPUfEhEPHBmaMKECbj33ntNQNO8eXMTFIWEhOCzzz5zuH/v3r0xaNAgNGvWDA0aNMAjjzyC1q1bY9GiRbn2Y/BTrVq17K18+fJwOrbYJrbYFhEpIM6c80RRQXAmfNasWSU+JpELdTo5Dd8uj8K1E/9F37f/xqeL9phAqGp4EIZf0gALn+iNb+/rimvb1VQgJCKeOTOUkpKCVatW4Zlnnsm+z9fXF3369MGSJUsK1Frzzz//NLNIr732Wq7HFixYYGaLGARdeumlePnll1GxYkWHz5OcnGw2m/j43GsUFJvGVwC/PQlELQESjwMhFUrmdURERFwQj9ur9p0ws0C/bjiExJR0c7+/rw8ua1bFzAL1bFQZ/n5FyroXEXGvYCg2Nhbp6emoWrVqrvt5e+vWrfn+XFxcHGrWrGkCGD8/P0yaNAmXX355rhS56667DvXq1cOuXbvw7LPPon///ibA4v55jR8/HmPHlkJTg/J1gKotgSMbgR1/AG1uKvnXFBERcbKjp5Ixc/V+zFgZjV1HE7Lvr1+5LIZ0jMR17WuhcpjaYYuI+yuVUzlhYWFYu3YtVqxYgXHjxpmaI84E2dx00024+uqr0apVK1x77bWmroj72u9jjzNTDLBsW3R0dMkNXqlyIl7l448/Ro0aNZCRYbUDtrnmmmtw1113mRM2vM6TQKGhoejUqRPmzZtXbK+/YcMGMztepkwZMzt+33334fTp09mP83Oxc+fOpiENG9N0794d+/btM4+tW7cOl1xyifnMDQ8PR4cOHbBy5cpiG5t4trT0DPy59Qju/2oluo2fj/G/bTWBUJkAP9zQoRa+f6Ab5o/shft7NVAgJCLeOTNUqVIlM1Nz5MiRXPfzNut88sNUuoYNG5rr7Ca3ZcsWM7vDeiJH6tevb15r586duOyyy856nPVFpdZggS22/34d2DkfSEsG/HUAECmSzEwgNdE5rx0QYi1zXwA33HADHn74Yfz111/Znz/Hjx/HnDlzMHv2bBOYDBgwwJzY4efQl19+iauuusqk/9auXfuChpmQkGAay3Tr1s2cEIqJicE999yDESNG4PPPP0daWpo5YcS6zW+//dakLrObJ+uO6NZbb0W7du3w4Ycfms9qnoQKCFAHLzl/KtyHC3fhi8V7cSQ+JwW9bWQ5kwZ3ZevqCAvWvyMR8UyFCobYDY5nGufPn28OyMSzp7zNg3VB8Wfsa37y2r9/P44dO4bq1avD6aq3BcKqA6cOAXv+ARr1cfaIRNwTA6FXajjntZ89CASWLdCurFtkmu7UqVOzg6Hvv//enKDhrAtP7rRp0yZ7/5deegk//vgjfvrpp0J9DjrC10xKSjIBFmd+6IMPPjDBFussGdhwNvzKK680DWmIzWlsoqKi8MQTT5jundSoUaMLGo94h82H4vH6nG3meoWygRjUrqYJghpXDXP20EREXC9Njilun3zyCb744gszw/Pggw+as5nsLkdDhw7N1WCBM0Bz587F7t27zf5vvfWWWWfotttuM4/zLCsP3kuXLsXevXtNYMUUFM4k2bfedhpfX6uRAilVTsQrcIblhx9+yD5p880335h0XgZC/Mx6/PHHTRDCNDWmyvGzjYHIheLzMNCyBULENDieQOLME5cq4Lps/GxkgPTuu+/i0KFDuT6fOZPEpjavvvqqSekTOZ8lu45lt8Ve+sxleOHK5gqERMRrFHqdoSFDhuDo0aMYNWoUDh8+bNLemD5ia6rALwT8wmDDQOmhhx4ysz3MgecZy6+//to8DzGVY/369Sa4OnnypMnV79u3rznb6vS1hmyaDgRWTbHWGxr4VoHTbUQkT6oaZ2ic9dqFwECDqUO//vqrqQn6559/8Pbbb5vHGAjxBM+bb75pTtrwc+366683KWulgeux/d///Z/53OW6b88//7wZT9euXTFmzBjccsstZty//fYbRo8ejWnTppnlDUTys3T3cXPZu0llBPqrK5yIeJdCB0PEVJD80kHyNj1gi2xu+eEXid9//x0ure7FQEBZ4NRB4NBaoEY7Z49IxP3wJEIBU9WcLTg42HS45IwQaxebNGmC9u3bm8f+/fdfMztjCzA4U8RZ7eLA2SbWBvEkkm12iK/HE0wcgw3rgrhxFp71RUyvYzBEjRs3Nttjjz2Gm2++2QRPCoYkP+kZmVi+x5oZ6lrf8XIWIiKeTKeACiIgGGh4qXWds0Mi4hWpcpxh4YLSvG7DOpyZM2ea5gTs3saZmLyd5y7kNRmIDRs2DBs3bjRNHNjM4fbbbzez73v27DEBEJcdYAe5P/74Azt27DBB1JkzZ8xJKp6Q4mMMotiEwb6mSCSvrYfjEZ+UhtAgf7SoEe7s4YiIlDoFQwWlFtsiXoXtrVmjw1odBjw2EyZMME0WLrroIpNOx/od26zRhQoJCTEz5exex/Q8pt+xiQObKNge55pugwcPNrM/bLs9fPhw3H///SblmI1nWLfJx2688UbTCKJU1mQTt0+R61S3vBZOFRGvVKQ0Oa/UqB/g4wsc3gCcjAbKRTp7RCJSgpiadvDg2TVOdevWxZ9//pnrPgYk9gqTNsfaJHtcby3v89twdoid6/Lr9sl2255q4sSJeOONN0ytKptMvP/++2a9JUdSU1NN8x7Woh44cMCkGLIbHxf4tv872tZnsscaV74WcfmHhQsX5nqcgefkyZPhKZbutlLkuihFTkS8lE4DFVTZikCklZOvVDkRkdLDRhHslMeGEKtXrzbBEGfkuA6TI2wq8dFHH5mAafPmzXjggQdM3dSaNWuy92EKITvx2TY2obCtM2WPazrZ7/f666/DU2SYeiFrZkj1QiLirRQMFXYBVlKqnIgUABswsPW2o61FixbOHp7bYGoigxIu4dC8eXMzM8OUQdZzOcLlG5599lmzOC4X8eYSELzOpR1sKleubBYLt22//PKLWbupV69euZ6Lr2O/X3i459TVbDkcj7gzqSgb6IeWqhcSES+lNLnC1g3NfQHYuwhIigOCI5w9IhFxYVdffTW6dOni8DEuoCrnx5blq1atyrV+HVMYuZYSG0k4wvWh2Igib+fSRYsW5fsaXPKBs08+eZZOYEDLxxgIsUbshRdeMAGSR9UL1augeiER8VoKhgqjUkOgYiPg2A5g53yg5XXOHpGIuLCwsDCzSdHFxsYiPT09ey07G95mMwlHmELH2aSePXua2R4u5s0OgHweR2bNmmXWuWPLdHtsnFGnTh2z/h3Xw3vqqadMQw0+V35BmG2hXoqPj4c71AspRU5EvJlOBRVWU1tXOdUNiYi4onfffde0QOci32wswZbjTLGzXxDc3qeffmo67zHoscdufQys2NSCbc+//PJL08Bi165dDp+HTRsiIiKyt8hI1220o3ohERGLgqGittje8TuQnurs0Yi4vLzd0sQ9OevvWKlSJdM2/MiRI7nu522mrjnCeiDO9nDxWnaM4wwS67RYP5QXH583bx7uueee847FlvLIhXgdYSpfXFxc9hYdHQ1XtfXwKdULiYgoGCqCWp2AkIpWzVCU43x1EYH5AmurxxD3l5iY6JRaJ87sdOjQwaS62XCRW97u1q3bOX+WdUM1a9ZEWloafvjhB1xzzTVn7TNlyhRUqVIFAwcOPO9YuNAuVa9e3eHjQUFBpsGC/ebqKXKqFxIRb6eaocLy9QMaXwGs/cZKlavX09kjEnFJ/v7+ptD86NGj5gt0filK4vozQgyE2Ma6XLly2UFuaWJjg2HDhqFjx45mbaF33nnHzPow9Y240CyDHqap0bJly8z6Qm3btjWXY8aMMQHUk08+met5eR+DIT43/73aYyrc1KlTTRe6ihUrmpqhxx57zNQhtW7dGh6zvlA9pciJiHdTMFTUVDkGQ1t/Bfq9AuTpPiQi/N/Cx5xB37Nnj8PFLcW9MBDKLy2tpA0ZMsQE1aNGjTKLrjLImTNnTnZThaioqFzBdlJSkllraPfu3SY9jgEN223zPdhjehx/9q677nI4I8XHbYEX638GDx5sntfdsV5oWXa9UAVnD0dExKl8Mj0goZ8de1isyhztUklLSEkAXqsHpCcDDy4BqjYv+dcUcVM8+65UOffGmb1zzQiV+mewm3DV38vmg/EY8N4/pl5o7ei+CFCanIh48eevZoaKIrAsUL+31USBC7AqGBLJF8/Y513zRUScnyLXsW4FBUIi4vX0KVhUTfpbl2qxLSIibkTrC4mI5FAwdKHB0IGVwKncLV9FRERcdn2hvaoXEhGxUTBUVGHVgJodrOvbNTskIiKub9uRUziZmLW+UM0IZw9HRMTpFAxdCKXKiYiIG1G9kIhIbvokvNAW27R7gdVhTkRExB3WF1KKnIiIoWDoQlRpDpSrA6QlWQGRiIiIW6wvpOYJIiKkYOhCcLFV2+zQ1tnOHo2IiMh564VCAv3QSvVCIiKGgqHiqhvaPgfISHf2aERERBxSvZCIyNn0aXih6lwEBEcAibHA/pXOHo2IiMh51hdSvZCIiI2CoQvlFwA06mtd36ZUORERcdH1hVQvJCJyFgVDxdpiW8GQiIi4nu0xp3BC9UIiImdRMFQcGvYBfP2B2O1A7E5nj0ZERCSXpbtULyQi4kiRPhEnTpyIunXrIjg4GF26dMHy5cvz3XfmzJno2LEjypUrh7Jly6Jt27b46quvcu2TmZmJUaNGoXr16ihTpgz69OmDHTt2wG2wZqhuD+v6di3AKiIirmXpbitFrks91QuJiFxQMDR9+nSMHDkSo0ePxurVq9GmTRv069cPMTExDvevUKECnnvuOSxZsgTr16/HnXfeabbff/89e5/XX38d7733HiZPnoxly5aZoInPmZSUBLfRZKB1uU3BkIiIuNr6QrbmCaoXEhG5oGBowoQJuPfee01A07x5cxPAhISE4LPPPnO4f+/evTFo0CA0a9YMDRo0wCOPPILWrVtj0aJF2bNC77zzDp5//nlcc8015rEvv/wSBw8exKxZs+A2mlxhXUYtARKsg46IiIir1AuVCfBD61qqFxIRKXIwlJKSglWrVpk0tuwn8PU1tznzcz4MfObPn49t27ahZ8+e5r49e/bg8OHDuZ4zIiLCpN8V5DldRrnaQNVWQGYGsOMPZ49GREQkT71QedULiYjk4Y9CiI2NRXp6OqpWrZrrft7eunVrvj8XFxeHmjVrIjk5GX5+fpg0aRIuv/xy8xgDIdtz5H1O22N58Xm42cTHx8Nlusod2WB1lWt7s7NHIyIigmVqqS0ikq9SOUUUFhaGtWvXYsWKFRg3bpypOVqwYEGRn2/8+PFm9si2RUZGwiU0HWBd7pwPpLpRvZOIiHhwvZCCIRGRYgmGKlWqZGZ2jhw5kut+3q5WrVr+L+Lri4YNG5pOcv/5z39w/fXXm4CGbD9XmOd85plnzGyTbYuOjoZLqN4WCKsOpCYAe/9x9mhERMTL7Yg5jeMJKaoXEhEpjmAoMDAQHTp0MHU/NhkZGeZ2t27dCvw8/Blbmlu9evVM0GP/nEx7Y1e5/J4zKCgI4eHhuTaX4OOjBVhFRMRlLN2teiERkXMp9CcjU9w++eQTfPHFF9iyZQsefPBBJCQkmO5yNHToUDNzY8MZoLlz52L37t1m/7feesusM3TbbbeZx318fPDoo4/i5Zdfxk8//YQNGzaY56hRowauvfZauJ0mA3JabGdmOns0IiLixWzBkFLkRESKoYECDRkyBEePHjWLpLLBAVPf5syZk90AISoqyqTF2TBQeuihh7B//36zoGrTpk3x9ddfm+exefLJJ81+9913H06ePIkePXqY5+Sirm6nXk8gMBQ4dQg4tBao0c7ZIxIREXh7vZAWWxURccQnk/2u3RzT6thIgfVDLpEyN/12YMtPQK+ngEuedfZoRES86zPYRTj797Lt8Cn0e+dvUy+0bnRfBPorTU5EvEN8IT5/9clYkqlyW1U3JCIizq8XUiAkIuKYPh1LQqO+gI+vtebQyShnj0ZExO1NnDgRdevWNenTXJR7+fLl+e6bmpqKF198EQ0aNDD7t2nTxqRe2xszZoypWbXfmMZtLykpCcOHD0fFihURGhqKwYMHn9X51JUt26N6IRGR81EwVBLKVgRqZ3XC25b7ACwiIoUzffp007xn9OjRWL16tQlu+vXrh5iYGIf7P//88/joo4/w/vvvY/PmzXjggQcwaNAgrFmzJtd+LVq0wKFDh7K3RYsW5Xr8sccew88//4zvvvsOCxcuxMGDB3HdddfBHTADfulu1QuJiJyPgqGSohbbIiLFYsKECbj33ntN19LmzZtj8uTJCAkJwWeffeZwf3YsffbZZzFgwADUr1/fdD3ldXYztefv72+WdrBtXEvPhnnmn376qXntSy+91CwrMWXKFCxevBhLly6FO60v1KpmOWcPR0TEZSkYKum6ob2LgKQ4Z49GRMQtpaSkYNWqVejTp0/2fexYyttLlixx+DNcxy5vN1J2M80787Njxw6zjAMDpltvvdV0Q7XhazLdzv51mUZXu3btfF/XFeuFOtRRvZCIyLnoE7KkVGwAVGoMZKQCO+c5ezQiIm4pNjYW6enp2cs32PA2l3dwhCl0nNFhsMNFvrnW3cyZM00qnA3rjj7//HNTS/Thhx9iz549uPjii3Hq1CnzOJ+bC42XK1euwK/LIIwdjOw3568vpBQ5EZFzUTBUWguwiohIqXj33XfRqFEjM5PDgGbEiBEmxc5+Dbz+/fvjhhtuQOvWrU3wNHv2bLPO3YwZM4r8ulxknK1cbVtkZCScXy+k5gkiIueiYKg0gqEdfwDpqc4ejYiI22Edj5+f31ld3HibdT6OVK5cGbNmzTKLee/btw9bt2413eCYDpcfzgA1btwYO3fuNLf53EzRY4BU0Nd95plnTK2RbYuOjoYz64WCA3zRupbqhUREzkXBUEmq1REIqWTVDO1b7OzRiIi4Hc7ssHnB/Pnzs+9j6htvd+uW1bUzH6wbqlmzJtLS0vDDDz/gmmuuyXff06dPY9euXahevbq5zdcMCAjI9brbtm0zdUX5vW5QUJBZ3M9+c4ZltvWF6lRQvZCIyHnoU7Ik+foBja+writVTkSkSNhW+5NPPsEXX3yBLVu2mO5wnPVh6hsNHTrUzMrYLFu2zNQI7d69G//88w+uuOIKE0A9+eST2fs8/vjjpl323r17TYc4tt7mDNTNN99sHmea2913321e+6+//jINFfh6DIS6du0KV6aW2iIiBedfiH2lKJoOANZ+bbXYvmI84OPj7BGJiLiVIUOG4OjRoxg1apRpXtC2bVvT+MDWVIGzNfb1QFwslWsNMRhiehzbarPdtn0zhP3795vA59ixYyatrkePHqZlNq/bvP322+Z5udgqmyOwtmjSpElwZVa9kBZbFREpKJ9MfnK6OXbs4Vk85mg7Ky0hXykJwOv1gbQk4MElQNXmzh6RiIj3fAZ72e9lx5FTuPztv0290PrR/ZQmJyJeKb4Qn7/6lCxpgWWB+r2t69t+dfZoRETEg2l9IRGRwtEnZWlo0t+6VN2QiIiURr1QPaXIiYgUhIKh0mBronBgFXDK8WJ9IiIixVYv1EDBkIhIQSgYKg1h1YCaHa3r2+c4ezQiIuKBdsacxrHs9YUinD0cERG3oGCotFPlts529khERMQDLd1zPLteKMjfz9nDERFxCwqGSkuTAdbl7gVWhzkREZFilJ0ip3ohEZECUzBUWqo0A8rVAdKTgV1/OXs0IiLiYfVCy1QvJCJSaAqGSgsXW2060LqurnIiIlKMdh09jdjTKQjyV72QiEhhKBhyRt0QmyhkpDt7NCIi4iGWZLXUVr2QiEjhKBgqTbW7AcERQGIssPcfZ49GREQ8rV6ovlLkREQKQ8FQafILAFpeb11fOcXZoxEREU+rF1IwJCKeIO4AsOZrIHZnib+Uf4m/guTW8S5g5afA1l+sBVi5BpGIiEgR7TqakF0v1CZS9UIi4oaSTwF7F1lNxnb/BcRut+6/9Hmg5xMl+tIKhkpbtZZAZBcgehmw5qsS/wOLiIh3pMipXkjEy2RmAsd3Zy3bchqo1hqo0RYoUx4uLz0NOLg6J/jZvwLISMt53McXqNEeCKte4kNRMOSs2SEGQ6u+AHqMBHx18BIRkaJRvZCIF0k8bgU/DCB2LQDios7ep3xdoEa7nK16G6tm3RUCt11/WuPf8w+QHJd7n/L1gAaXAPUvAepdXGpBnYIhZ2h+LTDnaSAuGtgxF2hyhbNHJCIiblovtDSrk5yCIREPlJYMRC3NCn7+Ag6t4//5OY/7BlgZR2UrWY+d2AOc2Gttm37M2a9Cg6zgqK11yVmk4HDnBm7B5YD6vazgh0EQgzgnKFIwNHHiRLzxxhs4fPgw2rRpg/fffx+dO3d2uO8nn3yCL7/8Ehs3bjS3O3TogFdeeSXX/nfccQe++OKLXD/Xr18/zJkzBx4pIBhoeyuw5ANg5WcKhkRE5ALqhZJVLyTiKTiDcmRTTvCzbzGQdib3PpWb5cyg1LkICArNHYAwKDq0Fji4xtpORgHHd1nbxu+zdvQBKjUCqmcFRyZAapX7uUoicKvdFajf2xo/X9sFsqMKHQxNnz4dI0eOxOTJk9GlSxe88847JnDZtm0bqlSpctb+CxYswM0334yLLroIwcHBeO2119C3b19s2rQJNWvWzN7viiuuwJQpOR3WgoKCUJrS0jOQlpGJ4AC/0kuVYzC04w/gxD6gfJ3SeV0REfG4FLn2tVUvJMUkI8P6MsuTtcd2Ai0GAZ3vA0IqOHtkniv+UE4AwZmUhJjcj4dWtQIIBj+8DD9HHQ3/Tgw0uNkkHMsdHB1cC8Tvt5oUxG4HNszI2tEHqNwkd4pd1ZZAYMg5AreNOXU/+5acHbhVaZ4z88PALbAsXI1PJufYC4EBUKdOnfDBBx+Y2xkZGYiMjMTDDz+Mp59++rw/n56ejvLly5ufHzp0aPbM0MmTJzFr1qwivYn4+HhEREQgLi4O4eGFn/J7ZfYWfLlkL56+oinu6F4PpebLa6x/9Bf/B7hsVOm9rohIMbrQz2BPVRq/lxFTV+OX9YfwWJ/GeKRPoxJ5DfESp2OsVsarv7BSrOwFlAU63gl0Gw6E13DWCD1H8mlg3785QcTRrbkf9y8D1O2eE0QwoPDxKd4xnD6aJ0BaA5w6dPZ+Pn5A5aY5KXacPTq2yxq3CdyOOgjcssbNwM1JXZML8/lbqJmhlJQUrFq1Cs8880z2fb6+vujTpw+WLFlSoOdITExEamoqKlSocNYMEmeWGChdeumlePnll1GxouP85+TkZLPZv+ELUSbAD0mpGVi/P08hV2nMDvEf0uovgV5PA/6Bpfv6IiLi3usL7bHVC+msvRQBz4dzEXjOAm35BchIte4PigDa3ARUbw0smwwc3mBlsyz7yLq/+6NApYbOHr37yEi3gg1b8BO9POd3bfhYgYYtiGANkH8JZ0iFVgYaXW5tNlzy5WCeAImzVDGbrG3t12c/T0AIUKd7TtpelWbFH7iVsEIFQ7GxsWZmp2rVqrnu5+2tW/NEtfl46qmnUKNGDRNA2afIXXfddahXrx527dqFZ599Fv379zcBlp/f2dP+48ePx9ixY1FcbHnW6/afRKlqMgAIrQacPmytO9TyutJ9fRERcVu7YxNw9JStXqics4cj7oR1JWunAqumWKlwNjU7WjNALa7LSY1ijfPO+cCiCdZsBpcF4QxS86utjrj8Ei+5A0zOsrGRAVPITOe0v4GkPCfcy9XOCX7q9XKNNMSwalYdu62Wne+Fs0X26XV8T2x3bQt+IjuXfODmSd3kXn31VUybNs3MArF+yOamm27Kvt6qVSu0bt0aDRo0MPtddtllZz0PZ6ZYt2Q/M8RUvaJqXatc9oHlVFIqwoIDUCr8AoD2Q4G/X7fOyigYEhGRItQLlVq9q7gvfrFlcTsDoE2zgPSsDJvAUKD1jUCHO62ZoLx4lr9RH2uLWgYsehvY/huw+X/W1uBSKyiq28PtZgQuqFEAmxIwnfC4rXubXRe31MSzf4azbWwXbQsiKtR3/d+Xj4+VFsmt6UB4qkIFQ5UqVTIzNUeOHMl1P29Xq3bunMA333zTBEPz5s0zwc651K9f37zWzp07HQZDbK5QnA0WKoUGoWa5Mjhw8gw2HIjDRQ0qodR0GAb886Y1TX10O1C5cem9toiIuC211JYCOXMSWD8dWDkFOLol5362Vma6fqvrgaCwgj1X7S7ALdOsbmeL3gE2/mCtG8ONs0oXjwQa92cNBdw+cDxzwgpwcgU7+6zb8Qdyd0nLiwuGhtcCKtSzgkQGP6y58dOKNq6oUH+VwMBA0xp7/vz5uPbaa7MbKPD2iBEj8v25119/HePGjcPvv/+Ojh07nvd19u/fj2PHjqF69ZJfddY+VY7BEOuGSjUYiqgFNL4C2Dbbmh3q/2rpvbaIiLjx+kK2xVZdIL1GXO/L/IHV1vcKBiy2Dl8szG812AqCarQv+sxE1RbA4E+AS58DFr8PrP4KOLASmHaLVWzPmiIGWcyAcVXpaVZHtbwzO+b2vrMXBM2LTSW4Lg4DHl6arZ51OyJSdeBupNAhKtPThg0bZoIarhXE1toJCQm48847zePsEMeW2azrIbbSHjVqFKZOnYq6deuatYkoNDTUbKdPnzb1P4MHDzazS6wZevLJJ9GwYUPTsru0MFVu9obDWF/adUPU8W4rGFo31eoql18LQxEREbt6oUB3qxdiatHvz1qpWbYvj7YvlGUru37akKtLPgVs+M4Kgtj0wIbdyJgGx3S4MsX474V/u4FvAb2eApZOAlZ8anVGm/UA8NcrwEUPA+1uc+73GgaGcftzOqdx7Rt2Q+PC9xlp5/5Z1nVnBzt2/1Z5qX+v3hsMDRkyBEePHjUBDgObtm3bmsVRbU0VoqKiTIc5mw8//NB0obv++utzPc/o0aMxZswYk3a3fv16s+gq22uzuQLXIXrppZdKda2h1rWymihEl3JHOWK+bbk6wMl9wKaZ1geHiIjIeeuFyrlXvdCf44AtP5/7THuus+1Zlyw215n2/PELPtPgGAilnLbu8wuy1gjiLBCL3Evyi3toFaDPGKDHY1ZAxMAoLgr47Qlg4WtA1weBTvcUbyDmSK6Cf7uuaImxjvfn74jrPNr+ndn/2+P3Mp2c9gqFXmfIU9dyYOOE1mP/MP8frXq+DyqGlnJnDBYkzhsD1OwA3Ptn6b62iIiLr6czceJEvPHGG+YkXJs2bfD++++b7ARHuHwDsxN4ku3AgQNo0qSJyVJg51IbPj5z5kzTCbVMmTJmYXDuw31tevfujYULF+Z67vvvv98sOu7s38vD367Bz+sO4tE+jfBoHzepNeW6Jm83B9JTrBkDdteypSQxXSkz4xw/7GOllecXLLlCJ67SlpIAbJxpNUQ4sCrn/ooNrQCozc3O+72kngHWfgP8+641G0iBYUCnu4Cuw4Gw3F2Ji+zUkZyAxzbzczp3Xbvh62+1fGbdTvW2Viof/92wK5q71zdJ6a4z5MnYQa5+pbLYdTTB1A1d0rRK6Q6g7W3WGTN+oPFshlpViogY06dPNynaDEK48DfTs5lGvW3bNrM+XV7PP/88vv76a3zyySdo2rSpqVcdNGgQFi9ejHbt2pl9GOQMHz7cLCKelpZmlnRgVsLmzZtRtmzOCun33nsvXnzxxezbISEhrrG+UHa9kBs1T1j9uRUIsdC+78u5H0tLyenOlat2I+s2u3MxrYkbGw7lFRyRu27DPmBiIbunFK6npwIxW6z21uum59S1+AYAza6ygiBX6OoWUMaaCWp/h5XxwhO+MZut4GjpZKDtLUD3/7M6qhV5kdC1wKmD518klLVRrHEKyOliLGJPM0N2Rk5fi5lrDjjvTNv3dwMbvwfaDwOufq/0X19ExAVnhhgAMWj54IMPshv3cDmFhx9+GE8//fRZ+zPd+rnnnjPBjg3rUjkDxCDJEaZ/M7BikNSzZ8/smSGmgjP4cqXfy+6jp3HpWwtNvdD60X3dI02OxervtLK+vA76GGgzpOA/y68pXOXeYaH7XmutvnPhrAAL2vOr/ShoJ7XSkj1j5uC9svYlMz1nX46/wx3WCVUuoumqMjKAHb8D/0wA9i/P6bjG9Yx6PApUa5V7/4RjwCH7VLe11uxhXnyOSk3sAp92QNWWSm8TaGboAuqGGAxxZsgpeEaHwRBzfvu+ZJ3pEhHxYqw5XbVqlVlfzoZ1qVy4mwtzO5KcnJxrLTtiILRo0aJ8X4cHTKpQIXda0TfffGMCKDb4ueqqq/DCCy84fXbI1lLbreqFuLA4AyEWnbewutEWGGc5WJPCja2d80pJtGpuHQUQvJ+zUea+PY6fP6SS49Q73mYBfXGnUWWkA/EH858FY0vnc2FHOK75w+8M9Xq7R5oXx9ikv9U9d99iawHXnfOs7zzcGvUFIrsAh9dbwY8ttS4XH6BSo6zAJyvdjUFUUKgT3pB4EgVDdlpndeRhRzlOmPmU9jRznYusqV12Ylk/A+h8b+m+voiIi4mNjUV6enp2kx4b3ma9jyNMoZswYYKZ4eEC3lz+gfVBfB5HONP06KOPonv37mjZsmX2/bfccgvq1KljZprY6Oepp54yqXl8rvyCMG72ZyZLwlJ3TJFb/ol1yVmM4l6tnrMArAfh5mhGgkGYo8UxefvMcau4nhtbQ+flH2wV0jsKllh4z3Sw/Op5WAvlKNjhF30GaOfCoNHRLBZvh1Z1jwDIEX6vqtvd2g6tt9LnNs8CdvxhbfYqNMgJfEzw09r1ZvHEIygYstO8ejj8fX0QezoFB+OSzEKspf4hwTM9vz1ptcVkvq2z835FRNzMu+++a2p9WC/Ek1oMiLj8w2effeZwf6bTbdy48ayZo/vuuy/7eqtWrczad1wInEtA8DnzYlMGLhVRWusLdannJsHQ4Y3AvkVWLQePcaWJQQMbL3BjLY2jlDQTpDgIlk5GA2lJQOw2a3OEBfi2gIUNIGw/66iIP9e4AqwOeQ6DrLreMdvB4OaGKcCx54FlH1kBafU2WYFPG2XHSKlRMGSH6QZNqoVh08F4rI8+WfrBELUeYnWVY6Fh1FKgTrfSH4OIiIuoVKmSWYLhyJHcXy55m6lrjlSuXBmzZs1CUlKSWcCbMzusLapf/+xibS4Y/ssvv+Dvv/9GrVq1zlu7RDt37nQYDDGVj40e7GeGWNtUnPbEJiAma32hdrXdZH2h5R9blyzwD68Bl8Iv3Pzizc1RnRMbNjhMZ9sLJMdbbZy5RS128Nzl8k+/C68J+LpJimNJq9gAGPC6s0chXkzBkIPFVxkMrdsfh/6tqpf+ANiDv+Vgq1MMZ4cUDImIFwsMDESHDh1Mqtu1116bndbG2wxkzoV1Q1wEnK22f/jhB9x44425ZljYgOHHH3/EggULUK9evfOOZe3ateaSM0SOcG28kl4fz1Yv1C7STeqFWP/CtG/qcj/cCjvQMXDhhkvOburA92aCo6yNxfwMeGzBT5nyzhq5iBSCgqE82tSKwLfLrbohp2EaAYMh5tFeMR4oW8l5YxERcTLOtgwbNgwdO3Y0awuxu1tCQoJJfaOhQ4eaoIdparRs2TKzvhA7wfGSC3wzgHryySdzpcZNnToV//vf/xAWFmbWLyJ2H2KzBabC8fEBAwagYsWKpmboscceM3VIrVu3dtJvAli2x83qhdZ8DaSdAaq2Amp70Mk9prBzDR9utTo4ezQicgEUDDmYGaIN++OQkZEJX18n1OzUbG/lzLKjChct6/5I6Y9BRMRFDBkyxLS+HjVqlAlaGOTMmTMnu6lCVFSU6TBnw/Q4rjW0e/duhIaGmoDmq6++QrlyOWllH374YXb7bHtTpkzBHXfcYWak5s2blx14Md2N7bn5vM5iXy/kFsEQu6at+K91nQ2BVAMrIi5IwVAejauGIjjAF6eS07DnWAIaVA513uzQTw8DK6cA3R52384xIiLFgClx+aXFMc3NXq9evcziqedyviX2GPxwzSFXsvdYIo7Eu1G90I65Vm0Na2da3eDs0YiIOKRv2Hn4+/miRQ2rg4lTU+VYNxQUYeUh7/7LeeMQERGXYJsVcpt6IVvjhPa3axFMEXFZCobyWXyV1kU7afFVCiwLtLnJus5GCiIi4tXcKkUudgewa761UCaXiRARcVEKhhxok1U3tM6ZM0NkW49h229A3AHnjkVERJwm1/pC9SvAbRZZbXyF1VlNRMRFKRg6x8zQ5oPxSE3PcN5AqjQF6nQHMtOB1V86bxwiIuIa9UJ+vmhf28VbNiefAtZOta53yVm4VkTEFSkYcqBuxbIIC/ZHcloGth0+5RqzQ6u/sBaAExERr2ObFWpb2w3qhdZNA1JOARUbAfXzrM8jIuJiFAw5wHbattmh9fudWDdkW7E7pJK1wvX235w7FvEM6anOHoGIFNIyd6kXYpc+W+OEzvepnbaIuDwFQ+dZb8ipHeXIPwhod5t1XY0U5EKcOgJ8dR3wUmXgvXbA93cDSyYBUUuBlERnj05EzlkvdNxc7+rq9UK7FwCx24HAMKDtzc4ejYjIeWmdoXy0sXWUc/bMEHW4A/j3XWDXn8CxXUDFBs4ekbibvYuA7+8CTh+xbh/fbW0bv7du+/gBVZsDNdoDNTtYW+WmgJ8+IkScbd+xRByOT3KPeiHbrBADoaAwZ49GROS89E3nPDND24+cwpmUdJQJdGKOdoV6QMPLgJ3zgFWfA31fct5YxL1kZAD/vgP8+RKQmQFUbgZcMxFIOgkcXA0c4LbKCpIOb7A21qdRQAhQvY0VGNVoZ12yK5TSXkRKldvUC53YZ3U/pU73Ons0IiIFomAoH9UjglEpNAixp5Ox+VAcOtRxcmpCx7utYGjN18Clz1vpcyLnkngcmPUgsH2Odbv1TcCVE6w1rIgBti3HP/6gFRRxM0HSGqsAOmqJtdmUqQDUzJo9MrNI7YHQKk54cyLew23WF1rxX36gWE0TKjd29mhERApEwVA+fHx80DYyAvO2xJjFV50eDDXqC4TXBOIPAJv/B7S+0bnjEde2fxXw3R1AXBTgFwQMeANoP9TxrA7vi6hpbc2vzplROrYjZ+aIARJnjc4ct4JybjYRtYGa7XICpBptlR4jUhL1QvVcuF6IdYe2JSC63O/s0YiIFJiCofOkyjEYcnoTBWLtBmuH/hpnNVLwxmAoJcFq2criXH7prtsdiKjl7FG5Zien358DMlKB8vWAG78Eqrcu3PP4+gKVm1ibrQg6LRk4silrBmm1FSAd3WYFXNwYpBs+Vr0RZ42qNAfKRQLhtay/VdnK1nOLSKHrhdq5cr0Q6w+ZfluutnXyTkTETSgYOgeXaa9t0+52YMGrVtoSv5RWbQGvcDLK+oLPs45Jef4W5eoAdXtYi9MyOOJtb61pSYoHfnoY2DzLut3sauCaD4Bg69/xBWNqpkmRa5/7NQ+tzZlB4mX8fuDoFmvLyy/QmuFkYBQRmXVpd5uPBYUWz3hFPMCyPVn1QpHlnFu7WtB22qwV8nXRcYqIOKBgqABNFHbHJiDuTCoiygQ4d0Dh1YGmA4EtPwErpwAD34TH4sGVQd/SD4Gtv1jF/1ShvpWPzlmJQ+uAk/uAtdy+sR7nDESdi6zAqE4Pq/OeNwRHhzcCM4YCx3cBvv5A35eBLg+U/HsPDgfq9bQ2+xbetuYMx3ZaqZ1x+621stJTgBN7rC0/ZcpbwZFtNil7ywqewqrpy5Z4Dbdoqc32/Eyj9S+TsxSEiIibUDB0DhXKBiKyQhlEHz+DjQfi0L1hJWcPCeh4lxUMMV2szxjPO4vOVKyNM4Glk4DD63Pur98b6PKglX5hS7PirET0Mqtt9L7F1hdwzkpsmGFtFFotd3DEtC9PC45WfwXMfhxIS7ICiBs+ByI7OW88YVWBJv2tLe9irwyIGBiZLRqIywqUbFtyHHDmhLXxy5UjbAMeXuPsQKnJAOuEgYhH1Qu5QfOE5R9Zl61vAEJcOGgTEXFAwVABZocYDK3bf9I1gqF6vYAKDawZAOZos47IE5yOsWqhVnwKJMRY9/kHA62HWDMcXAPH0axEo8utzVZTFL0c2PcvsPdf4MBK4PRhYNNMa6OQSlnBUVZqHWta3LWGhQXLDIJss2INLwcGfQSUddEvTX4BVj0Bt/wwDTI7QIrOmVXKvn0QyEjLCqSic//s3FFA72esfy9aH0k8QNTxRByKc/F6If4/ueVn63rn+5w9GhGRQtM3hgIsvvrr+kNYH+0idUP84t7xTuCP563Aof0w957pOLgWWDYZ2PiDlUJFYTWAzvcA7e8o3Bd7toxucIm1UeoZYP/KrOBoEbB/BZAYa82scbOlZNW2zRxdBFRr7R4pWLE7gBnDgJhNgI8vcMmzQI//uG9gZ8P6Jm6Ogl/KSLfWRLKfTeIWvdRKm/zjOWDdt8CVbwORnUt79CIls76QK9cLMWWbJyj4OVqtlbNHIyJSOsHQxIkT8cYbb+Dw4cNo06YN3n//fXTu7PiLxyeffIIvv/wSGzduNLc7dOiAV155Jdf+TAUYPXq02ffkyZPo3r07PvzwQzRq1AiuUjfkEh3lbNreCsx/yUojY11GrQ5wK+lpwLZfgaWTgajFOffX6mSd1W9+jTWLcKECygD1LrY2WwrewTVZaXX/AlHLrHQsjoUbBYUDtbtmNWToAVRv63qzDEwjZKOElNNA2SrA9Z/mrtnxZL5ZKXLc7IMdtgJf8yUwdzRwZCPw6eXWiQKmkiptR9y8XqiLq9YL8TN11RTrehfNComIeyr0aeTp06dj5MiRJnhZvXq1CYb69euHmJis1KY8FixYgJtvvhl//fUXlixZgsjISPTt2xcHDhzI3uf111/He++9h8mTJ2PZsmUoW7asec6kpCQ4W8uaEWbi5WBcEo6eSoZL4Je7FoOs6ys/hdtg4PHve8B7ba1ifwZCLPZvdQNwz5/APfOAVtcXTyCUXzc0Bjo9Hwdu/xF4eh9wz3ygz1irFomBUHI8sOMPYN5o4L+XAW/UB2beZ7WNTj4Np3/xmP0E8P2dViDEGqgH/vGeQOhcOCPGlNGHV1knC2j1F8AHHYG1U62GHCJuxC3qhfi5mHDUms1veqWzRyMiUiQ+mfzELYQuXbqgU6dO+OCDD8ztjIwME+A8/PDDePrpp8/78+np6Shfvrz5+aFDh5oP/Bo1auA///kPHn/8cbNPXFwcqlatis8//xw33XTTeZ8zPj4eERER5ufCw8NR3C6fsBA7Yk7j02EdcVmzqnAJnNX4rK9VV/OfrVa6l6s6ut1KhWP6UmqidV+ZClYziE53W2f5XQFTsDjbxmYMrDni7BHXzbDh4qVs5NB0gFWsH1ql9MZ2Yp+1iCqbRNDF/wF6P+t6s1augn/DX0bmtPfmTN/At4AqzZw9Mo9U0p/B3vh7ycjIxLwtR8zs0BP9mrhmmtx/+1jpx5c8D/R6wtmjEREp0udvob5JpaSkYNWqVXjmmWey7/P19UWfPn3MrE9BJCYmIjU1FRUqWNP+e/bsMel2fA4bDp5BF5/TUTCUnJxsNvs3XNKpcgyG1u2Pc51giClCVVtaKUFrvwW6PQSXwrSlXX8Cyz4Eds7Lub9KC6DrA9ZsENPYXC0Fq0Y7a+s23AqO2JCBrb23/mq1g97xu7X9/Kj1N2BQxDOilRqW3Li2zQF+vN8KzBj0DvoYaKxFDc+J9V+cNVsyEVj4mhXYTu4BdBsB9HrSqi8TcWG+vj7o26Ka2VwSU7QZCHHtME9p5CMiXqlQaXKxsbFmZoezNvZ4mwFNQTz11FNmJsgW/Nh+rjDPOX78eBMw2TbOTJWkNpERrlc3xNw9NlIgdmFzlTQgdnRb8V9gUhfgm8FZgZCPFTQM+xl48F+g/VDXC4TyC47qdAP6jQP+bw3w0FLg0ueBGlx0NNNq6810ug86AB90AuaNsRo2MBAsrtoqdkj7dogVCNXsANz/twKhgmK6ZY9HgeHLrH9/LPL+9x1gYldg62y4RbdAZ6dmiuTHtsgqU7ZDKzt7NCIiRVaqOTavvvoqpk2bZuqIgoODi/w8nJli3ZL9zFBJBkQ5TRTiTFqfj6t0b2PbaRaMH9sB7HVy7cjJKGD5J1adBtsjU2AY0P52oPO91mKp7ox/c6ZYcev5hNX+edtsa9vzNxC7HVjE7W1rbSOuscMFcvk3Ya1SYcUfAr6/K6fBBBtLXP4S4B9Y7G/N47GV983fWgHQb08CcVHAtJuBJgOB/q8B5Ur2ZEqhAyDOPLK74vY/gMx0oMGlQMvBVkDHdvIizpYQa/0bpc73O3s0IiKlFwxVqlQJfn5+OHLkSK77ebtatXNP5b/55psmGJo3bx5at26dfb/t5/gc1avnLJjI223btnX4XEFBQWYrLc2qhyHAzwfHE1Kw/8QZRFYIgUsICrPSzdjNh7NDzgiGuD7QX+OshT/5xY3K17O+vLe9xXO/vEXUtII8bmdOWjNgTKXbMdda24h/E24MCBv1sb54cz2kMlZgfU67FwA/3GMVJvPnr3k/p2GGFB1rver3Aha+Diz5wOoguPsvoNdTVlpkSTXuKEhjjJ3zrS+X234DUhNyP86GHtxYs8Z/Qy2vAxpfoVQ/cZ5Vn1tLIXCW3N26mYqIXEgwFBgYaFpjz58/H9dee212AwXeHjFiRL4/x25x48aNw++//46OHTvmeqxevXomIOJz2IIfzvSwq9yDDz4IVxDk74em1cKx4UCcmR1ymWCI2ICAX7q56B0Dk9Iq6ucaPksnAf9MsDqbEYOxrg9ZndncYa2e4sIAh13wuPGL7Z5/rC/anIkwi77+aG3snMd23awx4sxRRK3cz8P0un/eBP56xUrDY03YDV+UbD2St2EAcflYoM1NVoMFzrwx1XHdNODKCVatUWlITwX2LLTapG/5BUiOyz2TxZmgFtdZDVK4YDADJc4+mvq1X4CAECsg4n4N+wABRZ9pFyl0+i5PvlEXzQqJiBe21mZ6GtcD+uKLL7BlyxYTsCQkJODOO636FXaIs2+w8Nprr+GFF17AZ599hrp165o6IG6nT1tfoJly9uijj+Lll1/GTz/9hA0bNpjnYF2RLeByBa1ruWDdEHGRO67Pw3qI1V+W/OvxC/v676wamfkvWoEQGw7c+ZtVE8Qv+d4UCOXFlDjOBHHRz5FbrJbhPUYClZpYfyPO+sx+HHi7BfARZyneAI5sstJOvrnemmVjINTudqvVuAKhksF0xztnA9dMAkIqWl3npvQHZj1k/S1KAhtyMFD+5THgrSbA14OBtd9YgVBYdetEAlu9P7LeWh+pemugcmOg99PA8OXAA/9a/5bK17W6MjJImn4r8GYj4McHrLQ6Blkeiuvb8RjCFGs22Fm+fHm++7JJz4svvogGDRqY/bkExJw5cwr9nFzeYfjw4ahYsSJCQ0MxePDgszIjvA5P9MQfAEIqacZaRLyztTaxLbZt0VXO5nCNIB5IqHfv3ubgwrbYxOv79u076zm4TtGYMWNyLbr68ccfm0VXe/TogUmTJqFx48Yu09Z1xopoPPnDenSpVwHT7+8Gl8JucrMeACJqA4+sLblgJGop8PuzwIFV1u3wmtaXtpbXW+u8yLnF7syaMfrV6lLHoMfGNwDISAX8y1gzFEwxlNKReNxqfsF6N2LHPq49xYD0Qv9d8+OVHbc4A8TZQc4U2vDLJBcY5uxO7W4Ffy0+J1us256TX0xtOPZmV1nPWffiUjsxUdKfwVzfjifJuBYdjzXvvPMOvvvuO2zbtg1VqlRx2Kjn66+/NifumjZtarISeCJv8eLFaNeuXYGfkyf7fv31V3M84/tjBgQ7qP7777/e23J8ykBg3yLg4seBy15w9mhERC7487dIwZCrKY0DztbD8bjinX9QNtAP68f0g5+vizRRsKWsvdXU6jh2ywygcb/iff7je6xUIi6wR4GhVpeursOBQBdKGXQnTGlkfQgbMOz6C0hPBio2Am78Aqjawtmj805cu+vXkVa7eqrV2Zrhq9aycM/Dj9RD67LS2360GjbYBEfYBSs9L3ydKM7UsqshX2vTLCDBbvHrslVygq3ILiV6wqKkP4MLu74dMwuee+45M6tjw1mdMmXKmCCpIM/J91K5cmVMnToV119/vdln69ataNasmVn2oWvXrt4XDHEW+8OLAB8/4NENVu2kiIg3rTPkzRpWDkWZAD8kpKRj99HTaFQ1DC6Dbarb3WYVhTOXu7iCITYGYA3Lso+sYlkfX+ts+SXPAWEust6Su2JtV4dh1sb2yTzTz9bZKop3ntpdgPsWWgsEs25r/3LgI9bBPWilqrFhybnEbLVqe7gd35VzP08esBMcgxJ2hivOjoAMcNj+ndsVrwJ7F1mvv+UnKzBa8Ym1cRaXKU2sQ6rZ3uqO6CaKsr4d16HL27GUgdCiRYsK/Jx8nOl29mvgcZapdu3aBQ6GPLaddrMrFQiJiMdQMFRA/n6+aFkzHCv2njCLr7pUMEQd7rSCoe2/W22uWYRdVKw7WDkFWDAeOHPcuq/+JdZ6O5q1KH5Boc5tiy45OFNz0QgrcJjztBVU8P8rpqT1fxVodnXuQOLYrqwZoJlAzOac+9n4gCclGHywoUhpzKAyJY7d8rgNfMuqT+O42HCBqXR8H9zK1bE60jE4Y5MOFw+MzrW+HWdqHOnXrx8mTJiAnj17mrohNuiZOXOmeZ6CPifTwNk0qFy5cgVeA6+0FwQvVWdOAOtnWNfVTltEPIiCoUKuN8RgiE0Uru+QpxOYs7HQvl4vq0PVqi+KlsvN9B4GU388b61dZJ63iRUEsWOVi39pEik2POs95CurKQEbXpzcB8wYagU2XGeK9XMMgg6uyV331fCyrDWB+p9/JqkksU0423BzS30b2GXXupvvhethcWNqJsfL4KhyE3iKd999F/fee6+ZyWGTHgZEbPLDRj4liQuCjx07Fh5pzTdW444qLUqv66KISClQMFSEjnKcGXJJHe+ygiF2lePaKYVJxzm0HvjjOWsBUWKHrUueBdrfceF1DSLuqnFfoO5S4J+3gH/fzVnzx4a1E5zVY0DB1CE2MHA1bLvNBYC5pSRYJzwYyDHQ40mPha9aW82OwN1zXa4ZSlHWt2Otz6xZs0w3uGPHjpkaItYB1a9fv8DPyUum07Gpj/3s0Llet7QXBC81rE1juiV1uU8nxkTEo7jWUc/FtallHRC3HIxHSloGXA6/7IRWtWoF2LWsIOIPAf8bbtVGMBDyCwS6PwL83xqg0z0KhESY4saZ1gcXW7OvDIDqdLdS0f6zDRg6C2h/u2sGQnmxJo2zQEO+Bp7YCQz6GGjUz1oDK7yGywVCede3s7Gtb9et27k7e7JuqGbNmkhLS8MPP/yAa665psDPyccDAgJy7cNOc1FRUfm+LhcDZ6Gu/eYRds4FTuy1GoBwoW8REQ+ib7qFUKdiCCLKBCDuTCq2HT6FVlkzRS6DqTHthwJ/vwGs+PTca0CkJFr1A4veyVnxnvUNfUZb65iISG5c82fYT9ZZchcMGgotOBxoM8Ta2F482XXrWzjbMmzYMLNod+fOnU0b7Lzr2zHoYZoacdHuAwcOmKUfeMllHBjsPPnkkwV+TnYhuvvuu81+FSpUMIENO80xEPK65glsokNsoKMmLyLiYRQMFQJzz5kq98+OWKzbf9L1giFqP8xK6dn7D3B0u/UF7qxFU6dbC6aeOmjdx0Vb+70CRHZ2ypBF3IonBEJ5hVSwNhc1ZMgQHD16FKNGjcpe346LqNoaIHC2ht3gbJge9/zzz2P37t1msdQBAwbgq6++ypXudr7npLfffts8L9tyszECGzNwDTyvWx+NNWfwsbIFREQ8jNYZKqQ3ft+KiX/two0da+H169vAJU29Cdj+m7Wi/RXWmVKDbXe5aCrXQCEu0nr5GGtGSDngIlJEHreeTjHxiN/Lb09Z7eYbXwHcMt3ZoxERKfbPXw88xVmy2FGO1rtqEwVbIwVay+4/Z6z2v9NuBT4faAVCgWFAnzHAiBVW4bcCIRERySv5FLB2qnW9833OHo2ISIlQmlwhtY20gqHtR04hMSUNIYEu+Ctke1+uM8T1hqbeCOxbDGSkWYumcj2i3s8AoZWdPUoREXFl66ZZtWQVG1przYmIeCDNDBVS1fBgVA0PQkYmsOmgixYcc/HFDndY19khjoFQw8utblhXTlAgJCIi58YM+uWf5MwKeWKtnIiIgqELS5VbF30SLovrA3FBxeptgNtmArd9D1Rp5uxRiYiIO+CadbHbgMBQoM3Nzh6NiEiJccEcL9fXplYE5m4+4tp1Q2UrAg+vdPYoRETEHS372LpkIMQ27CIiHkozQxfURMGFZ4ZERESK4sQ+qyMpdb7X2aMRESlRCoaKgGsN0d5jiYhLTHX2cERERIrPyk+BzAygfm+gchNnj0ZEpEQpGCqCciGBqFMxxFxff0CzQyIi4iG4HMPqL63rne939mhEREqcgiFPXm9IRESkMDZ8D5w5YS3P0Lifs0cjIlLiFAxdQBMFl+8oJyIiUqh22h9Z1zvdYy3TICLi4RQMFZFmhkRExKNELwMObwD8g4F2tzt7NCIipULBUBG1rBkOXx/gcHwSYuKTnD0cERGRC7Msa1ao1Q1ASAVnj0ZEpFQoGCqikEB/NKoSZq6v0+yQiIi4s/hDwJafrOud73P2aERESo2CoWJosa31hkRExK2tmgJkpAG1uwHVWzt7NCIipUbB0AVoHWnVDWlmSERE3FZaCrByinVds0Ii4mUUDBVDRznODGWyC4+IiIi7ObASSIgBQioCza5y9mhEREqVgqEL0LRaOAL9fHEyMRVRxxOdPRwREZHCi1piXdbpDvgFOHs0IiKlSsHQBQj090Wz6mqiICIibixqmXVZu6uzRyIi4h7B0MSJE1G3bl0EBwejS5cuWL58eb77btq0CYMHDzb7+/j44J133jlrnzFjxpjH7LemTZvCrdYb0uKrIiLibjIygOil1nUFQyLihQodDE2fPh0jR47E6NGjsXr1arRp0wb9+vVDTEyMw/0TExNRv359vPrqq6hWrVq+z9uiRQscOnQoe1u0aBHcq6OcZoZERMTNxG4DkuKAgBCgmrrIiYj3KXQwNGHCBNx7772488470bx5c0yePBkhISH47LPPHO7fqVMnvPHGG7jpppsQFBSU7/P6+/ubYMm2VapUCe6gTVZHuY0H45CeoSYKIiLiRqKyZoVqdlC9kIh4pUIFQykpKVi1ahX69OmT8wS+vub2kiVZBZhFtGPHDtSoUcPMIt16662IioqCO2hQORQhgX5ITEnHzpjTzh6OiIhI4YMhpciJiJcqVDAUGxuL9PR0VK1aNdf9vH348OEiD4J1R59//jnmzJmDDz/8EHv27MHFF1+MU6dOOdw/OTkZ8fHxuTZn8fP1QcuaVqrcOi2+KiIi7sRWLxSpYEhEvJNLdJPr378/brjhBrRu3drUH82ePRsnT57EjBkzHO4/fvx4REREZG+RkZFwlfWGRERE3MKpw8CJvQB8gMhOzh6NiIjrB0Os4/Hz88ORI0dy3c/b52qOUFjlypVD48aNsXPnToePP/PMM4iLi8veoqOj4RId5dREQURE3C1FrmoLINg6qSci4m0KFQwFBgaiQ4cOmD9/fvZ9GRkZ5na3bt2KbVCnT5/Grl27UL16dYePsxFDeHh4rs2Z2mQFQ1sOxSM5Ld2pYxER8USFWdKBuIxDkyZNUKZMGZM98NhjjyEpKSn7cdtyD3m34cOHZ+/Tu3fvsx5/4IEH4DGis9YXiuzi7JGIiDiNf2F/gG21hw0bho4dO6Jz587mgJOQkGC6y9HQoUNRs2ZNk8pma7qwefPm7OsHDhzA2rVrERoaioYNG5r7H3/8cVx11VWoU6cODh48aNp2cwbq5ptvhjuIrFAG5UMCcCIxFVsPncruMCciIhfOtqQDu5cyEOJxhynV27ZtQ5UqVc7af+rUqXj66adNl9OLLroI27dvxx133GGCGXZEpRUrVpgaWJuNGzfi8ssvNynb9tg99cUXX8y+ze6pHiMqq/FR7eI7mSki4vHB0JAhQ3D06FGMGjXKNE1o27ataXxga6rALnDsMGfD4KZdu3bZt998802z9erVCwsWLDD37d+/3wQ+x44dQ+XKldGjRw8sXbrUXHcHPMAyVW7h9qOmbkjBkIhI8bFf0oEYFP36668m2GHQk9fixYvRvXt33HLLLdmzQDzGLFuWNRMCnHV84Vp4DRo0MMcmewx+ijMN3GWkJACH1lvXa2tmSES8V6GDIRoxYoTZHLEFODY8CGVmnnv9nWnTpsHdsYkCg6F1++Nwu7MHIyLiIWxLOrBWtKBLOnA26OuvvzapdMxg2L17t2nMc/vtt+f7Gtyfs088uWXvm2++MY8xIGIGwwsvvOAZs0MHVgGZ6UBYDSDCuU2IRETcLhiSczVRUEc5EZHicq4lHbZu3erwZzgjxJ9jlgFPxqWlpZlan2effdbh/rNmzTIdTJlKl/d5mL7NNfDWr1+Pp556yqTmzZw5M99lH7jZOHPZh0KtL5QnABQR8SYKhopJ60irEw8XXk1ITkPZIP1qRUScgRkKr7zyCiZNmmRqjNiZ9JFHHsFLL71kZnby+vTTT80SDwx67N13333Z11u1amWa+lx22WWmwQ9T6vJirezYsWPhFrTYqoiI66wz5AmqhAWjekQwMjKBjQfUYltEpDgUZUkHBjxMibvnnntMEDNo0CATHDFYYQdUe/v27cO8efPMvufDwIrcZdmHfGWkA/tXWNfVSU5EvJyCoWLUOnvxVQVDIiLFoShLOiQmJuZq5EMMqChvDeuUKVNMR7qBAweedyzshErusuxDvmI2A8nxQGAoULWls0cjIuJUyuUq5rqh3zcdwTrVDYmIFJvCLunARgfsQMdOprY0Oc4W8X5bUGQLqhgM8bn9/XMfDpkKxxbdAwYMQMWKFU3NENcq6tmzJ1q3bg23ZkuRq9UR8NPXABHxbvoULIHFVzUzJCJSfAq7pMPzzz9vusLxkmvbsY02A6Fx48blel6mx/Fn77rrLoczUnzcFnhx4dbBgweb53R72fVCWl9IRMQn83x9r90AO/ZERESYHG1npiXEnUlFm7F/mOtrXrgc5csGOm0sIiLe9hnsalz29/J2SyAuGrh9FtDgEmePRkTEqZ+/qhkqRhFlAlCvUllzfb2aKIiIiKuJ228FQj6+VpqciIiXUzBUUk0UolU3JCIiLpoiV60VEBTm7NGIiDidgqESWnx1neqGRETE1UQvsy4jtb6QiAgpGCpmbbLba2tmSEREXIwWWxURyUXBUDFrUSMCfr4+iDmVjMNxSc4ejoiIiCX5FHBko3VdwZCIiKFgqJiVCfRDoyqh5vpa1Q2JiIir2L8CyMwAImoD4TWcPRoREZegYKhE1xtSMCQiIi5CKXIiImdRMFQCWkfa6obUREFERFwtGOri7JGIiLgMBUMlPDPkAWvaioiIu0tPA/avtK6rk5yISDYFQyWgSbUwBPr7Ij4pDXuPJTp7OCIi4u2ObABSE4CgCKBKM2ePRkTEZSgYKgEBfr5oXj3cXFfdkIiIOF2UbX2hToCvn7NHIyLiMhQMlfB6Q+uiVTckIiJOFq3mCSIijigYKiGt1VFORERcAWtXbc0TVC8kIpKLgqES0iaro9zGg3FIS89w9nBERMRbnYwCTh0CfP2Bmh2cPRoREZeiYKiE1K8UitAgfySlZmBHzGlnD0dERLyVbVaoehsgMMTZoxERcSkKhkqIr68PWtZUEwUREXGReiGlyImInEXBUCmsN7ROi6+KiIizO8lpsVURkbMoGCpBaqIgIiJOdeYkELPZuq6ZIRGRsygYKoUmClsPnUJSarqzhyMiIt5m/wq2kwPK1wPCqjp7NCIiLkfBUAmqWa4MKpYNRFpGJrYcinf2cERExFubJ9Tu5uyRiIh4TjA0ceJE1K1bF8HBwejSpQuWL1+e776bNm3C4MGDzf4+Pj545513Lvg53QXfb+usxVfXq25IREScFgypXkhEpFiCoenTp2PkyJEYPXo0Vq9ejTZt2qBfv36IiYlxuH9iYiLq16+PV199FdWqVSuW53THuqF1qhsSEZHSlJYCHFhlXVe9kIhI8QRDEyZMwL333os777wTzZs3x+TJkxESEoLPPvvM4f6dOnXCG2+8gZtuuglBQUHF8pzuWDekmSERESlVh9cDaWeAMuWBSo2dPRoREfcPhlJSUrBq1Sr06dMn5wl8fc3tJUuWFGkARXnO5ORkxMfH59pcfWZo19HTOJ2c5uzhiIiIt6XIRXbhgdXZoxERcUmF+nSMjY1Feno6qlbN3ZGGtw8fPlykARTlOcePH4+IiIjsLTIyEq6qUmiQaaSQmQls0OyQiIiU9mKrtZUiJyKSH7c8VfTMM88gLi4ue4uOjoYry2mioLohEZGiKGyTHTbradKkCcqUKWNOmD322GNISkrKfnzMmDGmyY391rRp01zPwf2HDx+OihUrIjQ01DQDOnLkCNwCz8BlzwwpGBIRKZZgqFKlSvDz8zvrYMDb+TVHKInnZO1ReHh4rs09Fl/VzJCISGEVtsnO1KlT8fTTT5v9t2zZgk8//dQ8x7PPPptrvxYtWuDQoUPZ26JFi3I9zgDq559/xnfffYeFCxfi4MGDuO666+AWju8GEo4CfoFAjXbOHo2IiGcEQ4GBgejQoQPmz5+ffV9GRoa53a1b0dYwKInndDVtsmaG1FFORKTwCttkZ/HixejevTtuueUWM5vUt29f3HzzzWfNJvn7+5uTbraNJ+dsmHXAIIqvfemll5rj1JQpU8xzL12aNePiyqKXWZcMhAKCnT0aERHPSZPj2blPPvkEX3zxhTnj9uCDDyIhIcEcpGjo0KEmjc2+QcLatWvNxusHDhww13fu3Fng53R3LbOCof0nzuDY6WRnD0dExG0UpcnORRddZH7GFvzs3r0bs2fPxoABA3Ltt2PHDtSoUcMs/3DrrbciKioq+zH+fGpqaq7XZRpd7dq1i9wwqFRFLclpniAiIvnyRyENGTIER48exahRo0yDg7Zt22LOnDnZDRB4MOGByoZpBe3a5UzRv/nmm2br1asXFixYUKDndHfhwQGoX7ksdh9NwPoDcbikSRVnD0lExC2cq8nO1q1bHf4MZ4T4cz169EBmZibS0tLwwAMP5EqTY93R559/buqKmCI3duxYXHzxxdi4cSPCwsLMsYiZC+XKlStwcx92OuVm49ROp1FZM0NqniAiUrzBEI0YMcJsjtgCHBumKPBgdCHP6Qna1CpngqF10ScVDImIlCAeh1555RVMmjTJBD3MRHjkkUfw0ksv4YUXXjD79O/fP3v/1q1bm/3q1KmDGTNm4O677y7S67LTKYMqp0s8DsRus65rZkhExPO6ybmjnI5yaqIgIlKSTXYY8Nx+++2455570KpVKwwaNMgERwxWWJPqCGeAGjdunJ3Czedmit7JkycL/Lou0+nUVi9UsRFQNqcOSkREzqZgqNQ7yp0s0EyZiIgUrclOYmJirnRtYkBF+X3+nj59Grt27UL16tXNbb5mQEBArtfdtm2bSQXP73VdptOpraW2UuREREomTU4Kr0WNcPj7+iD2dAoOxiWZhVhFROT82GRn2LBh6NixIzp37mzWEMrbuKdmzZpm5oeuuuoq0wWO9aq2NDnOFvF+W1D0+OOPm9tMjWNtK9tw8zF2nSMu6M10Ob52hQoVTGDz8MMPm0Coa1cXDzIUDImIFJiCoVISHOCHxlXDsPlQPNZHn1QwJCJSQo17nn/+ebOIKi/ZwbRy5com8Bk3blz2Pvv37zeBz7Fjx8zjbLbAltm8bvP222+b5+Viq2yMwLWNWIfk0tKSgYNrrOtabFVE5Lx8Mj0gZ4sde3gWjznarrwA6zMz1+Pb5dF4oFcDPN0/90rnIiLuyl0+g73i98Iucp/1BUIqAU/sBHx8Sud1RUTc9PNXNUNOqhsSEREpsfWFmCKnQEhE5LwUDDmho9yG/XHIyHD7CTkREXE1tk5yaqktIlIgCoZKEWuGgvx9cSo5DX9sdrxon4iISJEw6z27eYLjjnciIpKbgqFSFODni0HtaprrI6auwU/rDjp7SCIi4ilidwBnjgP+wUD1Ns4ejYiIW1AwVMpeurYlrmlbA2kZmXhk2hpMXRbl7CGJiIgniM6aFarZAfAPdPZoRETcgoIhJ8wOvX1jW9zapbbJaHj2xw345O/dzh6WiIi4O1uKnOqFREQKTMGQE/j6+uDla1vi/l71ze1xs7dgwh/b8l0ZXURE5Ly02KqISKEpGHISLgj4TP9meKJfE3P7vT93YuzPm9VlTkRECu/0UeD4Lut6ZGdnj0ZExG0oGHKy4Zc0xNirW5jrny/ei6d+WI90BUQiIlKUeqHKzYAy5Z09GhERt6FgyAUMu6gu3rqhDXx9gO9W7cfD365GSlqGs4clIiLuQilyIiJFomDIRQzuUAuTbm2PAD8fzN5wGPd+uRJnUtKdPSwREXEHCoZERIpEwZALuaJldXw6rBOCA3yxcPtRDPtsOeKTUp09LBERcWWpZ4BD66zr6iQnIlIoCoZcTM/GlfH13V0QFuSP5XuP49ZPluF4QoqzhyUiIq7qwGogIxUIrQaUr+vs0YiIuBUFQy6oY90K+Pa+rqhQNhAbDsRhyEdLcDguydnDEhERVxS1xLqs3YWtSp09GhERt6JgyEW1rBmBGfd3RbXwYOyIOY0bPlqMqGOJzh6WiIi4muhl1mWk6oVERApLwZALa1glDN890A11KoYg+vgZExDtOHLK2cMSERFXkZGREwypeYKISKEpGHJxkRVC8N393dC4aiiOxCfjxo+WYMP+OGcPS0REXMHRrUBSHBAQAlRr5ezRiIi4HQVDbqBKeDCm39cNrWtF4ERiKm7+ZCmW7znu7GGJiIirLLZaqyPgF+Ds0YiIuB1/Zw9ACqZ82UB8c08X3PPFSizbcxxDP1uGybd1QO8mVZw9NBERcfb6QqoXEimy9PR0pKZqKRN3ExAQAD8/vwt+HgVDbiQsOABf3NUZD369Cn9tO2oWZn33pnYY0Kq6s4cmIiJOXWxV6wuJFFZmZiYOHz6MkydPOnsoUkTlypVDtWrV4HMBnTQVDLmZ4AA/fHR7Rzw2Yy1+XX8II6auxmuDW+OGjpHOHpqIiJSm+EPAyX2Ajy9Qq7OzRyPidmyBUJUqVRASEnJBX6il9APZxMRExMTEmNvVq1cv3WBo4sSJeOONN8w/ojZt2uD9999H5875fxB/9913eOGFF7B37140atQIr732GgYMGJD9+B133IEvvvgi18/069cPc+bMKcrwPF6gvy/eu6mdWZh12opoPPH9epxOTsOd3es5e2giIlLa9UJVWgDB4c4ejYjbpcbZAqGKFSs6ezhSBGXKlDGXDIj4dyxqylyhGyhMnz4dI0eOxOjRo7F69WoTDDFwsUVmeS1evBg333wz7r77bqxZswbXXnut2TZu3JhrvyuuuAKHDh3K3r799tsivSFv4efrg/HXtcLdPawAaOzPm/H+/B0mUhYRES8QZWuprRQ5kcKy1QhxRkjcl+3vdyE1X4UOhiZMmIB7770Xd955J5o3b47JkyebgXz22WcO93/33XdNoPPEE0+gWbNmeOmll9C+fXt88MEHufYLCgoyOX+2rXz58kV+U96C07nPD2yGR/s0Mrffmrsd43/bqoBIRMSbZoZqd3P2SETcllLj3Ftx/P0KFQylpKRg1apV6NOnT84T+Pqa20uWLHH4M7zffn/iTFLe/RcsWGCmuJo0aYIHH3wQx44dK9w78eJ/BI/2aYwXrmxubn/89248++NGpGcoIBIR8VjJp4FD663rkZoZEhEplWAoNjbW5FhWrVo11/28zfohR3j/+fbnzNGXX36J+fPnm3qihQsXon///ua1HElOTkZ8fHyuzdsxXe61wa3AAPnb5VF4dPpapKZnOHtYIiLFgrWqdevWRXBwMLp06YLly5efc/933nnHnFxjTnlkZCQee+wxJCUlZT8+fvx4dOrUCWFhYeZEHNO3t23blus5evfubU442W8PPPAAXMKBVUBmOhBeCyinBjoiUjR169Y1n5fezCW6yd10003Z11u1aoXWrVujQYMGZrbosssuO2t/HsTGjh1byqN0fUM61UbZIH88Om0tfl53EInJaZh4a3vTgU5ExF3ZalWZls1AiAduZhgweGEgk9fUqVPx9NNPm/Ttiy66CNu3bzeNehjMMNWbeNJt+PDhJiBKS0vDs88+i759+2Lz5s0oW7Zs9nMxLfzFF1/Mvu0y9QVqqS3itXiipm3btsUSxKxYsSLXZ543KtTMUKVKlUynhiNHjuS6n7dZ5+MI7y/M/lS/fn3zWjt37nT4+DPPPIO4uLjsLTo6ujBvw6Nd2boGPhnaEUH+vpi/NQZXvr8IU/7dg5OJKc4emohIkRS2VpWNe7p3745bbrnFnPVkkMNGPvazSexWygCpRYsWphHQ559/jqioKJMKbo+vY1/PGh4e7lr1QlpsVUTyYO04T/IUROXKlV3nJI87BEOBgYHo0KGDSWezycjIMLe7dXNcwMn77fenuXPn5rs/7d+/39QM5dcznM0WeECy3yTHJU2rmMVZw4L9sTPmtOk01/mV+fi/b9dg8c5YZKieSETcRFFqVTkbxJ+xBT+7d+/G7Nmzcy3pkBdPrFGFChVy3f/NN9+Yk3MtW7Y0J+K4roXTZaQD0Sus67UVDIl4E57E4cw2G5TZ0nd5MoeXv/32m/mezu/JixYtwq5du3DNNdeY8pTQ0FAzEz5v3rxzpsn5+Pjgv//9LwYNGmSCJC6J89NPPxVobCxvYffoevXqmRRlpipznHnxRBZPRHGc/K4/YsSI7MfY7vz+++83Y2ZaND97f/nlF7hUmhxTFYYNG4aOHTuatYX4C0xISDBn7Gjo0KGoWbOmSWWjRx55BL169cJbb72FgQMHYtq0aVi5ciU+/vhj8/jp06dNytvgwYPNWTf+4Z588kk0bNjQpEFI0XStXxGLnrwU/1t3AN8uj8aWQ/H4ad1Bs0VWKIMhHSNxfYdIVIsIdvZQRUSKVKu6detWhz/DGSH+XI8ePbLPkLLWh6lwjvCk3qOPPmpmk3jgtX+eOnXqoEaNGli/fj2eeuopk5o3c+bMfOtZudmUWD3rkU1AyikgMAyo2qJkXkPEC/Hz4kyq43r1klQmwK/AXdEYXDD1l59VthTeTZs2mUumB7/55psmw4pdmZk5xZNA48aNM4EH6/Ovuuoq8zlWu3btfF9j7NixeP31182aolxL9NZbb8W+ffvOOlnk6LO0Vq1aZn1Rrt3EWfr77rvPBDw33nij2efDDz80scSrr75q+gPwRNS///6b/fO879SpU/j6669NyQxTl4u6flCJBUNDhgzB0aNHMWrUKNMEgTmLTDewHaiYZsCzdvZn6Ji//fzzz5sDESPMWbNmZR9w+AZ5kOGiq4wGedBhSgNbcPMPJ0UXERKAod3q4vaudbDxQDymr4zC/9YcRPTxM3jzj+2YMHc7ejepgiGdInFp0yoI8Ct0p3UREZfDetNXXnkFkyZNMjVGTLnmiTkeV7gAeF6sHeLadzyTao8Hcft6Vh7QWcfKk3Y8SDutnjU6a32hyE6Ar2pCRYoLA6Hmo34v9dfd/GI/hAQW7Ct5RESEydSypfCS7cQQg6PLL788e18GL0wDtuFn4I8//mhmeuxnYxzNPjG1mPhZ+t5775mZdjY8O5eAgIBcn4GcIeIM/owZM7KDoZdffhn/+c9/zGeyDWesiLNWfJ0tW7agcePG5j4Gdi7ZQIG/wPx+iTwI5XXDDTeYzRFOo/3+e+n/w/MmPNvQqlYEWtVqhecGNMfsDYcwfWU0lu85jj+3xpitUmgQBneoaWaM6lcOdfaQRUSKXKvKgOf222/HPffckx3IMIOBwc1zzz2X64Qdj2VMwfj777/NGc1zYWBFDK4cBUNMo+MZT/uZIXayK7HmCaoXEhE7zNqyx+yrMWPG4Ndff8WhQ4fMLPmZM2fMxMW5tG7dOvs6myuwHCUmJqbAnT+ZBsfX4Gsx1ZkTJ8TnOHjwoMPmaLR27VrzOWwLhLyqm5yUnjKBfhjcoZbZdh09jRkro/HDqgOIPZ2MjxbuNlvnuhXMbNGAVtXN/iIizmJfq8r21/a1qvmdlGNdj33AQ7Y0C9ui1Lx8+OGHzVlSnsTjGczz4YGazlXPWioZDeokJ1Ji6WqcpXHG6xaHvF3hHn/8cVOnz9Q5lp9wAuL66683Acr5ZnjynlTn5+75sBSGr8nSGPYG4NIFTLVbtsyazebrn8v5Hi8pCoa8WIPKoXimfzM83reJmR2asSIaf22LwfK9x8025qdNuLptDRMYtaoZoVWaRcQpClurypx4dqBr165ddpocZ4t4vy0oYmocU7j/97//mQO2be07pqDwgMxUOD7OfHvmvjOdm2sV9ezZM9dZ01J3MhqI3w/4+AE1c58FFpELw+85BU1Xc/ZJovzW4rTHWhymvLEZgm2maO/evSU2rn///deUxzz00EPZ9/Gz1IaftWzYwJNZl1xyyVk/z89WNlFjTVRpzg65/l9cShxrhfq1qGa2w3FJ+H5VNGas3I+o44n4ZlmU2ZpVD8dNnSJxbduaphZJRKS0FLZWlTWq/FLDywMHDpjWsQyEWERswyJe23od9qZMmWK+PPDLBvPXbYEX093Y6IfP6VS2eqFqrYAgpTSLeCMGFJxtYWDDLnH5zdqwTp8NX/j5x89EnhQqyAxPUfH12KSB5S+cbf/qq6/MOkb2M+9M22NDG64RZ2uWwCCKM/VsuMYTTvys5QktzmaxHopjP1+90oVQMCS5sLvciEsb4aHeDbF09zFMWxGNOZsOm250o3/ahHGzt6B/y2pmtqhrvYrw9dVskYiUvMLUqvr7+2P06NFmy48tXS4/DH7YvtblZKfIqV5IxFsxFY2z5Vx3jXU5PInjCAOKu+66y8zWsP6SHTFLrMslYFpir1mzxpzAYgDDJgycJWLLbxuOOykpCW+//bZ5HxwXU/dsfvjhB3M/f5YnohgQsfNcSfLJPN8RwQ3wD8vUBrbn05pDxY8Lts5ac8AERlsPn8q+v3aFEBMUXd+hFqqGq0W3iLfSZ3Ap/l4m9wAObwBu+BxoYaW+iEjh8Qv5nj17zKwF17MRz/o7FubzVzNDcl7lQgJxR/d6GHZRXWw4EGeCop/WHjRpdG/8vg1v/bENlzSpYtLsejaurLWLRERKQlK8tcYQqZOciEixUDAkBcYpz9a1ypnt+YHNMHvDYUxfEYUVe09g/tYYs1HjqqHo2agyLm5cGV3qVUBwMXVJERHxavtXAJkZQLk6QLjjjnYiIiXlgQceMIuhOnLbbbdh8uTJcEcKhqRI2G2F6XHcdsacxk9rD2Dhjlis338S24+cNtt/F+1BkL8vOtergF6NK+PiRpVNoKSudCIiRaB6IRFxohdffNHU8zjizinSCobkgjWsEoqRfZuY7URCCv7dFYu/tx/F39tjcTg+Cf/siDUbsAXVwoNxcaNKJp2uR8NKKF820NnDFxFxD9G2xVa1vpCIlL4qVaqYzdMoGJJixeDmytY1zMbeHDtiTluB0Y5YLNt9zARH363abzZOELWuGWECI25tI8uZNt8iIpJHeiqwf5V1vXY3Z49GRMRjKBiSEsN0uMZVw8x2z8X1kZSajhV7j2fPGm07cgrr9seZ7f0/dyIsyB/dGlS0gqNGlVG7Yoiz34KIiGtgB7nUBCA4Aqjc1NmjERHxGAqGpNSwkQLrhrg9NxBmgdd/dlizRot2HMWJxFT8sfmI2ahuxZDswKhrg4oIDdI/VxHxUrbFVmt1BuwWmBURkQujb5fiNGzBfUPHSLOlZ2Ri08G47Fmj1VEnsPdYIvYu2Ycvl+xDgJ8P2tcub4KjrvUroEa5MqgUGqS0OhHxDmqeICJSIhQMiUvw881p2z3i0kY4lZSKJbuO4W/OHG2PNWsaLdtz3Gw2rDmqWDYQlcOCUTU8CFXDglElPAhVwoNRJSzILATLy8phCppExI1xbXQFQyIiJULBkLiksOAA9G1RzWy071iCmTVauD3WzCAdPZWMtIxMxJ5OMduWQ/k/F4OmCiGBJkhi0GQfKNkHTgqaRMQlndwHnD4M+AYANdo7ezQi4ubq1q2LRx991GyiYEjcRJ2KZXF7N251ze2MjEycSEzBkfhkHDmVhKO8jE9CzKmcy5j4JBw9nYzU9EwcS0gx27mCJuJMU06AFGRagTMlr3q5MqhZLhjVI8qgrGqXRKQ02WaFqrcBAtVYRkSkOOlbnbglX18fVAwNMltz5L/Ql33QFHMqCTFZl0fsLjnLxOsFDZoiygSgekQwapogyQqQzPUIK3BiLZRmmESk2ChFTkSkxCgYEo9W2KAp78zSobgkHDx5xlweOHkGp5LSEHcm1WxbD5/KNy2PM0t5g6Qa5bJmmSLY/CHQtB4XESlwJzkFQyJe7+OPP8aYMWOwf/9++Np1lrzmmmtQsWJFPPfccxg5ciSWLl2KhIQENGvWDOPHj0efPn2K9HoTJkzAlClTsHv3blSoUAFXXXUVXn/9dYSGhmbv8++//5rXXb58OYKCgtC5c2dMmzYN5cuXR0ZGBt58800z7ujoaFStWhX333+/2d9VKBgSyRM0Nauef9DExg62AOngSQZLZ0yQdOhkEg7GWZcp6RlW+l58MtZGn3T4PIH+vlaQFGHNLtXMmlHifdXCrQCqXEiAAiYRb3fmBBCz2boe2cXZoxHx/GYlqYml/7oBIdaZ1AK44YYb8PDDD+Ovv/7CZZddZu47fvw45syZg9mzZ+P06dMYMGAAxo0bZwKTL7/80gQw27ZtQ+3atQs9NF9fX7z33nuoV6+eCYgeeughPPnkk5g0aZJ5fO3atWYcd911F9599134+/ubsaWnp5vHn3nmGXzyySd4++230aNHDxw6dAhbt26FK/HJzORf3r3Fx8cjIiICcXFxCA/P/4usSEnjDBPT7Bgk2QIm+5kl3s9Zp4L8XxeUFTCxuYMJkhg4mUvb7WBUKhtkAjkRZ9JncAn+Xrb/AUy9AajQAPi/1cU9RBGvlZSUhD179pgv+cHBwdadKQnAKzVKfzDPHgQCyxZ492uvvdbMAn366afmNmddxo4da2Ze7GeLbFq2bIkHHngAI0aMuOAGCt9//715rtjYWHP7lltuQVRUFBYtWnTWvqdOnULlypXxwQcf4J577kGp/R0L+fmrmSGRYsTAhF3puLFNuCMpaZw5ygmSOKPE61yElrf5GDvkJadlWGstHcv/LJW/r48JlqrZgqSs60zFswVNTNnzVw2TiHuKVr2QiOR266234t577zWzM5z9+eabb3DTTTeZQIgzQ0yj+/XXX80sTFpaGs6cOWMClqKYN2+eSbPjbA4DDD4fA5DExESEhISYmSHOVjmyZcsWJCcnZ89guSoFQyKljClykRVCzJaf5LR00+yBwRFnk2yBEi8Px1uXbPrA9uKcceKWH04ccYHanFmlMmY9JnbK41bVpOYFq0ueiCs3T1CKnEjppKtxlsYZr1sITHtjYhcDnk6dOuGff/4xaWj0+OOPY+7cuaZOp2HDhihTpgyuv/56pKSkFHpYe/fuxZVXXokHH3zQpN2xZogzQHfffbd5PgZDfP78nOsxV6JvPyIuKMjf77wBU1p6hmkdbguSrMszOByfbC5ts0zskmcaQpxKxrr9cfk+X2iQv9VOPCs1zwRLZmYpa+YpPNg0ftAsk0gpSUsBDqyyrtfu5uzRiHg+1u0UIl3NWZgOdt1115kZoZ07d6JJkyZo3759djODO+64A4MGDTK3OVPEoKYoVq1aZRogvPXWW9npdzNmzMi1T+vWrTF//nyTppdXo0aNTEDEx0sqTa44KBgScVMMSjjLw+18NUxWsMRAKScVjxvvZ6OH08lp1nY0DbuOJpxzlokpgAyW7AMm63ZQ9kxTWJC/mj+IXKhD64C0JKBMBaBSI2ePRkRcLFWOszabNm3CbbfdlisAmTlzppk94nH4hRdeMAFNUTRs2BCpqal4//33zfMx0Jo8eXKufdggoVWrVqaxAmuJAgMDTQMFps5VqlQJTz31lGm4wPu7d++Oo0ePmjFzdslVKBgS8ZIapla1IvLdj4GQCZBsaXh2163OeFa78fSMzOxOeUD+s0whgX4mMAoL9jdj8PXhxpNu1qV128echLM95ufrc87Hrds+4MSU7XrOvtZz8znMfb4+8Mt6Duv1Yd3OGovtOXzz/Iy5nfW6vN82Juu5cp7X38/HrCXFmi0GpQFZt3np7+ub7+O8rSBRCl0vxBQ5/bsRETuXXnqpSVtjlzg2MbBvhc3ObhdddFF2MMJan6Jo06aNeb7XXnvNBD09e/Y09UNDhw7N3qdx48b4448/8Oyzz5qW2pwJ6tKlC26++WbzOIMxdpgbNWoUDh48iOrVq5ugyZWom5yIFAgDoWOnk7Nrlo5wTabsgMk2y5SE+KQ0Zw/VpVkBkg8CsoImBkuBDJRMIJUVNGUFVQzG+BHND2l+UpsP61y3M63LrMdsH+e5Hsu63/rZ3Lft92tVMwIf3tahSO9Jn8El9HuZdiuw9Regz1igR+G7PolI4buQiXtRNzkRKTX8Yl4lPNhsrWvlv19iCmeZWLeUZK5nZAIZ/PKdmZl9nZfW7UykZ5zj8Qz7+3Ku88v72Y9Zz8WfY+CWnrUfr+c8nvUzWfel21/P3i//n+Fz8pJ1WGkZGUhLz0Sq7TI9w7qflxnWJX8uLza94JaEoqUtlBR2HRQXwn+8tuYJ6iQnIlJiihQMTZw4EW+88QYOHz5sptCYS8ipsfx89913ZpqMBVzMZeR0GxeEsuGXl9GjR5tFmU6ePGlyCj/88EOzr4i4l5BAf9SrxM31i1BLmgmc8gZLdrcZFOUKovI8zmAMsNL2mCTFFDvrMmvjLUeP2f2M9Xie58i+bu3ASzbQEBczdJYVEFVv6+yRiIgHYgOG+++/3+FjderUMbU93qDQR7/p06dj5MiRpoCKOYHvvPMO+vXrZ3IWq1Spctb+ixcvNnmDzDFkodfUqVPNYlGrV682i0DR66+/bla3/eKLL8w0FwMnPufmzZs1dSkibos1RkG+flCcIYXGCLVaK2sTESkBV199tfku70hAQAC8RaF75LKQigs93XnnnWjevLkJithn/LPPPnO4/7vvvosrrrgCTzzxBJo1a4aXXnrJtP/jarS2WSEGVM8//zyuueYa06Lvyy+/NEVWs2bNuvB3KCIibo8ZCVw1nSfIePBevnz5OffncYXtZlnMGxkZiccee8zklhfmObn/8OHDzUrvoaGhGDx4MI4cOVIi709EpLSFhYWZjnGONs4MeYtCBUNcYIk9x/v06ZPzBL6+5vaSJUsc/gzvt9+fOOtj259FT0y3s9+HBU88MOX3nFzNloVR9puIiHgmW0YC06mZVcD0bB5HYmJiHO7PDISnn37a7M8V0D/99FPzHOx2VJjnZAD1888/m1TvhQsXmpN0XNtDRES8NBiKjY1Feno6qlatmut+3mZA4wjvP9f+tsvCPCdT7hgw2Tae9RMREc9U2IwEpmez9pTtZjnz07dvX5OubT/zc77nZAciBlHcjy1sO3TogClTppjnXro0q7GBiLi9oq7BI57z93PLTHb2OucZPRvODCkgEhHxPLaMBH7uFzQjgetrfP311yb4YXOf3bt3Y/bs2bj99tsL/Jx8nIsN2mctNG3aFLVr1zb7dO3a1WHWAjcbZS2IuC4uAsr/7znjW7lyZXNb68C5D5bZ8LOci7jy78i/X6kEQ1y8yc/P76ycad6uVq2aw5/h/efa33bJ+7gQk/0+bds67qATFBRkNhER8WznykjYunWrw5/hjBB/rkePHuaAmZaWZhb5s6XJFeQ5mZnAg2u5cuUKlbUwduzYC3q/IlI6+AWaTbsOHTpkAiJxT5zR50kq/j1LJRjigYGpAvPnzzcd4WzTU7w9YsQIhz/TrVs38/ijj+YsGDd37lxzP/EfIgMi7mMLfng2bdmyZXjwwQeL/MZERMQ7LViwAK+88gomTZpk6k937tyJRx55xDTwYbfSkqKsBRH3wu+1/CLNEyY8QSLuhRM0/v7+FzyjV+g0OX7QDxs2DB07djTpB+zYk5CQYPKuaejQoahZs6Y5Q0Y8APXq1QtvvfUWBg4ciGnTpmHlypX4+OOPzeN8AwyUXn75ZbOukK21do0aNbIDLhER8U5FyUjgMYQpcffcc4+53apVK3Ocuu+++/Dcc88V6Dl5yRQMrn1nPzt0rtdV1oKI++H3ULaR9qZW0pJboeeUhgwZgjfffBOjRo0yMzlr167FnDlzstMNoqKizJSjfe42O/sw+GG3nu+//960zLatMURPPvkkHn74YXOg6tSpE06fPm2eU2sMiYh4N/uMBBtbRoItwyCvxMTEs1ImGPwQ0+YK8px8nF+O7Pfheno8xuX3uiIi4n58MnlkcHNMRWBXOXb/CQ8Pd/ZwRES8Skl/BrMNNjMSPvroo+yMhBkzZpj6Hp6Iy5uRMGbMGNMFjifhbGlyTLtmgMPnKshzEn+GjRc+//xz87540o7YUc4Vfi8iInLhn79u2U1ORES8BzMS2DGIGQlsXsCshLwZCfYzQVzEm6kvvDxw4IDpFHXVVVdh3LhxBX5Oevvtt83zcrFVdonjOkSsQxIREc/hETNDjPqY0x0dHa2zbyIipczWKID1NTwTJxYdm0REXP+45BEzQ6dOnTKX6tojIuLcz2IFQzl0bBIRcf3jkkfMDLHwlT3iw8LCitRezxY9etrZO098X574njz1fek9ec/74mGEBxx2Ab2QtR48jY5N3vO+9J7chye+L72nCzsuecTMEN9krVq1Lvh5+Mv2lH9Env6+PPE9eer70nvyjvelGaGz6djkfe9L78l9eOL70nsq2nFJp/BERERERMQrKRgSERERERGvpGAoa9Xw0aNHe9zK4Z74vjzxPXnq+9J7ch+e+r7cnaf+XTzxfek9uQ9PfF96TxfGIxooiIiIiIiIFJZmhkRERERExCspGBIREREREa+kYEhERERERLySgiEREREREfFKCoYATJw4EXXr1kVwcDC6dOmC5cuXw12NHz8enTp1MiueV6lSBddeey22bdsGT/Pqq6+aFd0fffRRuLMDBw7gtttuQ8WKFVGmTBm0atUKK1euhDtLT0/HCy+8gHr16pn31KBBA7z00ktmNWh38ffff+Oqq64yK1fz39msWbNyPc73MmrUKFSvXt28xz59+mDHjh1w1/eUmpqKp556yvz7K1u2rNln6NChOHjwoFPH7O10bHIvnnJc8sRjkyccl0jHpholcmzy+mBo+vTpGDlypGnft3r1arRp0wb9+vVDTEwM3NHChQsxfPhwLF26FHPnzjX/kPr27YuEhAR4ihUrVuCjjz5C69at4c5OnDiB7t27IyAgAL/99hs2b96Mt956C+XLl4c7e+211/Dhhx/igw8+wJYtW8zt119/He+//z7cBf9/4WcBv4w6wvfz3nvvYfLkyVi2bJn5kObnRlJSEtzxPSUmJprPP35Z4OXMmTPNF9Wrr77aKWMVHZvcjacclzz12OQJxyXSsWlmyRybMr1c586dM4cPH559Oz09PbNGjRqZ48ePz/QEMTExPO2RuXDhwkxPcOrUqcxGjRplzp07N7NXr16ZjzzySKa7euqppzJ79OiR6WkGDhyYedddd+W677rrrsu89dZbM90R///58ccfs29nZGRkVqtWLfONN97Ivu/kyZOZQUFBmd9++22mO74nR5YvX27227dvX6mNS3Lo2OQ+POm45KnHJk87LpGOTfuK7XW9emYoJSUFq1atMtOINr6+vub2kiVL4Ani4uLMZYUKFeAJeGZx4MCBuf5m7uqnn35Cx44dccMNN5i0kXbt2uGTTz6Bu7voooswf/58bN++3dxet24dFi1ahP79+8MT7NmzB4cPH871bzAiIsKkMXnK54bts4MpC+XKlXP2ULyOjk3uxZOOS556bPL04xLp2FR0/vBisbGxJo+0atWque7n7a1bt8LdZWRkmNxlTne3bNkS7m7atGlmmpTpCJ5g9+7dZtqeqTDPPvuseV//93//h8DAQAwbNgzu6umnn0Z8fDyaNm0KPz8/8//YuHHjcOutt8IT8GBDjj43bI+5O6ZUME/75ptvRnh4uLOH43V0bHIfnnZc8tRjk6cfl0jHpqLz6mDI0/Fs1caNG83ZD3cXHR2NRx55xOSas5jYE/ALAc++vfLKK+Y2z77x78VcX3c94NCMGTPwzTffYOrUqWjRogXWrl1rvviw8NGd35e3YC3HjTfeaApx+YVIpLh5yrHJE49Lnnps0nHJ/aWW4LHJq9PkKlWqZM4QHDlyJNf9vF2tWjW4sxEjRuCXX37BX3/9hVq1asHdMWWEhcPt27eHv7+/2ViQy0JBXudZHnfDbi/NmzfPdV+zZs0QFRUFd/bEE0+Ys3A33XST6QBz++2347HHHjPdpDyB7bPBEz83bAebffv2mS94mhVyDh2b3IMnHpc89djk6ccl0rGp6Lw6GOKUb4cOHUweqf0ZEd7u1q0b3BEjZh5sfvzxR/z555+mjaQnuOyyy7BhwwZzNse28cwVp7h5nV8c3A1TRPK2lmU+c506deDO2P2F9Q32+Pfh/1uegP9P8cBi/7nB9At27nHXzw37gw3bsM6bN8+01BXn0LHJPXjicclTj02eflwiHZuKzuvT5JgTyylSfoB17twZ77zzjmnzd+edd8Jd0w84Dfy///3PrOdgyxNlER17zrsrvpe8ueVsGcn/Kdw155xnpVjUyVQE/o/ONUQ+/vhjs7kzrhfAXOzatWubdIQ1a9ZgwoQJuOuuu+AuTp8+jZ07d+YqTOWXGxZ7830xveLll19Go0aNzAGIbT+ZbsG1U9zxPfFM8PXXX29qH3jWnme0bZ8dfJxfzqV06djk+jzxuOSpxyZPOC6Rjk3pJXNsKra+dG7s/fffz6xdu3ZmYGCgaWe6dOnSTHfFP6mjbcqUKZmexhNamP7888+ZLVu2NK0vmzZtmvnxxx9nurv4+Hjzd+H/U8HBwZn169fPfO655zKTk5Mz3cVff/3l8P+jYcOGZbcwfeGFFzKrVq1q/naXXXZZ5rZt2zLd9T3t2bMn388O/pw4h45N7scTjkueeGzyhOMS6diEEjk2+fA/xRNWiYiIiIiIuA+vrhkSERERERHvpWBIRERERES8koIhERERERHxSgqGRERERETEKykYEhERERERr6RgSEREREREvJKCIRERERER8UoKhkRERERExCspGBIREREREa+kYEhERERERLySgiEREREREfFKCoZERERERATe6P8BXJSNM+I4XaQAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 1000x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "import matplotlib.pyplot as plt  # 시각화를 위해 matplotlib 가져오기\n",
        "\n",
        "# === 1) build_dnn_model 함수 정의 (항상 2개 블록) ===\n",
        "def build_dnn_model(\n",
        "    input_shape,\n",
        "    units1=128,\n",
        "    units2=64,\n",
        "    dropout1=0.3,\n",
        "    dropout2=0.3,\n",
        "    learning_rate=1e-3\n",
        "):\n",
        "    \"\"\"\n",
        "    항상 은닉층 2개를 쌓는 DNN 모델.\n",
        "    units1, units2: 첫 번째·두 번째 Dense 블록 유닛 수\n",
        "    dropout1, dropout2: 각 블록 다음에 사용할 Dropout 비율\n",
        "    learning_rate: Adam 옵티마이저 학습률\n",
        "    \"\"\"\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Input(shape=input_shape))\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    # 첫 번째 Dense 블록\n",
        "    model.add(layers.Dense(units1, activation=None))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Activation(\"relu\"))\n",
        "    model.add(layers.Dropout(dropout1))\n",
        "\n",
        "    # 두 번째 Dense 블록\n",
        "    model.add(layers.Dense(units2, activation=None))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Activation(\"relu\"))\n",
        "    model.add(layers.Dropout(dropout2))\n",
        "\n",
        "    # 출력층\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# === 2) objective 함수 정의 ===\n",
        "def objective(trial):\n",
        "    # 2-1) 튜닝할 하이퍼파라미터 샘플링\n",
        "    units1 = trial.suggest_categorical(\"units1\", [64, 96, 128, 192, 256, 384, 512])\n",
        "    units2 = trial.suggest_categorical(\"units2\", [32, 64, 128, 256])\n",
        "    dropout1 = trial.suggest_float(\"dropout1\", 0.1, 0.5, step=0.1)\n",
        "    dropout2 = trial.suggest_float(\"dropout2\", 0.1, 0.5, step=0.1)\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True)\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64, 128])\n",
        "\n",
        "    # 2-2) 학습/검증용 데이터 분리\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X, y, test_size=0.2, stratify=y, random_state=41\n",
        "    )\n",
        "\n",
        "    # 2-3) 클래스 가중치 계산 (필요 시)\n",
        "    class_weights_array = compute_class_weight(\n",
        "        class_weight='balanced',\n",
        "        classes=np.unique(y_train),\n",
        "        y=y_train\n",
        "    )\n",
        "    class_weight_dict = {cls: w for cls, w in zip(np.unique(y_train), class_weights_array)}\n",
        "\n",
        "    # 2-4) 모델 생성 (항상 2개 블록)\n",
        "    input_shape = X_train.shape[1:]\n",
        "    model = build_dnn_model(\n",
        "        input_shape=input_shape,\n",
        "        units1=units1,\n",
        "        units2=units2,\n",
        "        dropout1=dropout1,\n",
        "        dropout2=dropout2,\n",
        "        learning_rate=learning_rate\n",
        "    )\n",
        "\n",
        "    # 2-5) 콜백 정의\n",
        "    callbacks = [\n",
        "        EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
        "    ]\n",
        "\n",
        "    # 2-6) 모델 학습\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=50,\n",
        "        batch_size=batch_size,\n",
        "        class_weight=class_weight_dict,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # 2-7) 마지막 에폭의 검증 정확도 반환\n",
        "    val_acc = history.history[\"val_accuracy\"][-1]\n",
        "    print(f\"[Trial {trial.number:>2d}] \"\n",
        "          f\"units1={units1}, units2={units2}, \"\n",
        "          f\"dropout1={dropout1:.1f}, dropout2={dropout2:.1f}, \"\n",
        "          f\"lr={learning_rate:.1e}, batch_size={batch_size} → val_acc={val_acc:.4f}\\n\")\n",
        "    return val_acc\n",
        "\n",
        "# ============================================\n",
        "# 3) Optuna 스터디 생성 및 최적화 실행\n",
        "# ============================================\n",
        "if __name__ == \"__main__\":\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective, n_trials=30, show_progress_bar=True)\n",
        "\n",
        "    print(\"========== 최적 하이퍼파라미터 ==========\")\n",
        "    for key, value in study.best_params.items():\n",
        "        print(f\"{key}: {value}\")\n",
        "\n",
        "    # ============================================\n",
        "    # 4) 최적 파라미터로 전체 데이터 재학습\n",
        "    # ============================================\n",
        "    best = study.best_params\n",
        "    final_model = build_dnn_model(\n",
        "        input_shape=X.shape[1:],\n",
        "        units1=best[\"units1\"],\n",
        "        units2=best[\"units2\"],\n",
        "        dropout1=best[\"dropout1\"],\n",
        "        dropout2=best[\"dropout2\"],\n",
        "        learning_rate=best[\"learning_rate\"]\n",
        "    )\n",
        "\n",
        "    callbacks_final = [\n",
        "        EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
        "    ]\n",
        "\n",
        "    # 4-1) 최종 학습 결과를 history 객체로 저장\n",
        "    final_history = final_model.fit(\n",
        "        X, y,\n",
        "        validation_split=0.2,\n",
        "        epochs=50,\n",
        "        batch_size=best[\"batch_size\"],\n",
        "        class_weight={cls: w for cls, w in zip(np.unique(y), compute_class_weight(\n",
        "            class_weight='balanced',\n",
        "            classes=np.unique(y),\n",
        "            y=y\n",
        "        ))},\n",
        "        callbacks=callbacks_final,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # ============================================\n",
        "    # 5) 최종 학습 과정 시각화 (plot_history 함수 사용)\n",
        "    # ============================================\n",
        "    def plot_history(history):\n",
        "        plt.figure(figsize=(10, 4))\n",
        "\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(history.history['loss'], label='train_loss')\n",
        "        plt.plot(history.history['val_loss'], label='val_loss')\n",
        "        plt.title(\"Loss\")\n",
        "        plt.legend()\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(history.history['accuracy'], label='train_acc')\n",
        "        plt.plot(history.history['val_accuracy'], label='val_acc')\n",
        "        plt.title(\"Accuracy\")\n",
        "        plt.legend()\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "    # plot_history 함수를 호출하여 학습/검증 지표 시각화\n",
        "    plot_history(final_history)\n",
        "\n",
        "    # 5-2) 모델 저장\n",
        "    final_model.save(\"dnn_model.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXJKazdsDCZ1",
        "outputId": "04e2de46-44b0-491f-aefa-1502f36a59c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========== 최종 Tie-breaker 적용 결과 ==========\n",
            "units1: 64\n",
            "units2: 128\n",
            "dropout1: 0.30000000000000004\n",
            "dropout2: 0.4\n",
            "learning_rate: 0.00023837704617109712\n",
            "batch_size: 16\n"
          ]
        }
      ],
      "source": [
        "# Optuna 튜닝 완료 후, 동일 best_value를 가진 Trial 중 최종 Best를 선택하는 후처리 코드\n",
        "\n",
        "# 1) Optuna가 기록한 최고 검증 정확도 가져오기\n",
        "best_value = study.best_value\n",
        "\n",
        "# 2) 동일한 value를 가진 모든 Trial 리스트 생성\n",
        "same_value_trials = [t for t in study.trials if t.value == best_value]\n",
        "\n",
        "# 3) 모델 복잡도 계산 함수 (units1 * units2)\n",
        "def model_complexity(trial):\n",
        "    return trial.params.get(\"units1\", float(\"inf\")) * trial.params.get(\"units2\", float(\"inf\"))\n",
        "\n",
        "# 4) 실행 시간 계산 함수\n",
        "def trial_duration(trial):\n",
        "    if trial.datetime_start and trial.datetime_complete:\n",
        "        return (trial.datetime_complete - trial.datetime_start).total_seconds()\n",
        "    return float(\"inf\")\n",
        "\n",
        "# 5) Tie-breaker: 1차 기준=모델 복잡도(작을수록 우선), 2차 기준=실행 시간(짧을수록 우선)\n",
        "def tie_breaker_key(trial):\n",
        "    return (model_complexity(trial), trial_duration(trial))\n",
        "\n",
        "# 6) 정렬 후 최종 Best Trial 선택\n",
        "sorted_trials = sorted(same_value_trials, key=tie_breaker_key)\n",
        "final_best = sorted_trials[0]\n",
        "\n",
        "# 7) 최종 Best 파라미터\n",
        "best_params = final_best.params\n",
        "\n",
        "# 예시 출력\n",
        "print(\"========== 최종 Tie-breaker 적용 결과 ==========\")\n",
        "for key, value in best_params.items():\n",
        "    print(f\"{key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnuE7NqWxT10"
      },
      "source": [
        "# 테스트 데이터 로딩 및 평가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "id": "__4iIRuXxG3l",
        "outputId": "4eb5ae96-90c9-4b64-fdab-8c6364fc1a91"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
            "\n",
            "✅ Classification Report - TEST DATA\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Real       0.81      1.00      0.89      1000\n",
            "        Fake       1.00      0.76      0.87      1000\n",
            "\n",
            "    accuracy                           0.88      2000\n",
            "   macro avg       0.90      0.88      0.88      2000\n",
            "weighted avg       0.90      0.88      0.88      2000\n",
            "\n",
            "ROC AUC: 0.905\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# -------------------------------------------\n",
        "# 6. 테스트 데이터 평가\n",
        "# -------------------------------------------\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model(\"dnn_model.h5\")\n",
        "\n",
        "\n",
        "y_prob = model.predict(X_test)\n",
        "y_pred = (y_prob > 0.8).astype(int)\n",
        "\n",
        "print(\"\\n✅ Classification Report - TEST DATA\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Real','Fake']))\n",
        "print(f\"ROC AUC: {roc_auc_score(y_test, y_prob):.3f}\")\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Real','Fake'], yticklabels=['Real','Fake'])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2OsR5E88V8l"
      },
      "source": [
        "## Spectral_Contrast 특징 활용 모델\n",
        "- 오분류된 데이터에 대해서 따로 특징을 추출하여 분류를 시도함. 이를 활용하여 약 1% 성능 향상이 가능하였음."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4cCuHCo1s0F"
      },
      "outputs": [],
      "source": [
        "def predict_with_spectral_contrast(model,X_test, score:float = 0.32):\n",
        "    # 🔹 1. DNN 예측\n",
        "    y_prob = model.predict(X_test).flatten()\n",
        "\n",
        "    # 🔹 2. 보정 대상: 확률이 낮은 샘플\n",
        "    uncertain_idx = np.where(y_prob < score)[0]\n",
        "\n",
        "    # 🔹 3. test_label.txt에서 파일 이름 가져오기\n",
        "    df = pd.read_csv(test_label_path, sep='\\s+', header=None, usecols=[1, 4], names=['filename', 'label'])\n",
        "\n",
        "    # 라벨을 숫자로 변환\n",
        "    df['label'] = df['label'].map({'Real': 0, 'Fake': 1})\n",
        "\n",
        "    # 리스트와 배열로 추출\n",
        "    test_filenames = df['filename'].tolist()\n",
        "    y_test = df['label'].values.astype(int)\n",
        "\n",
        "    # # 확인\n",
        "    # print(\"✅ 파일 예시:\", test_filenames[:5])\n",
        "    # print(\"✅ 라벨 분포:\", pd.Series(y_test).value_counts().to_dict())\n",
        "\n",
        "\n",
        "    # 🔹 4. Spectral contrast 기반 보정\n",
        "    for idx in tqdm(uncertain_idx, desc=\"📌 Spectral Contrast 보정 중\"):\n",
        "        filename = test_filenames[idx]\n",
        "        file_path = os.path.join(test_audio_path, filename)\n",
        "\n",
        "        try:\n",
        "            y, sr = librosa.load(file_path, sr=16000)\n",
        "            contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
        "            high_contrast = np.mean(contrast[-2:, :])  # 고주파 2대역 평균\n",
        "\n",
        "            if (high_contrast < 21.0 or high_contrast > 27.0):\n",
        "                y_prob[idx] = 1.0  # Fake로 강제 보정\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Error processing {filename}: {e}\")\n",
        "    return y_prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "id": "tPcNNMs119AW",
        "outputId": "22496280-34f3-410b-be58-53416cbc5a2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "📌 Spectral Contrast 보정 중: 100%|████████████████████████████████████████████████| 1186/1186 [00:12<00:00, 96.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ Classification Report - TEST DATA\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Real       0.86      1.00      0.92      1000\n",
            "        Fake       1.00      0.83      0.91      1000\n",
            "\n",
            "    accuracy                           0.91      2000\n",
            "   macro avg       0.93      0.91      0.91      2000\n",
            "weighted avg       0.93      0.91      0.91      2000\n",
            "\n",
            "ROC AUC: 0.916\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgEAAAHWCAYAAADuNVprAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA7w0lEQVR4nO3dB3gUVdfA8TMbkpAEEnqVqghEkKpUKQKiKNIRBAkKqAjSQVBBQQRFKYJS5QVpIs2GoARQASkiTboCUUB6CwImQLLfc6/frtmQwAY22Wzu//c+8yY7Mzt7JybMmXPuvWPZ7Xa7AAAA49i83QAAAOAdBAEAABiKIAAAAEMRBAAAYCiCAAAADEUQAACAoQgCAAAwFEEAAACGIggAAMBQBAGAm37//Xd55JFHJCwsTCzLki+++MKjx//jjz/0cWfOnOnR4/qyOnXq6AVA6iAIgE85ePCgvPDCC1K8eHHJnDmzhIaGSo0aNeSDDz6Qf/75J1U/OyIiQnbu3Clvv/22zJ49WypXriwZRceOHXUAon6eSf0cVQCktqvl/fffT/Hxjx07Jm+++aZs377dQy0G4AmZPHIUIA1888030qpVKwkMDJQOHTpImTJl5OrVq7Ju3Trp37+/7N69W6ZOnZoqn60ujBs2bJDXXntNunfvniqfUaRIEf05/v7+4g2ZMmWSK1euyNdffy2tW7d22TZ37lwddMXExNzWsVUQMHToUClatKiUL1/e7fetWLHitj4PgHsIAuAToqKipE2bNvpCuXr1asmfP79zW7du3eTAgQM6SEgtp0+f1l+zZcuWap+h7rLVhdZbVHClsiqffvrpDUHAvHnz5PHHH5fFixenSVtUMBIcHCwBAQFp8nmAqSgHwCeMGjVKLl26JNOnT3cJABzuuece6dmzp/P19evX5a233pK7775bX9zUHeirr74qsbGxLu9T65944gmdTXjwwQf1RViVGmbNmuXcR6WxVfChqIyDulir9znS6I7vE1LvUfslFBkZKTVr1tSBRJYsWaRkyZK6TbfqE6CCnoceekhCQkL0e5s0aSJ79+5N8vNUMKTapPZTfReeffZZfUF119NPPy3Lly+XCxcuONdt3rxZlwPUtsTOnTsn/fr1k7Jly+pzUuWExx57THbs2OHc54cffpAHHnhAf6/a4ygrOM5T1fxVVmfLli1Sq1YtffF3/FwS9wlQJRn13yjx+Tds2FCyZ8+uMw4A3EcQAJ+gUtTq4ly9enW39u/cubMMGTJEKlasKGPHjpXatWvLyJEjdTYhMXXhbNmypTRo0EBGjx6tLybqQqrKC0rz5s31MZS2bdvq/gDjxo1LUfvVsVSwoYKQYcOG6c958skn5aeffrrp+1auXKkvcKdOndIX+j59+sj69ev1HbsKGhJTd/B///23Plf1vbrQqjS8u9S5qgv0kiVLXLIApUqV0j/LxA4dOqQ7SKpzGzNmjA6SVL8J9fN2XJBLly6tz1l5/vnn9c9PLeqC73D27FkdPKhSgfrZ1q1bN8n2qb4fuXPn1sFAXFycXjdlyhRdNpgwYYIUKFDA7XMFICJ2IJ2Ljo62q1/VJk2auLX/9u3b9f6dO3d2Wd+vXz+9fvXq1c51RYoU0evWrFnjXHfq1Cl7YGCgvW/fvs51UVFRer/33nvP5ZgRERH6GIm98cYben+HsWPH6tenT59Ott2Oz5gxY4ZzXfny5e158uSxnz171rlux44ddpvNZu/QocMNn/fcc8+5HLNZs2b2nDlzJvuZCc8jJCREf9+yZUt7vXr19PdxcXH2fPny2YcOHZrkzyAmJkbvk/g81M9v2LBhznWbN2++4dwcateurbdNnjw5yW1qSei7777T+w8fPtx+6NAhe5YsWexNmza95TkCuBGZAKR7Fy9e1F+zZs3q1v7Lli3TX9Vdc0J9+/bVXxP3HQgPD9fpdgd1p6lS9eou11McfQm+/PJLiY+Pd+s9x48f173pVVYiR44czvX333+/zlo4zjOhF1980eW1Oi91l+34GbpDpf1VCv/EiRO6FKG+JlUKUFSpxWb7958RdWeuPstR6ti6davbn6mOo0oF7lDDNNUIEZVdUJkLVR5Q2QAAKUcQgHRP1ZkVleZ2x59//qkvTKqfQEL58uXTF2O1PaHChQvfcAxVEjh//rx4ylNPPaVT+KpMkTdvXl2WWLBgwU0DAkc71QU1MZViP3PmjFy+fPmm56LOQ0nJuTRq1EgHXJ999pkeFaDq+Yl/lg6q/apUUqJECX0hz5Urlw6ifv31V4mOjnb7MwsWLJiiToBqmKIKjFSQNH78eMmTJ4/b7wXwH4IA+EQQoGq9u3btStH7EnfMS46fn1+S6+12+21/hqNe7RAUFCRr1qzRNf5nnnlGXyRVYKDu6BPveyfu5Fwc1MVc3WF/8skn8vnnnyebBVBGjBihMy6qvj9nzhz57rvvdAfI++67z+2Mh+PnkxLbtm3T/SQU1QcBwO0hCIBPUB3P1ERBaqz+raie/OoCpHq0J3Ty5End693R098T1J12wp70DomzDYrKTtSrV093oNuzZ4+edEil27///vtkz0PZv3//Ddv27dun77rViIHUoC786kKrsi9JdaZ0WLRoke7Ep0ZtqP1Uqr5+/fo3/EzcDcjcobIfqnSgyjiqo6EaOaJGMABIOYIA+IQBAwboC55Kp6uLeWIqQFA9xx3pbCVxD3518VXUeHdPUUMQVdpb3dknrOWrO+jEQ+kSc0yak3jYooMaCqn2UXfkCS+qKiOiesM7zjM1qAu7GmL54Ycf6jLKzTIPibMMCxculL/++stlnSNYSSpgSqlXXnlFDh8+rH8u6r+pGqKpRgsk93MEkDwmC4JPUBdbNVRNpdBVPTzhjIFqyJy68KgOdEq5cuX0RUHNHqguOmq42s8//6wvGk2bNk12+NntUHe/6qLUrFkz6dGjhx6TP2nSJLn33ntdOsapTmyqHKACEHWHr1LZEydOlLvuukvPHZCc9957Tw+dq1atmnTq1EnPKKiGwqk5ANSQwdSishavv/66WxkadW7qzlwN31SpedWPQA3nTPzfT/XHmDx5su5voIKCKlWqSLFixVLULpU5UT+3N954wzlkccaMGXougcGDB+usAIAUSGLEAJBu/fbbb/YuXbrYixYtag8ICLBnzZrVXqNGDfuECRP0cDWHa9eu6WFtxYoVs/v7+9sLFSpkHzRokMs+ihre9/jjj99yaFpyQwSVFStW2MuUKaPbU7JkSfucOXNuGCK4atUqPcSxQIECej/1tW3btvp8En9G4mF0K1eu1OcYFBRkDw0NtTdu3Ni+Z88el30cn5d4CKI6llqvju3uEMHkJDdEUA2lzJ8/v26faueGDRuSHNr35Zdf2sPDw+2ZMmVyOU+133333ZfkZyY8zsWLF/V/r4oVK+r/vgn17t1bD5tUnw3AfZb6v5QEDQAAIGOgTwAAAIYiCAAAwFAEAQAAGIogAAAAQxEEAABgKIIAAAAMRRAAAIChMuSMgUEVunu7CUCqO7/5Q283AUh1mTP5zvXin22+9zeZIYMAAADcYpmdEDf77AEAMBiZAACAuSzPPebaFxEEAADMZZmdEDf77AEAMBiZAACAuSzKAQAAmMkyOyFu9tkDAGAwMgEAAHNZlAMAADCTZXZC3OyzBwDAYGQCAADmsigHAABgJsvshLjZZw8AgMHIBAAAzEU5AAAAQ1lmJ8TNPnsAAAxGJgAAYC6LcgAAAGayzE6Im332AAAYjEwAAMBcltn3wgQBAABz2czuE2B2CAQAgMHIBAAAzGWZfS9MEAAAMJdFOQAAABiITAAAwFyW2ffCBAEAAHNZlAMAAICByAQAAMxlmX0vTBAAADCXRTkAAAAYiEwAAMBcltn3wgQBAABzWZQDAACAgcgEAADMZZl9L0wQAAAwl0U5AAAAGIhMAADAXJbZ98IEAQAAc1lmBwFmnz0AAAYjEwAAMJdldsdAggAAgLkssxPiZp89AAAGIxMAADCXRTkAAAAzWWYnxM0+ewAADEYmAABgLotyAAAARrIMDwIoBwAAYCgyAQAAY1mGZwIIAgAA5rLEaJQDAAAwFJkAAICxLMoBAACYyTI8CKAcAACAocgEAACMZRmeCSAIAAAYyzI8CKAcAACAocgEAADMZYnRCAIAAMayKAcAAAATkQkAABjLMjwTQBAAADCWZXgQQDkAAABDkQkAABjLMjwTQBAAADCXJUajHAAAgKHIBAAAjGVRDgAAwEyW4UEA5QAAAAxFEAAAMDoTYHloSYm4uDgZPHiwFCtWTIKCguTuu++Wt956S+x2u3Mf9f2QIUMkf/78ep/69evL77//7nKcc+fOSbt27SQ0NFSyZcsmnTp1kkuXLrndDoIAAIC5LA8uKfDuu+/KpEmT5MMPP5S9e/fq16NGjZIJEyY491Gvx48fL5MnT5ZNmzZJSEiINGzYUGJiYpz7qABg9+7dEhkZKUuXLpU1a9bI888/7/7p2xOGHRlEUIXu3m4CkOrOb/7Q200AUl3mVO65lqfTAo8d69T01m7v+8QTT0jevHll+vTpznUtWrTQd/xz5szRWYACBQpI3759pV+/fnp7dHS0fs/MmTOlTZs2OngIDw+XzZs3S+XKlfU+3377rTRq1EiOHj2q338rZAIAAMayPFgOiI2NlYsXL7osal1SqlevLqtWrZLffvtNv96xY4esW7dOHnvsMf06KipKTpw4oUsADmFhYVKlShXZsGGDfq2+qhKAIwBQ1P42m01nDtxBEAAAMJblwSBg5MiR+kKdcFHrkjJw4EB9N1+qVCnx9/eXChUqSK9evXR6X1EBgKLu/BNSrx3b1Nc8efK4bM+UKZPkyJHDuc+tMEQQAAAPGDRokPTp08dlXWBgYJL7LliwQObOnSvz5s2T++67T7Zv366DAJXCj4iIkLRCEAAAMJblwXkC1AU/uYt+Yv3793dmA5SyZcvKn3/+qTMHKgjIly+fXn/y5Ek9OsBBvS5fvrz+Xu1z6tQpl+Nev35djxhwvP9WKAcAAIxleWmI4JUrV3TtPiE/Pz+Jj4/X36uhg+pCrvoNOKg+BqrWX61aNf1afb1w4YJs2bLFuc/q1av1MVTfAXeQCQAAII01btxY3n77bSlcuLAuB2zbtk3GjBkjzz33nN6uggpVHhg+fLiUKFFCBwVqXgFVLmjatKnep3Tp0vLoo49Kly5d9DDCa9euSffu3XV2wZ2RAQpBAADAXJZ3PlbNB6Au6i+99JJO6auL9gsvvKAnB3IYMGCAXL58WY/7V3f8NWvW1EMAM2fO7NxH9StQF/569erpzIIaZqjmFnAX8wQAPop5AmCC1J4noGDXzz12rL8mNRNfQ58AAAAMRTkAAGAsy/CnCBIEAACMZREEeEfz5s3d3nfJkiWp2hYAAEzktSBATacIAIBXWWI0rwUBM2bM8NZHAwCgmV4OYHQAAACGSjcdAxctWqQfqHD48GG5evWqy7atW7d6rV0AgIzLIhPgfWp2o2effVY/IlFNnfjggw9Kzpw55dChQ85nKyPtZQkOlPf6tZD9y4bJuQ1j5PuZfaRSeGHn9jw5ssrUoe3l0Iq35ez6MfLlhy/J3YVz33CcKvcXk+VTXpYz60fLybXvSeT0XpI50D+NzwbwjOnTpkq5+0rKqJFve7sp8OFnB6QX6SIImDhxokydOlVPoxgQEKCnSoyMjJQePXpIdHS0t5tnrElDnpaHq5aS517/RCq3HiErN+yTbya/LAVy/9upc8HY56XYXbmkVa8pUrXtO3L4+DlZNvllCc4c4BIAqOBg1cZ98lD796Rm+/dk8vwfJT4+w01UCQPs2vmrLFo4X+69t6S3mwJknCBAlQCqV6+uvw8KCpK///5bf//MM8/Ip59+6uXWmUndqTetV15eG/eF/LT1oBw6ckbenrJMDh45LV1aPST3FM6jL/A93p4vW/Yclt//PCU9Rnym39f6sUrO44zq21wmzv9B3p8RKXsPndD7LY7cJlevXffq+QEpdeXyZRn0Sn95Y+hwCWV0U4ZhkQnwPvW4RPX8Y0U9UWnjxo36+6ioKMmAjzbwCZn8bJIpk5/EXL3msj4m9ppUr3C3BAb8250k5up/F3P13+rq1etSvfzd+nXu7FnkwfuLyelzl3Qp4Y+VI2TFxz2levniaXw2wJ0bMXyY1KpVW6pW+/eGBRmE5cHFB6WLIODhhx+Wr776Sn+v+gb07t1bGjRoIE899ZQ0a3bzBzLExsbqZywnXOzxcWnU8ozr0pVY2bjjkAzq8pjkzx0mNpslbRo9oO/+8+UKlf1/nNDp/7deflKyZQ0S/0x+0rdjfbkrX3bJl+vfuyRVKlBee6GR/G/JemnSbaJs33tElk15Ocm+A0B6tXzZN7J37x7p0buvt5sCZLzRAao/QHx8vP6+W7duulPg+vXr5cknn9SPVryZkSNHytChQ13W+eV9QPzzP5iqbTbBc6/PkilvttMd/65fj5Pt+47Igm9/kQqlC8v16/HSpu80mfRGOzm+5j29ffWm/fLtut3iyIqpwEGZvnidzP7q3+zOjv1Hpc6DJSWiSTUZMuHfwA9Iz04cPy6j3nlbpkz7nwQGBnq7OfAwy0fT+BkqCFDPQFaLQ5s2bfTijkGDBkmfPn1c1uV56BWPt9FEUUfPyCOdP9Ad/UKzZJYTZy7K7Heelai/zujt2/Yekapt3tHbAvwzyZnzl2TNrH66j4By/PRF/VX1BUhof9QJKZQvuxfOCEi5PXt2y7mzZ6VNq/+mOo+Li5Mtv2yW+Z/Olc3bdoqfn59X24jbZxEEpA9r166VKVOmyMGDB/WcAQULFpTZs2dLsWLFpGbNmsm+T0XmiaNzy8YfpCddibmqF5X2r1+9tLw27kuX7RcvxeivKsVfMbywDJ24VL/+89hZOXbqgtxbNI/L/vcUySMrftqThmcA3L4qVavKoi++dln3xmuDpGjx4vJspy4EAPBp6SIIWLx4sR4J0K5dOz1PgKrzK2p44IgRI2TZsmXebqKR6lcrrVP7v/1xSu4ulFtG9G4qv0WdlFlfbdDbm9evIKfPX5IjJ85JmRIF5P3+LeXrH37VwwEdxn6yUl5/8XHZ+dtfuhTQvnEVKVk0rzzdf7oXzwxwX0hIFilR4l6XdUHBwZItLNsN6+F7LLMTAekjCBg+fLhMnjxZOnToIPPnz3eur1Gjht4G7wjLklmGvfykFMybTc5FX5EvV22XNz76WvcHUPLlDpV3+zaXPDmz6lLB3KWbZOTUb12O8eG8H/SwwVF9W0j2sGAdDDzR9UNdagAAb7MMjwIsezoYgxccHCx79uyRokWLStasWWXHjh1SvHhxPWNgeHi4xMT8m252V1CF7qnWViC9OL/5Q283AUh1mVP5VrVEf9cblzvx+3uPiq9JN/MEHDhw4Ib169at08EAAACpwbI8t/iidBEEdOnSRXr27CmbNm3SqZljx47J3LlzpW/fvtK1a1dvNw8AkEFZhs8YmC76BAwcOFDPE1CvXj25cuWK1KpVS/f479+/v3Tu3NnbzQMAIENKF5kAFUG99tpreurgXbt26WmDT58+LWFhYXqIIAAAqcGiHOA9aiigmuyncuXKeiSAGgqoOgLu3r1bSpYsKR988IGeQhgAgNRgs1keW3yRV8sBQ4YM0RME1a9fX08T3KpVK/3sAJUJGD16tH7NRBwAAGTAIGDhwoUya9Ys/YwAVQa4//775fr163qIoK92sgAA+A7L8EuNV8sBR48elUqV/n32fJkyZXRnQJX+JwAAACCDZwLUQzgCAgL+a0ymTJIlSxZvNgkAYBDL8JtOrwYBarLCjh07Oh8ApGYGfPHFFyUkJMRlvyVLlniphQCAjMwyOwbwbhAQERHh8rp9+/ZeawsAAKbxahAwY8YMb348AMBwluGpgHQxYyAAAN5gGR4EpIsZAwEAQNojEwAAMJZldiKAIAAAYC7L8CiAcgAAAIYiEwAAMJZldiKAIAAAYC7L8CiAcgAAAIYiEwAAMJZldiKAIAAAYC7L8CiAcgAAAIYiEwAAMJZldiKAIAAAYC7L8CiAcgAAAIYiEwAAMJZldiKAIAAAYC7L8CiAcgAAAIYiEwAAMJZldiKAIAAAYC7L8CiAcgAAAIYiEwAAMJZldiKAIAAAYC7L8CiAcgAAAIYiEwAAMJZleCaAIAAAYCzL7BiAcgAAAKYiEwAAMJZleCqAIAAAYCzL7BiAcgAAAKYiEwAAMJZleCqAIAAAYCzL7BiAcgAAAKYiEwAAMJbN8FQAQQAAwFiW2TEA5QAAAExFJgAAYCzL8FQAmQAAgLFslueWlPrrr7+kffv2kjNnTgkKCpKyZcvKL7/84txut9tlyJAhkj9/fr29fv368vvvv7sc49y5c9KuXTsJDQ2VbNmySadOneTSpUvun3/Kmw0AAO7E+fPnpUaNGuLv7y/Lly+XPXv2yOjRoyV79uzOfUaNGiXjx4+XyZMny6ZNmyQkJEQaNmwoMTExzn1UALB7926JjIyUpUuXypo1a+T55593ux2WXYUaGUxQhe7ebgKQ6s5v/tDbTQBSXeZULlo3mvyzx471+bPlJDY21mVdYGCgXhIbOHCg/PTTT7J27dokj6UuzQUKFJC+fftKv3799Lro6GjJmzevzJw5U9q0aSN79+6V8PBw2bx5s1SuXFnv8+2330qjRo3k6NGj+v23QiYAAGAsy/LcMnLkSAkLC3NZ1LqkfPXVV/rC3apVK8mTJ49UqFBBpk2b5tweFRUlJ06c0CUAB3W8KlWqyIYNG/Rr9VWVABwBgKL2t9lsOnPgDoIAAAA8YNCgQfpuPeGi1iXl0KFDMmnSJClRooR899130rVrV+nRo4d88sknersKABR155+Qeu3Ypr6qACKhTJkySY4cOZz73AqjAwAAxrLEc6MDkkv9JyU+Pl7fwY8YMUK/VpmAXbt26fp/RESEpBUyAQAAY9m8NDpA9fhX9fyESpcuLYcPH9bf58uXT389efKkyz7qtWOb+nrq1CmX7devX9cjBhz73PL8U9ZsAABwp9TIgP3797us++2336RIkSL6+2LFiukL+apVq5zbL168qGv91apV06/V1wsXLsiWLVuc+6xevVpnGVTfAXdQDgAAGMvy0mRBvXv3lurVq+tyQOvWreXnn3+WqVOn6sXRrl69esnw4cN1vwEVFAwePFj3+G/atKkzc/Doo49Kly5ddBnh2rVr0r17dz1ywJ2RAQpBAADAWJaXJgx84IEH5PPPP9cdB4cNG6Yv8uPGjdPj/h0GDBggly9f1uP+1R1/zZo19RDAzJkzO/eZO3euvvDXq1dPjwpo0aKFnlvAXcwTAPgo5gmACVJ7noCmH/83Q9+d+qLzf0P1fAWZAACAsWyGPzuAIAAAYCzL7BiA0QEAAJiKTAAAwFiW4akAggAAgLEss2MAygEAAJiKTAAAwFg2w1MBBAEAAGNZYjbKAQAAGIpMAADAWBblAAAAzGQzOwagHAAAgKnIBAAAjGVRDri1r776yu0DPvnkk3fSHgAA0oxldgzgXhDQtGlTtyOquLi4O20TAABIL0FAfHx86rcEAIA0ZhmeCqBPAADAWDazY4DbCwIuX74sP/74oxw+fFiuXr3qsq1Hjx6eahsAAEhPQcC2bdukUaNGcuXKFR0M5MiRQ86cOSPBwcGSJ08eggAAgM+wDC8HpHiegN69e0vjxo3l/PnzEhQUJBs3bpQ///xTKlWqJO+//37qtBIAgFRgeXAxIgjYvn279O3bV2w2m/j5+UlsbKwUKlRIRo0aJa+++mrqtBIAAHg/CPD399cBgKLS/6pfgBIWFiZHjhzxfAsBAEjFRwnbPLQY0SegQoUKsnnzZilRooTUrl1bhgwZovsEzJ49W8qUKZM6rQQAIBVYvnnt9l4mYMSIEZI/f379/dtvvy3Zs2eXrl27yunTp2Xq1Kmp0UYAAJAeMgGVK1d2fq/KAd9++62n2wQAQJqwDE8FMFkQAMBYltkxQMqDgGLFit00cjp06NCdtgkAAKTHIKBXr14ur69du6YnEFJlgf79+3uybQAApCqb4amAFAcBPXv2THL9Rx99JL/88osn2gQAQJqwzI4BUj46IDmPPfaYLF682FOHAwAAvtIxcNGiRfo5AgAA+ArL8FTAbU0WlPCHZrfb5cSJE3qegIkTJ0p6sHXZu95uApDq8nec6+0mAKnu/Jx2vpEONyUIaNKkiUsQoKYQzp07t9SpU0dKlSrl6fYBAID0EgS8+eabqdMSAADSmGV4OSDFmRD15MBTp07dsP7s2bN6GwAAvsJmeW4xIghQfQCSoh4pHBAQ4Ik2AQCA9FQOGD9+vDN18vHHH0uWLFmc2+Li4mTNmjX0CQAA+BSbj97Bp3kQMHbsWGcmYPLkyS6pf5UBKFq0qF4PAICvsAzvE+B2EBAVFaW/1q1bV5YsWaIfIQwAAAwaHfD999+nTksAAEhjNrMTASnvGNiiRQt5990bJ+MZNWqUtGrVylPtAgAg1VmW5xYjggDVAbBRo0ZJPjtAbQMAABm0HHDp0qUkhwL6+/vLxYsXPdUuAABSnc1Xb+G9lQkoW7asfPbZZzesnz9/voSHh3uqXQAApMlF0OahxYhMwODBg6V58+Zy8OBBefjhh/W6VatWybx58/STBAEAQAYNAho3bixffPGFjBgxQl/0g4KCpFy5crJ69WoeJQwA8CmW2dWAlAcByuOPP64XRfUD+PTTT6Vfv36yZcsWPXsgAAC+wGZ4FHDbZQw1EiAiIkIKFCggo0eP1qWBjRs3erZ1AAAgfWQCTpw4ITNnzpTp06frDEDr1q31g4NUeYBOgQAAX2OZnQhwPxOg+gKULFlSfv31Vxk3bpwcO3ZMJkyYkLqtAwAgFdkMf5Sw25mA5cuXS48ePaRr165SokSJ1G0VAABIP5mAdevWyd9//y2VKlWSKlWqyIcffihnzpxJ3dYBAJDKHQNtHloydBBQtWpVmTZtmhw/flxeeOEFPTmQ6hQYHx8vkZGROkAAAMCXWDw7IGVCQkLkueee05mBnTt3St++feWdd96RPHnyyJNPPpk6rQQAAB53RzMdqo6C6umBR48e1XMFAADgS2x0DLxzfn5+0rRpU70AAOArLPHRq7eH+OozDwAAQHrIBAAA4ItsZicCCAIAAOayGR4EUA4AAMBQZAIAAMayfHWAv4cQBAAAjGUzOwagHAAAgKnIBAAAjGUZngkgCAAAGMtmeBRAOQAAAEMRBAAAjGVLB88OUA/hU6MUevXq5VwXExMj3bp1k5w5c0qWLFmkRYsWcvLkSZf3HT58WB5//HEJDg7WD/Hr37+/XL9+PWXnf/vNBgDAt1lefpTw5s2bZcqUKXL//fe7rO/du7d8/fXXsnDhQvnxxx/l2LFj0rx5c+f2uLg4HQBcvXpV1q9fL5988onMnDlThgwZkqLPJwgAAMALLl26JO3atZNp06ZJ9uzZneujo6Nl+vTpMmbMGHn44YelUqVKMmPGDH2x37hxo95nxYoVsmfPHpkzZ46UL19eHnvsMXnrrbfko48+0oGBuwgCAADGsonlsSU2NlYuXrzosqh1yVHpfnU3X79+fZf1W7ZskWvXrrmsL1WqlBQuXFg2bNigX6uvZcuWlbx58zr3adiwof7M3bt3p+D8AQAwlOXBcsDIkSMlLCzMZVHrkjJ//nzZunVrkttPnDghAQEBki1bNpf16oKvtjn2SRgAOLY7trmLIYIAAHjAoEGDpE+fPi7rAgMDb9jvyJEj0rNnT4mMjJTMmTOLN5EJAAAYy+bB0QHqgh8aGuqyJBUEqHT/qVOnpGLFipIpUya9qM5/48eP19+rO3pV179w4YLL+9TogHz58unv1dfEowUcrx37uHX+t/lzAwAgQ0wWZPPQ4q569erJzp07Zfv27c6lcuXKupOg43t/f39ZtWqV8z379+/XQwKrVaumX6uv6hgqmHBQmQUVeISHh7vdFsoBAACkoaxZs0qZMmVc1oWEhOg5ARzrO3XqpEsLOXLk0Bf2l19+WV/4q1atqrc/8sgj+mL/zDPPyKhRo3Q/gNdff113Nkwq+5AcggAAgLGsdDpr8NixY8Vms+lJgtQIA9Xzf+LEic7tfn5+snTpUunatasODlQQERERIcOGDUvR51h2u90uGcze45e93QQg1VXv/4W3mwCkuvNz2qXq8af/fNhjx+r0YGHxNfQJAADAUJQDAADGstJpOSCtEAQAAIxlE7OZfv4AABiLTAAAwFiW4fUAggAAgLEsMRvlAAAADEUmAABgLBvlAAAAzGSJ2SgHAABgKDIBAABjWYanAggCAADGsgyPAigHAABgKDIBAABj2cRsBAEAAGNZlAMAAICJyAQAAIxlidkIAgAAxrIoBwAAABORCQAAGMsmZiMIAAAYy6IcAAAATEQmAABgLEvMRhAAADCWZXgUQDkAAABDkQkAABjLZnhBgCAAAGAsy+wYgHIAAACmIhMAADCWRTkAAAAzWWbHAJQDAAAwFZkAAICxbJQDAAAwk2V2DEA5AAAAU5EJAAAYyzI8E0AQAAAwlmV4nwDKAQAAGIpMAADAWDazEwEEAQAAc1mUA9KHtWvXSvv27aVatWry119/6XWzZ8+WdevWebtpAABkSOkiCFi8eLE0bNhQgoKCZNu2bRIbG6vXR0dHy4gRI7zdPABABh4dYHlo8UXpIggYPny4TJ48WaZNmyb+/v7O9TVq1JCtW7d6tW0AgIxdDrA89D9flC6CgP3790utWrVuWB8WFiYXLlzwSpsAAMjo0kUQkC9fPjlw4MAN61V/gOLFi3ulTQAAM0YH2Dy0+KJ0EQR06dJFevbsKZs2bRLLsuTYsWMyd+5c6devn3Tt2tXbzQMAZFCW4eWAdDFEcODAgRIfHy/16tWTK1eu6NJAYGCgDgJefvllbzfPWLt3bJHP58+Sg7/tlfNnz8jAt0ZL1Yfquuxz5M9DMmvKeNm9Y6vExV2XQkWKyyvD3pPcefPLyePH5IW2TyR57P5vvis16jRIozMBkmazLBnYoqy0rl5M8mTLLCfO/yPz1h6S97/Y5dznleZlpXnVIlIwR4hci4uT7VHnZPjCHbLl4FnnPvP61JayhbNLrtDMcuHKVflx1wl5c/42OXHhHy+dGeBDQcD169fltddek/79++uywKVLlyQ8PFyyZMkiZ86ckVy5cnm7iUaKiYmRYnffK/UbNZF3Bve7Yfvxv47Iqy93knqNmkjbZ1+UoOAQOfLHIfEPCNTbc+XJKzMWr3B5z4qlS3RgUfHBGml2HkByejUOl+fqlZCXpmyQvUejpUKxHPLh89Xk4pVrMnXFfr3PweN/y4BPfpE/Tl2SoAA/6fpYKVnyysNSse9Xcvbvf0cyrd1zUsZ8uUtOXoiR/DmC5K22FeWTHg9Jw2Guv/9IfyzfvIHPWEFAmzZtZNGiRRIQEKAv/g4nT57U2YFdu/6LypF2KlWpoZfkzP34I6lYpYZ0fLGXc13+goWc3/v5+Un2nK4B3Ma130uNug0kKDg4lVoNuO/BErll2ZajsmL7Mf36yJnL0qJaUal0d07nPos2/OHyntfnbpEOde6R+wpnkzW7T+p1k77d59x+5OxlGbd0t8zpVVsy+VlyPc6eZueDlLPEbOmiT8Dhw4elc+fOLuuOHz8uderUkVKlSnmtXUieKt/8snGdFChURN7s/5JENK0n/bt20Bf55BzYv0eiDuyXBo2apmlbgeT8/PtpqX1fPrk7X1b9ukzhbFK1ZG5ZuePfoCAxfz+bRNQtIdGXr8quP5MeuZQtJEBaVi+mj00AgPQuXWQCli1bpvsB9OnTR8aMGaM7BtatW1fKlSsn8+fPv+l71cRCjsmFHK7GXpeAwH9T0kgd0efPScw/V2TJvBnSrtNL0uH5nrLt5/Xy7pB+8tbYqVKmfKUb3rNy2ZdyV5FiUqpMOa+0GUhs7Ne7JWuQv/w8qrHExdvFz2bpev/C9a53/w3LF5SPu9eQ4IBMus7f7N1Vcu6S6787bz5VXjo3KCkhmTPpAKDN6B/S+Gxwu/1CTJYuMgG5c+eWFStW6JkDVSCgMgAVKlSQTz/9VGy2mzdx5MiRej6BhMvUCe+nWdtNZbf/e4fzYI068mSr9lK8RElp0e5ZqVztIfnuq0U37B8bGyNrVi6X+mQBkI40q1JEWlUvKl0m/iR1Xl+u+wZ0b1Ra2jxUzGW/tXtPSK3XlknDod/Jql+PyYzuD0muUNcbjfHf7JXary+TZu+skvh4u0x+sXoanw1uh+XBxReli0yAUqhQIYmMjJSHHnpIGjRooJ8boIYL3sqgQYN04JBQ1LnrqdhSKFnDsomfXyY9GiAhdae/d+f2G/Zf/+NKuRobI3UbJj1aAPCGYW0ryLiv98iSjX/q13uOXpC7coVI78b3yfy1Uc79rsTGSdTJS3r55eBZ+eX9xvJM7Xt0JsFBZQbUcvDE3/LbsWjZPb65PHBPLtl84IxXzg1I10FA9uzZk7zIqyGCX3/9teTM+V/HnHPnziV7HDWUUC0JBVy+7OHWIjE1vfM9pcLlryOuadNjRw7r4YGJrfzmS3mgem0Jy5Y9DVsJ3FxQQCaJ//+sloO6i79VilhtD/BPPkvpeP/N9kE6YYnRvBYEjBs3zlsfDTf9c+WKHgbocOrEX3Lo9/2SNTRUX+ibtekg7w8dKPeVqyhly1eWrT+vl83r18jwcVNdjnP86GHZ8+tWGfzOeC+cBZC8b7cdlT5NysjRs5f1EMH7i2aXlx4rJXN/PKi3Bwf6Sd8mZWT5lqN6+F+OrIHSucG9kj97sHy56bDeR40kqFg8p2zYf1p3GCyaN4u81rKcHDr5t2z+nSxAemcZHgVYdkdxNwPZe5xMgCfs3PaLDO79/A3r6zZsLD0HDdXfr1z2hSyeO0POnj6lRwqo+QKq1Kzjsv/saRPkx8jlMnX+0lv28YD7qvf/wttN8HlZMmeSV1uWkycqF9I1fjVZ0OINf8qoz3fKtbh4CfS3ybSXakilu3NJzqyBOt2/7dBZef/LXbLt0L8ZyvC7ssnIZypJmcLZJTgwk5y88I/uN6D2OX6eyYLu1Pk57VL1+JsORnvsWFXuDhNfk+6CADVBzdWrV13WhYaGpugYBAEwAUEATJDaQcDPhzwXBDxY3PeCgHRxW3b58mXp3r275MmTR0JCQnR/gYQLAACpwTJ8dEC6CAIGDBggq1evlkmTJulOfh9//LEMHTpUChQoILNmzfJ28wAAyJDSxRBBNRpAXezV/ADPPvusHiZ4zz33SJEiRfTTBNu1S910EADAUJYYLV1kAtQQwOLFizvr/44hgTVr1pQ1a9Z4uXUAgIzKMvxRwukiCFABQFTUvxNzqGcFLFiwwJkhyJYtm5dbBwBAxuTVIODQoUP6QTSqBLBjxw69buDAgfLRRx9J5syZpXfv3vrxwgAApAbL8tzii7zaJ6BEiRL6aYHqYq889dRTMn78eNm3b59s2bJF9wu4//77vdlEAAAyLK9mAhJPUaCeJqiGC6oOgc2bNycAAACkKsvwIYLpYnQAAABeYYnRvJoJUA8QSvwQIXeeHAgAAHw8E6DKAR07dnQ+BVBNGfziiy/qWQMTWrJkiZdaCADIyCzDUwFezQREREToqYLDwsL00r59ez1LoOO1YwEAICONDhg5cqQ88MADkjVrVn0dbNq0qezfv99lH3Vj3K1bN8mZM6dkyZJFWrRoISdPnnTZ5/Dhw/L4449LcHCwPo4aUXf9+nXfyATMmDHDmx8PAIBX/Pjjj/oCrwIBddF+9dVX5ZFHHpE9e/Y4s+Fq5Nw333wjCxcu1DfE6hk7qtP8Tz/9pLfHxcXpACBfvnyyfv16PdquQ4cO4u/vLyNGjPDNpwh6Ak8RhAl4iiBMkNpPEdxx+G+PHatc4ay3/d7Tp0/rO3kVHNSqVUuio6Mld+7cMm/ePGnZsqXeRw2fL126tGzYsEGqVq0qy5cvlyeeeEKOHTsmefPm1ftMnjxZXnnlFX28gIAA35gxEAAAXx8jGBsbKxcvXnRZ1Dp3qIu+kiNHDv1VzZVz7do1qV+/vnMfNaNu4cKFdRCgqK9ly5Z1BgBKw4YN9efu3r3brc8lCAAAwANUnT9xnza17lbUzLm9evWSGjVqSJkyZfS6EydO6Dv5xFPnqwu+2ubYJ2EA4Nju2OYO5gkAABjL8uDogEGDBkmfPn1c1jlGv92M6huwa9cuWbdunaQ1ggAAgLEsD44QVBd8dy76CanOfkuXLtVPzL3rrruc61Vnv6tXr8qFCxdcsgFqdIDa5tjn559/djmeY/SAY59boRwAAEAaU33yVQDw+eefy+rVq6VYsWIu2ytVqqR7+a9atcq5Tg0hVEMCq1Wrpl+rrzt37pRTp04594mMjJTQ0FAJDw93qx1kAgAAxrK89LmqBKB6/n/55Zd6rgBHDV/1IwgKCtJfO3XqpMsLqrOgurC//PLL+sKvRgYoakihutg/88wzMmrUKH2M119/XR/b3YwEQQAAwFyWdz520qRJ+mudOnVumD9HzaSrjB07Vmw2m54kSI0yUD3/J06c6NzXz89PlxK6du2qgwM1v4CahG/YsGFut4N5AgAfxTwBMEFqzxOw669LHjtWmYJZxNeQCQAAGMsy/NkBBAEAAGNZZscAjA4AAMBUZAIAAMayxGwEAQAAc1liNMoBAAAYikwAAMBYluGpAIIAAICxLLNjAMoBAACYikwAAMBYlpiNIAAAYC5LjEY5AAAAQ5EJAAAYyzI8FUAQAAAwlmV2DEA5AAAAU5EJAAAYyxKzEQQAAMxlidEoBwAAYCgyAQAAY1mGpwIIAgAAxrLMjgEoBwAAYCoyAQAAY1liNoIAAIC5LDEa5QAAAAxFJgAAYCzL8FQAQQAAwFiW2TEA5QAAAExFJgAAYCxLzEYQAAAwlmV4FEA5AAAAQ5EJAAAYzBKTEQQAAIxlmR0DUA4AAMBUZAIAAMayxGwEAQAAY1mGRwGUAwAAMBSZAACAsSzDCwIEAQAAc1liNMoBAAAYikwAAMBYlpiNIAAAYCzL8CiAcgAAAIYiEwAAMJZleEGAIAAAYC5LjEY5AAAAQ5EJAAAYyxKzEQQAAIxlGR4FUA4AAMBQZAIAAMayDC8IEAQAAIxlmR0DUA4AAMBUBAEAABiKcgAAwFgW5QAAAGAiMgEAAGNZjA4AAMBMltkxAOUAAABMRSYAAGAsS8xGEAAAMJclRqMcAACAocgEAACMZRmeCiAIAAAYyzI7BqAcAACAqcgEAACMZYnZCAIAAOayxGiUAwAAMBSZAACAsRgdAACAoSyzYwDKAQAAmMqy2+12bzcCvi02NlZGjhwpgwYNksDAQG83B0gV/J4jIyIIwB27ePGihIWFSXR0tISGhnq7OUCq4PccGRHlAAAADEUQAACAoQgCAAAwFEEA7pjqJPXGG2/QWQoZGr/nyIjoGAgAgKHIBAAAYCiCAAAADEUQAACAoQgC4BUdO3aUpk2bersZQIrMnDlTsmXL5u1mAB5DEIAkL9CWZenF399fihUrJgMGDJCYmBhvNw3w+O94wuXAgQPebhqQpniKIJL06KOPyowZM+TatWuyZcsWiYiI0P9Ivvvuu95uGuDR3/GEcufO7bX2AN5AJgBJUmOh8+XLJ4UKFdJp+/r160tkZKTeFh8frx+kojIEQUFBUq5cOVm0aJHzvXFxcdKpUyfn9pIlS8oHH3zgxbMBkv8dT7io39OyZctKSEiI/t1/6aWX5NKlS8ke4/Tp01K5cmVp1qyZfsDQrf42gPSGTABuadeuXbJ+/XopUqSIfq3+kZszZ45MnjxZSpQoIWvWrJH27dvru6jatWvrfwjvuusuWbhwoeTMmVO/9/nnn5f8+fNL69atvX06QLJsNpuMHz9eX8QPHTqkgwBVCps4ceIN+x45ckQaNGggVatWlenTp4ufn5+8/fbbN/3bANIdNVkQkFBERITdz8/PHhISYg8MDFSTSdltNpt90aJF9piYGHtwcLB9/fr1Lu/p1KmTvW3btskes1u3bvYWLVq4fEaTJk1S9TwAd37HHUvLli1v2G/hwoX2nDlzOl/PmDHDHhYWZt+3b5+9UKFC9h49etjj4+P1ttv92wC8iUwAklS3bl2ZNGmSXL58WcaOHSuZMmWSFi1ayO7du+XKlSv6Diihq1evSoUKFZyvP/roI/nf//4nhw8fln/++UdvL1++vBfOBLj577iDKgGsXLlSZ7r27dunHx18/fp13SFW/c4HBwfr/dTv80MPPSRPP/20jBs3zvl+1anQnb8NID0hCECS1D+I99xzj/5eXcxVbVOlPMuUKaPXffPNN1KwYEGX9zjmVJ8/f77069dPRo8eLdWqVZOsWbPKe++9J5s2bfLCmQC3/h1X/vjjD3niiSeka9euOq2fI0cOWbdune7foi7kjiBA/Z6rPjJLly6V/v37O/8OHH0Hbva3AaQ3BAFwq0766quvSp8+feS3337T/6CpO/zkapw//fSTVK9eXddTHQ4ePJiGLQZSTo2CUf1ZVPCqfueVBQsW3LCf2jZ79mydCVDZhB9++EEKFCgg4eHht/zbANIbggC4pVWrVvquZ8qUKfouv3fv3vofzJo1a0p0dLS+8IeGhuqhhKpD1KxZs+S7777THazUP5ibN2/W3wPplcoKqCGxEyZMkMaNG+vfadXBLymqE+DcuXOlbdu28vDDD+tAQI0uuNXfBpDeEATALapPQPfu3WXUqFESFRWlezur2qnqQa1mUKtYsaLOFigvvPCCbNu2TZ566ik9t4D6h1JlBZYvX+7t0wCSpUpeY8aM0XNhDBo0SGrVqqV/xzt06JDs38Snn36qf88dgcBbb711078NIL3hUcIAABiKyYIAADAUQQAAAIYiCAAAwFAEAQAAGIogAAAAQxEEAABgKIIAAAAMRRAAAIChCAIAH9CxY0dp2rSp83WdOnWkV69ead4ONSuemgXywoULaf7ZADyPIAC4w4uzuiiqJSAgQM8/P2zYMP0I2tS0ZMkSPUWtO7hwA0gOzw4A7tCjjz4qM2bMkNjYWFm2bJl069ZN/P399fzzCanH0apAwRPUY24B4E6RCQDukHp8rHqCXJEiRfSz6NWz5r/66itnCl89m149arZkyZJ6/yNHjkjr1q31w2XUxbxJkyb6WfYOcXFx+rHNanvOnDllwIABkvgRH4nLASoAeeWVV6RQoUK6PSojMX36dH1c9bhbJXv27DojoNqlqCfdqQfdqKc7BgUF6QfoLFq0yOVzVFBz77336u3qOAnbCcD3EQQAHqYumOquX1m1apXs379fIiMjZenSpfpRtQ0bNpSsWbPK2rVr9WNms2TJorMJjveo59nPnDlT/ve//8m6devk3Llz8vnnn9/0M9WT7tQT7caPHy979+7Vj3xWx1VBweLFi/U+qh3Hjx+XDz74QL9WAYB65LN6XO7u3bv1I3Dbt28vP/74ozNYad68uX6s7vbt26Vz584ycODAVP7pAUhT6imCAG5PRESEvUmTJvr7+Ph4e2RkpD0wMNDer18/vS1v3rz22NhY5/6zZ8+2lyxZUu/roLYHBQXZv/vuO/06f/789lGjRjm3X7t2zX7XXXc5P0epXbu2vWfPnvr7/fv3qzSB/uykfP/993r7+fPnnetiYmLswcHB9vXr17vs26lTJ3vbtm3194MGDbKHh4e7bH/llVduOBYA30WfAOAOqTt8ddet7vJViv3pp5+WN998U/cNKFu2rEs/gB07dsiBAwd0JiChmJgYOXjwoERHR+u79SpVqrg8t75y5co3lAQc1F26n5+f1K5d2+02qzZcuXJFGjRo4LJeZSMqVKigv1cZhYTtUKpVq+b2ZwBI/wgCgDukauWTJk3SF3tV+1cXbYeQkBCXfS9duiSVKlWSuXPn3nCc3Llz33b5IaVUO5RvvvlGChYs6LJN9SkAYAaCAOAOqQu96ojnjooVK8pnn30mefLkkdDQ0CT3yZ8/v2zatElq1aqlX6vhhlu2bNHvTYrKNqgMhKrlq06JiTkyEarDoUN4eLi+2B8+fDjZDELp0qV1B8eENm7c6NZ5AvANdAwE0lC7du0kV65cekSA6hgYFRWlx/H36NFDjh49qvfp2bOnvPPOO/LFF1/Ivn375KWXXrrpGP+iRYtKRESEPPfcc/o9jmMuWLBAb1ejFtSoAFW2OH36tM4CqHJEv379dGfATz75RJcitm7dKhMmTNCvlRdffFF+//136d+/v+5UOG/ePN1hEUDGQRAApKHg4GBZs2aNFC5cWPe8V3fbnTp10n0CHJmBvn37yjPPPKMv7KoGry7YzZo1u+lxVTmiZcuWOmAoVaqUdOnSRS5fvqy3qXT/0KFDdc/+vHnzSvfu3fV6NdnQ4MGD9SgB1Q41QkGVB9SQQUW1UY0sUIGFGj6oRhGMGDEi1X9GANKOpXoHpuHnAQCAdIJMAAAAhiIIAADAUAQBAAAYiiAAAABDEQQAAGAoggAAAAxFEAAAgKEIAgAAMBRBAAAAhiIIAADAUAQBAACImf4Ph8peszh+EroAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 🔹 5. 최종 이진 판정 (확률 기준은 0.5 유지)\n",
        "y_prob = predict_with_spectral_contrast(model,X_test, score=0.5)\n",
        "y_pred = (y_prob >= 0.5).astype(int)\n",
        "print(\"\\n✅ Classification Report - TEST DATA\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Real','Fake']))\n",
        "print(f\"ROC AUC: {roc_auc_score(y_test, y_prob):.3f}\")\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Real','Fake'], yticklabels=['Real','Fake'])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJrbcPVlKgMe"
      },
      "source": [
        "## Spectral contrast 최적화 기준 자동화 선별 함수 (실험 코드)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XTfmvJZ9ujG"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "\n",
        "import os\n",
        "\n",
        "# 1) 실제 오디오 파일들이 들어 있는 디렉토리 경로\n",
        "test_audio_path = \"test\"   # 예시: 테스트 오디오가 들어 있는 폴더명\n",
        "\n",
        "# 2) 해당 폴더에 있는 모든 .wav 파일 이름을 리스트로 가져오기\n",
        "test_filenames = sorted([\n",
        "    f for f in os.listdir(test_audio_path)\n",
        "    if f.lower().endswith('.wav')\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "def run_experiment(model, X_test, y_test, test_filenames, test_audio_path,\n",
        "                   prob_thresholds=[0.3, 0.4, 0.5, 0.6],\n",
        "                   contrast_bounds=[(22.0, 26.0), (23.0, 26.5), (22.5, 27.0)]):\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for prob_thresh in prob_thresholds:\n",
        "        for contrast_low, contrast_high in contrast_bounds:\n",
        "                    # 1. DNN 확률 예측\n",
        "          y_prob = model.predict(X_test).flatten()\n",
        "\n",
        "          # 2. 보정 대상 (확률 기준 이하)\n",
        "          uncertain_idx = np.where(y_prob < prob_thresh)[0]\n",
        "\n",
        "          # 3. Spectral Contrast 보정\n",
        "          for idx in tqdm(uncertain_idx, desc=f\"🔍 p<{prob_thresh}, c<{contrast_low} or >{contrast_high}\"):\n",
        "              file_path = os.path.join(test_audio_path, test_filenames[idx])\n",
        "              try:\n",
        "                  y, sr = librosa.load(file_path, sr=16000)\n",
        "                  contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
        "                  high_contrast = np.mean(contrast[-2:, :])\n",
        "\n",
        "                  # Fake로 보정 조건\n",
        "                  if high_contrast < contrast_low or high_contrast > contrast_high:\n",
        "                      y_prob[idx] = 1.0  # Fake로 강제 보정\n",
        "              except Exception as e:\n",
        "                  print(f\"⚠️ Error: {file_path} - {e}\")\n",
        "          for a in prob_thresholds:\n",
        "            # 4. 이진 결과\n",
        "            y_pred = (y_prob >= a).astype(int)\n",
        "\n",
        "            # 5. 지표 계산\n",
        "            acc = accuracy_score(y_test, y_pred)\n",
        "            precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
        "\n",
        "            # 6. 기록\n",
        "            results.append({\n",
        "                'a' : a,\n",
        "                'prob_thresh': prob_thresh,\n",
        "                'contrast_low': contrast_low,\n",
        "                'contrast_high': contrast_high,\n",
        "                'accuracy': acc,\n",
        "                'precision': precision,\n",
        "                'recall': recall,\n",
        "                'f1': f1\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "u0kbVwyk93KE",
        "outputId": "6d2f8638-fd83-4eed-fc69-e84d87724fbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "🔍 p<0.32, c<21 or >27: 100%|█████████████████████████████████████████████████████| 1169/1169 [00:10<00:00, 108.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "🔍 p<0.32, c<20.5 or >27.5: 100%|█████████████████████████████████████████████████| 1169/1169 [00:10<00:00, 111.24it/s]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a</th>\n",
              "      <th>prob_thresh</th>\n",
              "      <th>contrast_low</th>\n",
              "      <th>contrast_high</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.32</td>\n",
              "      <td>0.32</td>\n",
              "      <td>20.5</td>\n",
              "      <td>27.5</td>\n",
              "      <td>0.909</td>\n",
              "      <td>0.919745</td>\n",
              "      <td>0.909</td>\n",
              "      <td>0.908414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.32</td>\n",
              "      <td>0.32</td>\n",
              "      <td>21.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0.903</td>\n",
              "      <td>0.911534</td>\n",
              "      <td>0.903</td>\n",
              "      <td>0.902495</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      a  prob_thresh  contrast_low  contrast_high  accuracy  precision  \\\n",
              "0  0.32         0.32          20.5           27.5     0.909   0.919745   \n",
              "1  0.32         0.32          21.0           27.0     0.903   0.911534   \n",
              "\n",
              "   recall        f1  \n",
              "0   0.909  0.908414  \n",
              "1   0.903  0.902495  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 실험 설정 값\n",
        "prob_thresholds = [0.32]\n",
        "contrast_bounds = [(21,27),(20.5, 27.5)]\n",
        "\n",
        "# 실행\n",
        "result_df = run_experiment(model, X_test, y_test, test_filenames, test_audio_path,\n",
        "                           prob_thresholds, contrast_bounds)\n",
        "\n",
        "# 결과 출력 (F1-score 기준 정렬)\n",
        "result_df_sorted = result_df.sort_values(by='f1', ascending=False).reset_index(drop=True)\n",
        "\n",
        "from IPython.display import display\n",
        "display(result_df_sorted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRpBFV7tLQI9"
      },
      "source": [
        "# 예측 결과 파일 작성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lW15vZBXGcBr",
        "outputId": "99b32046-1a08-4dec-e865-406c71c77721"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 병합된 행 개수: 2000 (테스트 파일 전체 개수와 동일)\n",
            "\n",
            "▶ 평가 지표\n",
            "   Accuracy : 0.9215\n",
            "   Precision: 0.8688\n",
            "   Recall   : 0.9930\n",
            "   F1-score : 0.9267\n",
            "\n",
            "▶ 혼동 행렬 (Confusion Matrix)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>예측 Fake</th>\n",
              "      <th>예측 Real</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>실제 Fake</th>\n",
              "      <td>850</td>\n",
              "      <td>150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>실제 Real</th>\n",
              "      <td>7</td>\n",
              "      <td>993</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         예측 Fake  예측 Real\n",
              "실제 Fake      850      150\n",
              "실제 Real        7      993"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "▶ False Positive 개수: 150\n",
            "   샘플 예시: ['KDF_E_0420.wav', 'KDF_E_0293.wav', 'KDF_E_1380.wav', 'KDF_E_0574.wav', 'KDF_E_0473.wav'] …\n",
            "▶ False Negative 개수: 7\n",
            "   샘플 예시: ['KDF_E_0851.wav', 'KDF_E_0269.wav', 'KDF_E_1863.wav', 'KDF_E_0410.wav', 'KDF_E_0199.wav'] …\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from IPython.display import display\n",
        "\n",
        "# ─────────── 1. 예측 결과(team_test_result.txt) 읽기 ───────────\n",
        "# team_test_result.txt 형식: \"<filename> <label>\" (label은 \"Fake\" 또는 \"Real\" 문자열)\n",
        "pred_df = pd.read_csv(\n",
        "    \"team_test_result.txt\",\n",
        "    sep=\"\\s+\",            # 공백(스페이스나 탭)으로 구분\n",
        "    header=None,          # 컬럼명이 없음을 알려 줌\n",
        "    names=[\"filename\", \"pred_str\"]  # 파일명과 예측 라벨 문자열을 읽음\n",
        ")\n",
        "\n",
        "# ─────────── 2. 실제 레이블(label/test_label.txt) 읽기 ───────────\n",
        "# test_label.txt 형식: \"<index> <filename> <start> <end> <label>\" 와 같은 5개 항목이 있고,\n",
        "# 여기서 두 번째 항목(parts[1])이 파일명이므로 get_test_filenames 함수에서 filenames를 추출했습니다.\n",
        "# 그러나 평가할 때는 test_label.txt 내부에서 filename과 “실제 라벨(Fake/Real)” 두 개만 필요하므로,\n",
        "# 미리 LabelEncoder를 이용해 0/1로 인코딩해 둔 부분이 있습니다. 이번에는 그냥 “label_str”을 읽어옵니다.\n",
        "\n",
        "# test_label.txt에 “index filename start end label” 형태로 되어 있다면:\n",
        "true_df = pd.read_csv(\n",
        "    \"test_label.txt\",\n",
        "    sep=\"\\s+\",\n",
        "    header=None,\n",
        "    names=[\"idx\", \"filename\", \"start\", \"end\", \"true_str\"]\n",
        ")\n",
        "\n",
        "# ─────────── 3. 문자열 라벨(“Fake”/“Real”)을 0/1 숫자로 바꾸기 ───────────\n",
        "# LabelEncoder로 “Fake”→0, “Real”→1 매핑한 객체를 사용합니다.\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "le.fit([\"Fake\", \"Real\"])  # 0=Fake, 1=Real\n",
        "\n",
        "# 실제 라벨(문자열) → 숫자 벡터\n",
        "true_df[\"true\"] = le.transform(true_df[\"true_str\"])\n",
        "\n",
        "# 예측 라벨(문자열) → 숫자 벡터\n",
        "pred_df[\"pred\"] = le.transform(pred_df[\"pred_str\"])\n",
        "\n",
        "# ─────────── 4. 파일명 기준으로 병합(merge) ───────────\n",
        "#    두 DataFrame 모두 “filename” 컬럼이므로 inner join으로 합칩니다.\n",
        "merged = pd.merge(\n",
        "    true_df[[\"filename\", \"true\"]],\n",
        "    pred_df[[\"filename\", \"pred\"]],\n",
        "    on=\"filename\",\n",
        "    how=\"inner\"\n",
        ")\n",
        "\n",
        "if len(merged) != len(true_df):\n",
        "    print(\"⚠️ 경고: 병합된 행(row) 수가 예상과 다릅니다.\")\n",
        "    print(f\"   실제 레이블 개수: {len(true_df)}, 병합된 개수: {len(merged)}\")\n",
        "else:\n",
        "    print(f\"✅ 병합된 행 개수: {len(merged)} (테스트 파일 전체 개수와 동일)\")\n",
        "\n",
        "# ─────────── 5. 평가 지표(Accuracy, Precision, Recall, F1-score) 계산 ───────────\n",
        "y_true = merged[\"true\"].values\n",
        "y_pred = merged[\"pred\"].values\n",
        "\n",
        "acc  = accuracy_score(y_true, y_pred)\n",
        "prec = precision_score(y_true, y_pred, zero_division=0)\n",
        "rec  = recall_score(y_true, y_pred, zero_division=0)\n",
        "f1   = f1_score(y_true, y_pred, zero_division=0)\n",
        "\n",
        "print(\"\\n▶ 평가 지표\")\n",
        "print(f\"   Accuracy : {acc:.4f}\")\n",
        "print(f\"   Precision: {prec:.4f}\")\n",
        "print(f\"   Recall   : {rec:.4f}\")\n",
        "print(f\"   F1-score : {f1:.4f}\")\n",
        "\n",
        "# ─────────── 6. 혼동 행렬(Confusion Matrix) 출력 ───────────\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "cm_df = pd.DataFrame(\n",
        "    cm,\n",
        "    index=[f\"실제 {lab}\" for lab in le.classes_],       # [\"실제 Fake\", \"실제 Real\"]\n",
        "    columns=[f\"예측 {lab}\" for lab in le.classes_]      # [\"예측 Fake\", \"예측 Real\"]\n",
        ")\n",
        "print(\"\\n▶ 혼동 행렬 (Confusion Matrix)\")\n",
        "display(cm_df)\n",
        "\n",
        "# ─────────── 7. (옵션) 잘못 예측한 파일명 리스트 몇 개 출력 ───────────\n",
        "mask_fp = (merged[\"true\"] == 0) & (merged[\"pred\"] == 1)  # False Positive (원래는 Fake인데 Real로 예측)\n",
        "mask_fn = (merged[\"true\"] == 1) & (merged[\"pred\"] == 0)  # False Negative (원래는 Real인데 Fake로 예측)\n",
        "\n",
        "print(f\"\\n▶ False Positive 개수: {mask_fp.sum()}\")\n",
        "print(\"   샘플 예시:\", merged.loc[mask_fp, \"filename\"].tolist()[:5], \"…\")\n",
        "\n",
        "print(f\"▶ False Negative 개수: {mask_fn.sum()}\")\n",
        "print(\"   샘플 예시:\", merged.loc[mask_fn, \"filename\"].tolist()[:5], \"…\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w11DsD3VDCZ4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}